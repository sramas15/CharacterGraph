Play: 0

=========================================================================================================
Speaker: FIRST SOLDIER
Number of Total Listeners: 175

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
154 features selected out of 308 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
    BERTRAM       0.20      0.03      0.06        29
 FIRST LORD       0.00      0.00      0.00        29
   PAROLLES       0.20      0.03      0.05        35
SECOND LORD       0.22      0.95      0.35        38
SECOND SOLDIER       0.00      0.00      0.00         9
    SERVANT       0.00      0.00      0.00        29

avg / total       0.12      0.22      0.10       175

=========================================================================================================

=========================================================================================================
Speaker: BERTRAM
Number of Total Listeners: 368

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
386 features selected out of 773 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
COUNTESS OF ROUSILLON       0.20      0.10      0.13        21
      DIANA       1.00      0.25      0.40        20
 FIRST LORD       0.23      0.31      0.26        59
FIRST SOLDIER       0.00      0.00      0.00        12
FOURTH LORD       0.00      0.00      0.00         6
  GENTLEMAN       0.00      0.00      0.00        10
     HELENA       0.00      0.00      0.00        20
KING OF FRANCE       0.00      0.00      0.00        29
      LAFEU       0.19      0.32      0.24        41
   PAROLLES       0.30      0.79      0.44        61
SECOND LORD       0.20      0.18      0.19        57
    SERVANT       0.00      0.00      0.00        16
      WIDOW       0.00      0.00      0.00        10

avg / total       0.21      0.26      0.20       368

=========================================================================================================

=========================================================================================================
Speaker: GENTLEMAN
Number of Total Listeners: 21

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
21 features selected out of 43 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

      DIANA       0.33      1.00      0.50         7
     HELENA       0.00      0.00      0.00         7
      WIDOW       0.00      0.00      0.00         7

avg / total       0.11      0.33      0.17        21

=========================================================================================================

=========================================================================================================
Speaker: HELENA
Number of Total Listeners: 285

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
585 features selected out of 1170 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
    BERTRAM       0.20      0.09      0.13        22
      CLOWN       1.00      0.22      0.36         9
COUNTESS OF ROUSILLON       0.65      0.68      0.67        22
      DIANA       0.33      0.10      0.15        30
FIRST GENTLEMAN       0.50      0.20      0.29         5
 FIRST LORD       0.00      0.00      0.00        14
FOURTH LORD       0.00      0.00      0.00        11
  GENTLEMAN       0.00      0.00      0.00        10
KING OF FRANCE       0.41      0.46      0.43        24
      LAFEU       0.00      0.00      0.00        15
    MARIANA       0.33      0.06      0.11        16
   PAROLLES       0.25      0.89      0.39        44
SECOND GENTLEMAN       0.00      0.00      0.00         5
SECOND LORD       0.00      0.00      0.00        14
      WIDOW       0.41      0.63      0.49        35

avg / total       0.28      0.34      0.26       285

=========================================================================================================

=========================================================================================================
Speaker: COUNTESS OF ROUSILLON
Number of Total Listeners: 162

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
406 features selected out of 813 total
F1 mean: 0.07 (+/- 0.03)

             precision    recall  f1-score   support

    BERTRAM       0.00      0.00      0.00        13
      CLOWN       0.47      0.97      0.63        37
FIRST GENTLEMAN       0.00      0.00      0.00        11
 FIRST LORD       0.00      0.00      0.00         5
     HELENA       0.44      0.63      0.52        35
KING OF FRANCE       0.00      0.00      0.00         5
      LAFEU       0.33      0.53      0.41        19
SECOND GENTLEMAN       0.00      0.00      0.00        11
SECOND LORD       0.00      0.00      0.00         5
    STEWARD       1.00      0.24      0.38        21

avg / total       0.37      0.45      0.35       162

=========================================================================================================

=========================================================================================================
Speaker: KING OF FRANCE
Number of Total Listeners: 485

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
552 features selected out of 1104 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
    BERTRAM       0.15      0.13      0.14        61
COUNTESS OF ROUSILLON       0.20      0.02      0.04        44
      DIANA       0.00      0.00      0.00        29
 FIRST LORD       0.15      0.06      0.08        68
FOURTH LORD       0.00      0.00      0.00        10
  GENTLEMAN       0.00      0.00      0.00        32
     HELENA       0.47      0.35      0.40        26
      LAFEU       0.16      0.55      0.24        67
   PAROLLES       0.00      0.00      0.00        42
SECOND LORD       0.16      0.35      0.22        68
      WIDOW       0.00      0.00      0.00        29

avg / total       0.13      0.17      0.12       485

=========================================================================================================

=========================================================================================================
Speaker: FIRST LORD
Number of Total Listeners: 90

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
180 features selected out of 361 total
F1 mean: 0.09 (+/- 0.01)

             precision    recall  f1-score   support

    BERTRAM       1.00      0.05      0.09        22
FIRST SOLDIER       0.00      0.00      0.00         5
KING OF FRANCE       0.00      0.00      0.00         5
   PAROLLES       0.00      0.00      0.00        14
SECOND LORD       0.43      1.00      0.60        38
    SERVANT       0.00      0.00      0.00         6

avg / total       0.42      0.43      0.27        90

=========================================================================================================

=========================================================================================================
Speaker: CLOWN
Number of Total Listeners: 91

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
316 features selected out of 633 total
F1 mean: 0.13 (+/- 0.10)

             precision    recall  f1-score   support

COUNTESS OF ROUSILLON       0.58      1.00      0.73        48
     HELENA       1.00      0.29      0.44         7
      LAFEU       0.00      0.00      0.00        15
   PAROLLES       0.50      0.38      0.43         8
    STEWARD       0.00      0.00      0.00        13

avg / total       0.43      0.58      0.46        91

=========================================================================================================

=========================================================================================================
Speaker: PAROLLES
Number of Total Listeners: 395

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
514 features selected out of 1029 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
    BERTRAM       0.25      0.82      0.39        77
      CLOWN       0.67      0.17      0.27        12
COUNTESS OF ROUSILLON       0.00      0.00      0.00         7
      DIANA       0.00      0.00      0.00         8
 FIRST LORD       0.20      0.02      0.04        46
FIRST SOLDIER       0.33      0.03      0.05        40
  GENTLEMAN       0.00      0.00      0.00         7
     HELENA       0.77      0.34      0.48        29
KING OF FRANCE       0.00      0.00      0.00        11
      LAFEU       0.58      0.47      0.52        45
SECOND LORD       0.24      0.35      0.29        60
SECOND SOLDIER       0.00      0.00      0.00        14
    SERVANT       0.00      0.00      0.00        26
      WIDOW       0.00      0.00      0.00         8

avg / total       0.29      0.30      0.23       395

=========================================================================================================

=========================================================================================================
Speaker: SECOND LORD
Number of Total Listeners: 171

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
280 features selected out of 560 total
F1 mean: 0.07 (+/- 0.05)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
    BERTRAM       0.00      0.00      0.00        29
 FIRST LORD       0.39      0.93      0.55        46
FIRST SOLDIER       0.38      0.18      0.24        28
   PAROLLES       0.28      0.43      0.34        30
SECOND SOLDIER       0.50      0.06      0.11        17
    SERVANT       0.00      0.00      0.00        16

avg / total       0.27      0.36      0.26       171

=========================================================================================================

=========================================================================================================
Speaker: WIDOW
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
137 features selected out of 275 total
F1 mean: 0.10 (+/- 0.14)

             precision    recall  f1-score   support

      DIANA       0.43      0.59      0.50        17
     HELENA       0.45      0.59      0.51        17
    MARIANA       0.33      0.07      0.12        14

avg / total       0.41      0.44      0.39        48

=========================================================================================================

=========================================================================================================
Speaker: DIANA
Number of Total Listeners: 244

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
215 features selected out of 431 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

    BERTRAM       0.18      0.61      0.28        33
COUNTESS OF ROUSILLON       0.00      0.00      0.00        24
 FIRST LORD       0.00      0.00      0.00        24
  GENTLEMAN       0.00      0.00      0.00        24
     HELENA       0.00      0.00      0.00         9
KING OF FRANCE       0.00      0.00      0.00        24
      LAFEU       0.00      0.00      0.00        24
    MARIANA       0.00      0.00      0.00        10
   PAROLLES       0.00      0.00      0.00        14
SECOND LORD       0.00      0.00      0.00        24
      WIDOW       0.17      0.68      0.27        34

avg / total       0.05      0.18      0.08       244

=========================================================================================================

=========================================================================================================
Speaker: LAFEU
Number of Total Listeners: 249

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
424 features selected out of 849 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

    BERTRAM       0.29      0.75      0.42        48
      CLOWN       0.00      0.00      0.00        14
COUNTESS OF ROUSILLON       0.50      0.50      0.50        40
      DIANA       0.00      0.00      0.00         5
 FIRST LORD       0.00      0.00      0.00        16
FOURTH LORD       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00         6
     HELENA       0.00      0.00      0.00        21
KING OF FRANCE       0.43      0.35      0.38        26
   PAROLLES       0.46      0.62      0.53        47
SECOND LORD       0.00      0.00      0.00        16
      WIDOW       0.00      0.00      0.00         5

avg / total       0.27      0.38      0.30       249

=========================================================================================================

Play: 1

=========================================================================================================
Speaker: CHARMIAN
Number of Total Listeners: 264

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
183 features selected out of 366 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ALEXAS       0.00      0.00      0.00        37
        ALL       0.00      0.00      0.00        13
     ANTONY       0.00      0.00      0.00         7
     CAESAR       0.00      0.00      0.00         9
  CLEOPATRA       0.25      0.02      0.04        45
  ENOBARBUS       0.00      0.00      0.00        18
     GALLUS       0.14      0.11      0.12         9
       IRAS       0.24      0.97      0.39        63
   MAECENAS       0.00      0.00      0.00         9
    MARDIAN       0.00      0.00      0.00        24
 PROCULEIUS       0.00      0.00      0.00        10
 SOOTHSAYER       0.00      0.00      0.00        20

avg / total       0.11      0.24      0.10       264

=========================================================================================================

=========================================================================================================
Speaker: CLEOPATRA
Number of Total Listeners: 976

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
740 features selected out of 1481 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ALEXAS       0.17      0.02      0.03        64
        ALL       0.00      0.00      0.00        39
     ANTONY       0.25      0.06      0.09        70
     CAESAR       0.00      0.00      0.00        31
   CHARMIAN       0.21      0.20      0.21       181
      CLOWN       0.00      0.00      0.00         8
  DEMETRIUS       0.00      0.00      0.00         6
   DIOMEDES       0.00      0.00      0.00         9
  DOLABELLA       0.00      0.00      0.00        26
  ENOBARBUS       1.00      0.09      0.16        35
       EROS       0.00      0.00      0.00        10
 EUPHRONIUS       0.00      0.00      0.00        20
     GALLUS       0.00      0.00      0.00        31
       IRAS       0.19      0.79      0.31       187
   MAECENAS       0.00      0.00      0.00        31
    MARDIAN       0.11      0.01      0.02        95
  MESSENGER       0.25      0.03      0.05        38
      PHILO       0.00      0.00      0.00         6
 PROCULEIUS       0.00      0.00      0.00        49
   SELEUCUS       0.00      0.00      0.00         8
    SERVANT       0.00      0.00      0.00         9
 SOOTHSAYER       0.00      0.00      0.00         5
     THYMUS       0.00      0.00      0.00        10
    THYREUS       0.00      0.00      0.00         8

avg / total       0.16      0.20      0.12       976

=========================================================================================================

=========================================================================================================
Speaker: POMPEY
Number of Total Listeners: 316

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
246 features selected out of 493 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

    AGRIPPA       0.00      0.00      0.00        34
        ALL       0.00      0.00      0.00        13
     ANTONY       0.00      0.00      0.00        34
     CAESAR       0.12      0.03      0.05        34
    CAPTAIN       0.00      0.00      0.00        17
  ENOBARBUS       0.00      0.00      0.00        34
FIRST SERVANT       0.00      0.00      0.00        17
    LEPIDUS       0.00      0.00      0.00        34
   MAECENAS       0.00      0.00      0.00        34
      MENAS       0.13      0.98      0.23        41
 MENECRATES       0.00      0.00      0.00         7
SECOND SERVANT       0.00      0.00      0.00        17

avg / total       0.03      0.13      0.03       316

=========================================================================================================

=========================================================================================================
Speaker: SOLDIER
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
85 features selected out of 170 total
F1 mean: 0.04 (+/- 0.07)

             precision    recall  f1-score   support

     ANTONY       0.30      0.91      0.45        11
   CANIDIUS       0.00      0.00      0.00         5
  CLEOPATRA       0.00      0.00      0.00         6
  ENOBARBUS       0.43      0.43      0.43         7
       EROS       0.00      0.00      0.00         6
  MESSENGER       0.00      0.00      0.00         5

avg / total       0.16      0.33      0.20        40

=========================================================================================================

=========================================================================================================
Speaker: MESSENGER
Number of Total Listeners: 227

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
101 features selected out of 203 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

     ALEXAS       0.17      0.03      0.05        37
        ALL       0.00      0.00      0.00        20
     ANTONY       0.00      0.00      0.00         9
   CHARMIAN       0.00      0.00      0.00        37
  CLEOPATRA       0.18      0.95      0.30        40
  ENOBARBUS       0.00      0.00      0.00         9
FIRST ATTENDANT       0.00      0.00      0.00         6
       IRAS       0.25      0.03      0.05        37
    MARDIAN       0.00      0.00      0.00        20
SECOND ATTENDANT       0.00      0.00      0.00         6
 SOOTHSAYER       0.00      0.00      0.00         6

avg / total       0.10      0.18      0.07       227

=========================================================================================================

=========================================================================================================
Speaker: CANIDIUS
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
65 features selected out of 130 total
F1 mean: 0.09 (+/- 0.02)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00         7
  CLEOPATRA       0.00      0.00      0.00         7
  ENOBARBUS       0.29      1.00      0.45        10
  MESSENGER       0.00      0.00      0.00         5
    SOLDIER       0.00      0.00      0.00         5

avg / total       0.09      0.29      0.13        34

=========================================================================================================

=========================================================================================================
Speaker: MAECENAS
Number of Total Listeners: 60

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
83 features selected out of 166 total
F1 mean: 0.06 (+/- 0.05)

             precision    recall  f1-score   support

    AGRIPPA       0.26      0.93      0.41        15
     ANTONY       0.00      0.00      0.00         9
     CAESAR       0.17      0.07      0.10        14
  ENOBARBUS       0.00      0.00      0.00         7
    LEPIDUS       0.00      0.00      0.00         8
  VENTIDIUS       0.00      0.00      0.00         7

avg / total       0.10      0.25      0.12        60

=========================================================================================================

=========================================================================================================
Speaker: ENOBARBUS
Number of Total Listeners: 453

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
447 features selected out of 895 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

    AGRIPPA       0.25      0.24      0.25        37
     ALEXAS       0.25      0.05      0.08        20
     ANTONY       0.14      0.85      0.24        55
     CAESAR       1.00      0.03      0.06        32
   CANIDIUS       0.00      0.00      0.00         6
    CAPTAIN       0.00      0.00      0.00         9
   CHARMIAN       0.25      0.04      0.06        27
  CLEOPATRA       0.44      0.24      0.31        33
       EROS       1.00      0.17      0.29         6
 EUPHRONIUS       0.00      0.00      0.00         5
FIRST ATTENDANT       0.00      0.00      0.00        10
FIRST SERVANT       0.00      0.00      0.00         9
       IRAS       0.00      0.00      0.00        27
    LEPIDUS       0.44      0.12      0.19        34
   MAECENAS       0.00      0.00      0.00        27
      MENAS       0.37      0.57      0.45        28
     POMPEY       0.00      0.00      0.00        13
     SCARUS       0.00      0.00      0.00         6
SECOND ATTENDANT       0.00      0.00      0.00        10
SECOND SERVANT       0.00      0.00      0.00         9
     SILIUS       0.00      0.00      0.00        10
 SOOTHSAYER       0.00      0.00      0.00        15
  VENTIDIUS       0.33      0.04      0.07        25

avg / total       0.25      0.20      0.13       453

=========================================================================================================

=========================================================================================================
Speaker: CAESAR
Number of Total Listeners: 497

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
544 features selected out of 1088 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

    AGRIPPA       0.20      0.64      0.31        69
     ANTONY       0.18      0.08      0.11        52
   CHARMIAN       0.00      0.00      0.00        14
  CLEOPATRA       0.00      0.00      0.00        14
   DERCETAS       0.00      0.00      0.00         9
  DOLABELLA       0.25      0.04      0.07        24
  ENOBARBUS       0.40      0.05      0.09        40
     GALLUS       0.00      0.00      0.00        23
       IRAS       0.00      0.00      0.00        14
    LEPIDUS       0.36      0.20      0.26        44
   MAECENAS       0.15      0.48      0.22        69
    MARDIAN       0.00      0.00      0.00        14
      MENAS       0.00      0.00      0.00        10
  MESSENGER       0.00      0.00      0.00         6
    OCTAVIA       0.00      0.00      0.00        15
     POMPEY       0.00      0.00      0.00        10
 PROCULEIUS       0.00      0.00      0.00        22
   SELEUCUS       0.00      0.00      0.00         8
     SILIUS       0.00      0.00      0.00         7
    THYREUS       0.00      0.00      0.00         6
  VENTIDIUS       0.00      0.00      0.00        27

avg / total       0.14      0.19      0.12       497

=========================================================================================================

=========================================================================================================
Speaker: ALEXAS
Number of Total Listeners: 57

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
84 features selected out of 169 total
F1 mean: 0.04 (+/- 0.05)

             precision    recall  f1-score   support

   CHARMIAN       0.26      0.93      0.41        15
  CLEOPATRA       0.00      0.00      0.00         8
  ENOBARBUS       0.00      0.00      0.00         6
       IRAS       0.00      0.00      0.00        15
    MARDIAN       0.25      0.20      0.22         5
 SOOTHSAYER       0.00      0.00      0.00         8

avg / total       0.09      0.26      0.13        57

=========================================================================================================

=========================================================================================================
Speaker: ANTONY
Number of Total Listeners: 981

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
877 features selected out of 1754 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

    AGRIPPA       0.00      0.00      0.00        51
     ALEXAS       0.00      0.00      0.00        27
        ALL       0.50      0.08      0.13        26
     CAESAR       0.50      0.02      0.04        53
   CANIDIUS       0.00      0.00      0.00         8
    CAPTAIN       0.00      0.00      0.00        14
   CHARMIAN       0.17      0.06      0.09        84
  CLEOPATRA       0.19      0.66      0.30       102
  DEMETRIUS       0.00      0.00      0.00         7
   DIOMEDES       0.00      0.00      0.00        13
  ENOBARBUS       0.14      0.69      0.24       107
       EROS       0.64      0.42      0.51        43
 EUPHRONIUS       0.00      0.00      0.00        20
FIRST ATTENDANT       0.00      0.00      0.00        19
FIRST SERVANT       0.00      0.00      0.00        13
       IRAS       0.21      0.04      0.06        84
    LEPIDUS       0.00      0.00      0.00        51
   MAECENAS       0.10      0.02      0.04        44
      MENAS       0.00      0.00      0.00        20
  MESSENGER       0.00      0.00      0.00        12
    OCTAVIA       1.00      0.25      0.40        12
      PHILO       0.00      0.00      0.00         7
     POMPEY       0.00      0.00      0.00        20
     SCARUS       1.00      0.40      0.57        10
SECOND ATTENDANT       0.00      0.00      0.00        19
SECOND SERVANT       0.00      0.00      0.00        13
    SERVANT       0.00      0.00      0.00        12
     SILIUS       0.00      0.00      0.00         7
    SOLDIER       0.00      0.00      0.00         7
 SOOTHSAYER       0.67      0.08      0.14        25
     THYMUS       0.00      0.00      0.00        13
    THYREUS       0.00      0.00      0.00         6
  VENTIDIUS       0.17      0.06      0.09        32

avg / total       0.19      0.19      0.12       981

=========================================================================================================

=========================================================================================================
Speaker: EROS
Number of Total Listeners: 49

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
81 features selected out of 163 total
F1 mean: 0.13 (+/- 0.15)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
     ANTONY       0.43      1.00      0.60        20
   CHARMIAN       0.00      0.00      0.00         6
  CLEOPATRA       0.00      0.00      0.00         6
  ENOBARBUS       1.00      0.33      0.50         6
       IRAS       0.00      0.00      0.00         6

avg / total       0.30      0.45      0.30        49

=========================================================================================================

=========================================================================================================
Speaker: THYREUS
Number of Total Listeners: 53

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
64 features selected out of 129 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

     ANTONY       0.21      1.00      0.34        11
   CHARMIAN       0.00      0.00      0.00         9
  CLEOPATRA       0.00      0.00      0.00         9
  ENOBARBUS       0.00      0.00      0.00         6
 EUPHRONIUS       0.00      0.00      0.00         9
       IRAS       0.00      0.00      0.00         9

avg / total       0.04      0.21      0.07        53

=========================================================================================================

=========================================================================================================
Speaker: AGRIPPA
Number of Total Listeners: 108

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
119 features selected out of 238 total
F1 mean: 0.05 (+/- 0.03)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00        13
     CAESAR       0.31      0.44      0.36        18
  ENOBARBUS       0.23      0.85      0.36        20
    LEPIDUS       0.17      0.08      0.11        12
   MAECENAS       0.50      0.06      0.11        16
     SILIUS       0.00      0.00      0.00        10
  VENTIDIUS       0.00      0.00      0.00        19

avg / total       0.19      0.25      0.16       108

=========================================================================================================

=========================================================================================================
Speaker: LEPIDUS
Number of Total Listeners: 148

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
129 features selected out of 258 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    AGRIPPA       0.24      0.29      0.26        21
     ANTONY       0.00      0.00      0.00        17
     CAESAR       0.18      0.68      0.28        22
    CAPTAIN       0.00      0.00      0.00         7
  ENOBARBUS       0.26      0.33      0.29        21
FIRST SERVANT       0.00      0.00      0.00         7
   MAECENAS       0.17      0.10      0.12        20
      MENAS       0.00      0.00      0.00         9
     POMPEY       0.00      0.00      0.00         9
SECOND SERVANT       0.00      0.00      0.00         7
  VENTIDIUS       0.00      0.00      0.00         8

avg / total       0.12      0.20      0.14       148

=========================================================================================================

=========================================================================================================
Speaker: OCTAVIA
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
81 features selected out of 162 total
F1 mean: 0.10 (+/- 0.06)

             precision    recall  f1-score   support

    AGRIPPA       0.33      0.10      0.15        10
     ANTONY       1.00      0.29      0.44         7
     CAESAR       0.35      0.92      0.51        12
   MAECENAS       0.00      0.00      0.00         7

avg / total       0.41      0.39      0.30        36

=========================================================================================================

=========================================================================================================
Speaker: CLOWN
Number of Total Listeners: 64

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
65 features selected out of 131 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

     CAESAR       0.12      1.00      0.22         8
   CHARMIAN       0.00      0.00      0.00         8
  CLEOPATRA       0.00      0.00      0.00         8
     GALLUS       0.00      0.00      0.00         8
       IRAS       0.00      0.00      0.00         8
   MAECENAS       0.00      0.00      0.00         8
    MARDIAN       0.00      0.00      0.00         8
 PROCULEIUS       0.00      0.00      0.00         8

avg / total       0.02      0.12      0.03        64

=========================================================================================================

=========================================================================================================
Speaker: FIRST GUARD
Number of Total Listeners: 67

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 92 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     CAESAR       0.00      0.00      0.00         7
   CHARMIAN       0.00      0.00      0.00         7
  CLEOPATRA       0.00      0.00      0.00         7
     GALLUS       0.00      0.00      0.00         7
       IRAS       0.00      0.00      0.00         7
   MAECENAS       0.00      0.00      0.00         7
    MARDIAN       0.00      0.00      0.00         7
 PROCULEIUS       0.00      0.00      0.00         7
SECOND GUARD       0.16      1.00      0.28        11

avg / total       0.03      0.16      0.05        67

=========================================================================================================

=========================================================================================================
Speaker: IRAS
Number of Total Listeners: 69

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
59 features selected out of 118 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     ALEXAS       0.00      0.00      0.00         7
        ALL       0.00      0.00      0.00         6
     ANTONY       0.00      0.00      0.00         6
   CHARMIAN       0.25      1.00      0.40        15
  CLEOPATRA       0.33      0.27      0.30        11
  ENOBARBUS       0.00      0.00      0.00         7
    MARDIAN       0.00      0.00      0.00         5
 PROCULEIUS       0.00      0.00      0.00         5
 SOOTHSAYER       0.00      0.00      0.00         7

avg / total       0.11      0.26      0.13        69

=========================================================================================================

=========================================================================================================
Speaker: SECOND SOLDIER
Number of Total Listeners: 24

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
29 features selected out of 59 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

FIRST SOLDIER       0.33      1.00      0.50         8
FOURTH SOLDIER       0.00      0.00      0.00         8
THIRD SOLDIER       0.00      0.00      0.00         8

avg / total       0.11      0.33      0.17        24

=========================================================================================================

=========================================================================================================
Speaker: PROCULEIUS
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
74 features selected out of 148 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

   CHARMIAN       0.25      1.00      0.40         9
  CLEOPATRA       0.00      0.00      0.00         9
       IRAS       0.00      0.00      0.00         9
    MARDIAN       0.00      0.00      0.00         9

avg / total       0.06      0.25      0.10        36

=========================================================================================================

=========================================================================================================
Speaker: THIRD SOLDIER
Number of Total Listeners: 21

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
20 features selected out of 41 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

FIRST SOLDIER       0.33      1.00      0.50         7
FOURTH SOLDIER       0.00      0.00      0.00         7
SECOND SOLDIER       0.00      0.00      0.00         7

avg / total       0.11      0.33      0.17        21

=========================================================================================================

=========================================================================================================
Speaker: SOOTHSAYER
Number of Total Listeners: 38

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
30 features selected out of 61 total
F1 mean: 0.05 (+/- 0.09)

             precision    recall  f1-score   support

     ALEXAS       0.00      0.00      0.00        10
   CHARMIAN       0.26      1.00      0.42        10
  ENOBARBUS       0.00      0.00      0.00         8
       IRAS       0.00      0.00      0.00        10

avg / total       0.07      0.26      0.11        38

=========================================================================================================

=========================================================================================================
Speaker: MENAS
Number of Total Listeners: 179

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
120 features selected out of 241 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

    AGRIPPA       0.00      0.00      0.00        16
     ANTONY       0.00      0.00      0.00        16
     CAESAR       0.00      0.00      0.00        16
    CAPTAIN       0.00      0.00      0.00        16
  ENOBARBUS       0.19      0.97      0.31        32
FIRST SERVANT       0.00      0.00      0.00        16
    LEPIDUS       0.00      0.00      0.00        16
   MAECENAS       0.00      0.00      0.00        16
     POMPEY       0.25      0.16      0.19        19
SECOND SERVANT       0.00      0.00      0.00        16

avg / total       0.06      0.19      0.08       179

=========================================================================================================

=========================================================================================================
Speaker: DOLABELLA
Number of Total Listeners: 145

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
100 features selected out of 200 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     CAESAR       1.00      0.09      0.17        11
   CHARMIAN       0.12      0.05      0.07        19
  CLEOPATRA       0.00      0.00      0.00        21
FIRST GUARD       0.00      0.00      0.00         5
     GALLUS       0.00      0.00      0.00        10
       IRAS       0.00      0.00      0.00        21
   MAECENAS       0.00      0.00      0.00        10
    MARDIAN       0.00      0.00      0.00        21
 PROCULEIUS       0.15      0.95      0.27        22
SECOND GUARD       0.00      0.00      0.00         5

avg / total       0.12      0.16      0.06       145

=========================================================================================================

Play: 2

=========================================================================================================
Speaker: DUKE SENIOR
Number of Total Listeners: 174

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
226 features selected out of 452 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     AMIENS       0.18      0.97      0.31        32
     AUDREY       0.00      0.00      0.00         8
      CELIA       0.00      0.00      0.00        11
 FIRST LORD       0.00      0.00      0.00        21
      HYMEN       0.00      0.00      0.00         5
     JAQUES       0.25      0.04      0.07        24
     OLIVER       0.00      0.00      0.00        11
    ORLANDO       0.00      0.00      0.00        19
      PHEBE       0.00      0.00      0.00        10
   ROSALIND       0.00      0.00      0.00        10
SECOND LORD       0.00      0.00      0.00         5
    SILVIUS       0.00      0.00      0.00        10
 TOUCHSTONE       0.00      0.00      0.00         8

avg / total       0.07      0.18      0.07       174

=========================================================================================================

=========================================================================================================
Speaker: CELIA
Number of Total Listeners: 273

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
377 features selected out of 755 total
F1 mean: 0.06 (+/- 0.01)

             precision    recall  f1-score   support

    CHARLES       0.00      0.00      0.00        11
      CORIN       0.00      0.00      0.00        25
  FREDERICK       0.00      0.00      0.00        23
    LE BEAU       0.00      0.00      0.00        19
     OLIVER       0.00      0.00      0.00        10
    ORLANDO       0.00      0.00      0.00        14
   ROSALIND       0.40      1.00      0.57       108
    SILVIUS       0.00      0.00      0.00        11
 TOUCHSTONE       0.00      0.00      0.00        52

avg / total       0.16      0.40      0.22       273

=========================================================================================================

=========================================================================================================
Speaker: FREDERICK
Number of Total Listeners: 68

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
102 features selected out of 205 total
F1 mean: 0.07 (+/- 0.08)

             precision    recall  f1-score   support

      CELIA       0.20      0.69      0.31        16
    CHARLES       0.00      0.00      0.00         9
    LE BEAU       0.00      0.00      0.00         9
    ORLANDO       0.00      0.00      0.00         9
   ROSALIND       0.36      0.31      0.33        16
 TOUCHSTONE       0.00      0.00      0.00         9

avg / total       0.13      0.24      0.15        68

=========================================================================================================

=========================================================================================================
Speaker: ROSALIND
Number of Total Listeners: 593

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
713 features selected out of 1427 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     AMIENS       0.00      0.00      0.00         8
      CELIA       0.32      0.93      0.48       181
    CHARLES       0.00      0.00      0.00        12
      CORIN       0.20      0.03      0.06        61
DUKE SENIOR       0.00      0.00      0.00         8
  FREDERICK       0.00      0.00      0.00        24
     JAQUES       0.20      0.03      0.05        37
    LE BEAU       0.00      0.00      0.00        20
     OLIVER       0.00      0.00      0.00        18
    ORLANDO       0.32      0.15      0.20        89
      PHEBE       0.00      0.00      0.00        17
    SILVIUS       0.33      0.09      0.14        33
 TOUCHSTONE       0.33      0.04      0.06        85

avg / total       0.25      0.32      0.20       593

=========================================================================================================

=========================================================================================================
Speaker: LE BEAU
Number of Total Listeners: 57

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
104 features selected out of 208 total
F1 mean: 0.08 (+/- 0.05)

             precision    recall  f1-score   support

      CELIA       0.00      0.00      0.00        14
    CHARLES       0.00      0.00      0.00         5
  FREDERICK       0.00      0.00      0.00         5
    ORLANDO       0.00      0.00      0.00         5
   ROSALIND       0.00      0.00      0.00        14
 TOUCHSTONE       0.25      1.00      0.39        14

avg / total       0.06      0.25      0.10        57

=========================================================================================================

=========================================================================================================
Speaker: JAQUES
Number of Total Listeners: 239

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
357 features selected out of 715 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

     AMIENS       0.35      0.52      0.42        29
     AUDREY       0.00      0.00      0.00        18
      CELIA       0.20      0.48      0.29        29
      CORIN       0.00      0.00      0.00        12
DUKE SENIOR       0.33      0.05      0.09        20
 FIRST LORD       1.00      0.17      0.29        12
     OLIVER       0.00      0.00      0.00        11
    ORLANDO       0.16      0.22      0.19        27
      PHEBE       0.00      0.00      0.00        11
   ROSALIND       0.00      0.00      0.00        29
    SILVIUS       0.00      0.00      0.00        11
 TOUCHSTONE       0.20      0.57      0.30        30

avg / total       0.19      0.23      0.17       239

=========================================================================================================

=========================================================================================================
Speaker: OLIVER
Number of Total Listeners: 91

Best model LogisticRegression(C=1.3000000000000003, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
262 features selected out of 524 total
F1 mean: 0.12 (+/- 0.12)

             precision    recall  f1-score   support

       ADAM       0.40      0.11      0.17        19
      CELIA       0.00      0.00      0.00        15
    CHARLES       0.00      0.00      0.00         5
    ORLANDO       0.46      0.90      0.61        21
   ROSALIND       0.33      0.88      0.48        16
    SILVIUS       0.33      0.07      0.11        15

avg / total       0.30      0.40      0.28        91

=========================================================================================================

=========================================================================================================
Speaker: CHARLES
Number of Total Listeners: 20

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
99 features selected out of 198 total
F1 mean: 0.13 (+/- 0.13)

             precision    recall  f1-score   support

       ADAM       0.00      0.00      0.00         6
     OLIVER       0.00      0.00      0.00         6
    ORLANDO       0.40      1.00      0.57         8

avg / total       0.16      0.40      0.23        20

=========================================================================================================

=========================================================================================================
Speaker: CORIN
Number of Total Listeners: 44

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
140 features selected out of 280 total
F1 mean: 0.21 (+/- 0.04)

             precision    recall  f1-score   support

      CELIA       0.50      0.09      0.15        11
   ROSALIND       0.50      0.09      0.15        11
 TOUCHSTONE       0.55      1.00      0.71        22

avg / total       0.53      0.55      0.43        44

=========================================================================================================

=========================================================================================================
Speaker: SILVIUS
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
129 features selected out of 258 total
F1 mean: 0.15 (+/- 0.18)

             precision    recall  f1-score   support

      CELIA       0.00      0.00      0.00        11
    ORLANDO       0.00      0.00      0.00         6
      PHEBE       0.54      0.87      0.67        15
   ROSALIND       0.46      0.69      0.55        16

avg / total       0.32      0.50      0.39        48

=========================================================================================================

=========================================================================================================
Speaker: TOUCHSTONE
Number of Total Listeners: 206

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
390 features selected out of 781 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

     AMIENS       0.00      0.00      0.00         8
     AUDREY       0.35      0.87      0.50        39
      CELIA       0.43      0.11      0.17        28
      CORIN       0.78      0.64      0.70        22
DUKE SENIOR       0.00      0.00      0.00         8
     JAQUES       0.10      0.05      0.06        22
    MARTEXT       0.00      0.00      0.00         5
     OLIVER       0.00      0.00      0.00         8
    ORLANDO       0.00      0.00      0.00         8
      PHEBE       0.00      0.00      0.00         8
   ROSALIND       0.29      0.66      0.40        32
    SILVIUS       0.00      0.00      0.00         8
    WILLIAM       0.00      0.00      0.00        10

avg / total       0.26      0.35      0.26       206

=========================================================================================================

=========================================================================================================
Speaker: ORLANDO
Number of Total Listeners: 422

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
403 features selected out of 806 total
F1 mean: 0.05 (+/- 0.04)

             precision    recall  f1-score   support

       ADAM       0.70      0.39      0.50        18
     AMIENS       0.00      0.00      0.00        12
      CELIA       0.21      0.09      0.12        81
    CHARLES       0.17      0.08      0.11        13
      CORIN       0.00      0.00      0.00        33
DUKE SENIOR       0.25      0.08      0.12        12
 FIRST LORD       0.00      0.00      0.00         8
  FREDERICK       0.00      0.00      0.00        13
     JAQUES       0.25      0.07      0.10        46
    LE BEAU       0.00      0.00      0.00        13
     OLIVER       0.75      0.19      0.30        16
      PHEBE       0.00      0.00      0.00         9
   ROSALIND       0.24      0.91      0.38        92
    SILVIUS       0.00      0.00      0.00         9
 TOUCHSTONE       0.17      0.02      0.04        47

avg / total       0.21      0.25      0.16       422

=========================================================================================================

=========================================================================================================
Speaker: PHEBE
Number of Total Listeners: 57

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
155 features selected out of 311 total
F1 mean: 0.11 (+/- 0.04)

             precision    recall  f1-score   support

      CELIA       0.00      0.00      0.00         8
    ORLANDO       0.00      0.00      0.00        11
   ROSALIND       0.00      0.00      0.00        15
    SILVIUS       0.40      1.00      0.57        23

avg / total       0.16      0.40      0.23        57

=========================================================================================================

=========================================================================================================
Speaker: WILLIAM
Number of Total Listeners: 22

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
14 features selected out of 29 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

     AUDREY       0.50      1.00      0.67        11
 TOUCHSTONE       0.00      0.00      0.00        11

avg / total       0.25      0.50      0.33        22

=========================================================================================================

Play: 3

=========================================================================================================
Speaker: ANGELO
Number of Total Listeners: 129

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
151 features selected out of 302 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

    ADRIANA       0.00      0.00      0.00        10
     AEGEON       0.00      0.00      0.00         5
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00        19
ANTIPHOLUS OF SYRACUSE       1.00      0.38      0.55         8
  COURTEZAN       0.00      0.00      0.00         8
DROMIO OF EPHESUS       0.23      0.16      0.19        19
DROMIO OF SYRACUSE       0.00      0.00      0.00         5
       DUKE       0.00      0.00      0.00         5
    LUCIANA       0.00      0.00      0.00         8
  MESSENGER       0.00      0.00      0.00         5
    OFFICER       0.00      0.00      0.00        13
SECOND MERCHANT       0.20      0.96      0.34        24

avg / total       0.13      0.22      0.12       129

=========================================================================================================

=========================================================================================================
Speaker: DUKE
Number of Total Listeners: 167

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
186 features selected out of 372 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     ABBESS       0.00      0.00      0.00         5
    ADRIANA       0.00      0.00      0.00        17
     AEGEON       0.13      0.82      0.23        22
     ANGELO       0.00      0.00      0.00        17
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00        13
ANTIPHOLUS OF SYRACUSE       0.00      0.00      0.00         5
  COURTEZAN       0.00      0.00      0.00        17
DROMIO OF EPHESUS       0.00      0.00      0.00        13
DROMIO OF SYRACUSE       0.00      0.00      0.00         5
     GAOLER       0.50      0.20      0.29         5
    LUCIANA       0.10      0.18      0.13        17
  MESSENGER       0.00      0.00      0.00        14
SECOND MERCHANT       0.00      0.00      0.00        17

avg / total       0.04      0.13      0.05       167

=========================================================================================================

=========================================================================================================
Speaker: ABBESS
Number of Total Listeners: 80

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
156 features selected out of 313 total
F1 mean: 0.07 (+/- 0.00)

             precision    recall  f1-score   support

    ADRIANA       0.20      1.00      0.33        16
     ANGELO       0.00      0.00      0.00        16
  COURTEZAN       0.00      0.00      0.00        16
    LUCIANA       0.00      0.00      0.00        16
SECOND MERCHANT       0.00      0.00      0.00        16

avg / total       0.04      0.20      0.07        80

=========================================================================================================

=========================================================================================================
Speaker: DROMIO OF SYRACUSE
Number of Total Listeners: 202

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
361 features selected out of 723 total
F1 mean: 0.07 (+/- 0.04)

             precision    recall  f1-score   support

    ADRIANA       0.71      0.20      0.31        25
     ANGELO       0.25      0.12      0.16        17
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00        18
ANTIPHOLUS OF SYRACUSE       0.53      1.00      0.69        72
  BALTHAZAR       0.00      0.00      0.00        11
  COURTEZAN       0.00      0.00      0.00         9
DROMIO OF EPHESUS       0.22      0.52      0.31        21
       LUCE       0.00      0.00      0.00         6
    LUCIANA       0.00      0.00      0.00        17
SECOND MERCHANT       0.00      0.00      0.00         6

avg / total       0.32      0.45      0.33       202

=========================================================================================================

=========================================================================================================
Speaker: ANTIPHOLUS OF EPHESUS
Number of Total Listeners: 434

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
327 features selected out of 655 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ABBESS       0.00      0.00      0.00         6
    ADRIANA       0.00      0.00      0.00        40
     AEGEON       0.00      0.00      0.00        16
     ANGELO       0.13      0.04      0.06        51
ANTIPHOLUS OF SYRACUSE       0.00      0.00      0.00         7
  BALTHAZAR       0.00      0.00      0.00        19
  COURTEZAN       0.00      0.00      0.00        33
DROMIO OF EPHESUS       0.18      0.96      0.30        75
DROMIO OF SYRACUSE       0.00      0.00      0.00        23
       DUKE       0.00      0.00      0.00        16
       LUCE       0.00      0.00      0.00        10
    LUCIANA       0.00      0.00      0.00        33
  MESSENGER       0.00      0.00      0.00        16
    OFFICER       1.00      0.03      0.05        40
      PINCH       0.00      0.00      0.00        17
SECOND MERCHANT       0.11      0.03      0.05        32

avg / total       0.15      0.18      0.07       434

=========================================================================================================

=========================================================================================================
Speaker: AEGEON
Number of Total Listeners: 109

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
274 features selected out of 549 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

    ADRIANA       0.00      0.00      0.00        11
     ANGELO       0.00      0.00      0.00        11
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00        11
  COURTEZAN       0.00      0.00      0.00        11
DROMIO OF EPHESUS       0.00      0.00      0.00        11
       DUKE       0.15      0.87      0.25        15
     GAOLER       0.67      0.33      0.44         6
    LUCIANA       0.12      0.18      0.14        11
  MESSENGER       0.00      0.00      0.00        11
SECOND MERCHANT       0.00      0.00      0.00        11

avg / total       0.07      0.16      0.07       109

=========================================================================================================

=========================================================================================================
Speaker: COURTEZAN
Number of Total Listeners: 32

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
50 features selected out of 101 total
F1 mean: 0.15 (+/- 0.10)

             precision    recall  f1-score   support

    ADRIANA       0.25      1.00      0.40         6
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         5
ANTIPHOLUS OF SYRACUSE       0.50      0.80      0.62         5
DROMIO OF EPHESUS       0.00      0.00      0.00         5
DROMIO OF SYRACUSE       0.00      0.00      0.00         5
    LUCIANA       0.00      0.00      0.00         6

avg / total       0.12      0.31      0.17        32

=========================================================================================================

=========================================================================================================
Speaker: LUCE
Number of Total Listeners: 35

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
27 features selected out of 55 total
F1 mean: 0.07 (+/- 0.00)

             precision    recall  f1-score   support

     ANGELO       0.20      1.00      0.33         7
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         7
  BALTHAZAR       0.00      0.00      0.00         7
DROMIO OF EPHESUS       0.00      0.00      0.00         7
DROMIO OF SYRACUSE       0.00      0.00      0.00         7

avg / total       0.04      0.20      0.07        35

=========================================================================================================

=========================================================================================================
Speaker: DROMIO OF EPHESUS
Number of Total Listeners: 266

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
246 features selected out of 493 total
F1 mean: 0.03 (+/- 0.05)

             precision    recall  f1-score   support

    ADRIANA       0.27      0.35      0.31        34
     AEGEON       0.00      0.00      0.00         8
     ANGELO       0.17      0.04      0.07        24
ANTIPHOLUS OF EPHESUS       0.18      0.88      0.31        43
ANTIPHOLUS OF SYRACUSE       1.00      0.55      0.71        11
  BALTHAZAR       0.00      0.00      0.00        15
  COURTEZAN       0.00      0.00      0.00        19
DROMIO OF SYRACUSE       1.00      0.11      0.20        18
       DUKE       0.00      0.00      0.00         8
       LUCE       0.00      0.00      0.00        10
    LUCIANA       0.50      0.04      0.07        28
  MESSENGER       0.00      0.00      0.00         8
    OFFICER       0.00      0.00      0.00        20
      PINCH       0.00      0.00      0.00        11
SECOND MERCHANT       0.00      0.00      0.00         9

avg / total       0.24      0.23      0.14       266

=========================================================================================================

=========================================================================================================
Speaker: LUCIANA
Number of Total Listeners: 82

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
202 features selected out of 404 total
F1 mean: 0.09 (+/- 0.05)

             precision    recall  f1-score   support

    ADRIANA       0.45      0.97      0.61        35
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         5
ANTIPHOLUS OF SYRACUSE       0.67      0.29      0.40        14
  COURTEZAN       0.00      0.00      0.00         9
DROMIO OF EPHESUS       0.00      0.00      0.00         7
DROMIO OF SYRACUSE       0.00      0.00      0.00         7
    OFFICER       0.00      0.00      0.00         5

avg / total       0.30      0.46      0.33        82

=========================================================================================================

=========================================================================================================
Speaker: PINCH
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
40 features selected out of 80 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

    ADRIANA       0.17      1.00      0.29         6
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         6
  COURTEZAN       0.00      0.00      0.00         6
DROMIO OF EPHESUS       0.00      0.00      0.00         6
    LUCIANA       0.00      0.00      0.00         6
    OFFICER       0.00      0.00      0.00         6

avg / total       0.03      0.17      0.05        36

=========================================================================================================

=========================================================================================================
Speaker: ANTIPHOLUS OF SYRACUSE
Number of Total Listeners: 192

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
310 features selected out of 621 total
F1 mean: 0.05 (+/- 0.01)

             precision    recall  f1-score   support

     ABBESS       0.00      0.00      0.00         6
    ADRIANA       0.00      0.00      0.00        15
     AEGEON       0.00      0.00      0.00         6
     ANGELO       0.00      0.00      0.00        13
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         7
  COURTEZAN       0.00      0.00      0.00        11
DROMIO OF EPHESUS       1.00      0.29      0.44        14
DROMIO OF SYRACUSE       0.44      0.99      0.61        77
       DUKE       0.00      0.00      0.00         6
    LUCIANA       0.27      0.18      0.22        22
  MESSENGER       0.00      0.00      0.00         6
SECOND MERCHANT       0.00      0.00      0.00         9

avg / total       0.28      0.44      0.30       192

=========================================================================================================

=========================================================================================================
Speaker: OFFICER
Number of Total Listeners: 32

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
34 features selected out of 68 total
F1 mean: 0.06 (+/- 0.06)

             precision    recall  f1-score   support

    ADRIANA       0.00      0.00      0.00         6
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00         7
  COURTEZAN       0.00      0.00      0.00         6
DROMIO OF EPHESUS       0.35      1.00      0.52         7
    LUCIANA       0.33      0.67      0.44         6

avg / total       0.14      0.34      0.20        32

=========================================================================================================

=========================================================================================================
Speaker: ADRIANA
Number of Total Listeners: 305

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
403 features selected out of 806 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     ABBESS       0.00      0.00      0.00        15
     AEGEON       0.00      0.00      0.00         9
     ANGELO       0.17      0.04      0.07        24
ANTIPHOLUS OF EPHESUS       0.00      0.00      0.00        19
ANTIPHOLUS OF SYRACUSE       0.00      0.00      0.00        11
  COURTEZAN       0.20      0.03      0.05        39
DROMIO OF EPHESUS       0.00      0.00      0.00        26
DROMIO OF SYRACUSE       0.25      0.05      0.08        21
       DUKE       0.00      0.00      0.00         9
    LUCIANA       0.25      0.97      0.40        74
  MESSENGER       0.00      0.00      0.00         7
    OFFICER       0.00      0.00      0.00        17
      PINCH       0.00      0.00      0.00        12
SECOND MERCHANT       0.00      0.00      0.00        22

avg / total       0.12      0.25      0.11       305

=========================================================================================================

Play: 4

=========================================================================================================
Speaker: FIRST WATCH
Number of Total Listeners: 23

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
77 features selected out of 155 total
F1 mean: 0.27 (+/- 0.12)

             precision    recall  f1-score   support

   MENENIUS       0.50      0.09      0.15        11
SECOND WATCH       0.52      0.92      0.67        12

avg / total       0.51      0.52      0.42        23

=========================================================================================================

=========================================================================================================
Speaker: FIRST CITIZEN
Number of Total Listeners: 109

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
176 features selected out of 352 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

        ALL       0.25      0.07      0.11        28
     BRUTUS       0.00      0.00      0.00         7
    MARCIUS       0.00      0.00      0.00         6
   MENENIUS       0.33      0.05      0.08        21
SECOND CITIZEN       0.32      0.97      0.48        32
   SICINIUS       0.00      0.00      0.00         7
THIRD CITIZEN       0.00      0.00      0.00         8

avg / total       0.22      0.31      0.18       109

=========================================================================================================

=========================================================================================================
Speaker: LARTIUS
Number of Total Listeners: 68

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
108 features selected out of 216 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         7
   COMINIUS       1.00      0.10      0.18        10
FIRST SENATOR       0.33      0.09      0.14        11
    MARCIUS       0.28      1.00      0.44        18
   MENENIUS       0.00      0.00      0.00         7
  MESSENGER       0.00      0.00      0.00         6
SECOND SENATOR       0.00      0.00      0.00         9

avg / total       0.28      0.29      0.17        68

=========================================================================================================

=========================================================================================================
Speaker: THIRD CITIZEN
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
117 features selected out of 234 total
F1 mean: 0.05 (+/- 0.08)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         7
FIRST CITIZEN       0.29      0.36      0.32        14
    MARCIUS       0.00      0.00      0.00         8
   MENENIUS       0.00      0.00      0.00         5
SECOND CITIZEN       0.29      0.64      0.40        14

avg / total       0.17      0.29      0.21        48

=========================================================================================================

=========================================================================================================
Speaker: AUFIDIUS
Number of Total Listeners: 140

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
271 features selected out of 543 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

FIRST CONSPIRATOR       0.00      0.00      0.00        17
 FIRST LORD       0.00      0.00      0.00        11
FIRST SERVANT       0.00      0.00      0.00         7
      LORDS       0.00      0.00      0.00        11
    MARCIUS       0.24      0.92      0.38        24
SECOND CONSPIRATOR       0.00      0.00      0.00        17
SECOND LORD       0.00      0.00      0.00        11
SECOND SERVANT       0.00      0.00      0.00         7
THIRD CONSPIRATOR       0.21      0.59      0.31        17
 THIRD LORD       0.00      0.00      0.00        11
THIRD SERVANT       0.00      0.00      0.00         7

avg / total       0.07      0.23      0.10       140

=========================================================================================================

=========================================================================================================
Speaker: BRUTUS
Number of Total Listeners: 693

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
347 features selected out of 695 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00        15
    AEDILES       0.00      0.00      0.00        11
        ALL       0.09      0.06      0.07        36
BOTH CITIZENS       0.00      0.00      0.00        10
BOTH TRIBUNES       0.00      0.00      0.00        27
   COMINIUS       0.00      0.00      0.00        55
FIFTH CITIZEN       0.00      0.00      0.00        10
FIRST CITIZEN       0.08      0.04      0.05        25
FIRST OFFICER       0.00      0.00      0.00         6
FIRST SENATOR       0.00      0.00      0.00        41
FOURTH CITIZEN       0.00      0.00      0.00        10
     HERALD       0.00      0.00      0.00         9
    LARTIUS       0.00      0.00      0.00        41
    MARCIUS       0.11      0.03      0.05        60
   MENENIUS       0.14      0.14      0.14        85
  MESSENGER       0.00      0.00      0.00        13
 PATRICIANS       0.00      0.00      0.00        11
  PLEBEIANS       0.00      0.00      0.00        15
SECOND CITIZEN       0.00      0.00      0.00        18
SECOND CITIZENS       0.00      0.00      0.00         5
SECOND OFFICER       0.00      0.00      0.00         6
SECOND SENATOR       0.00      0.00      0.00        25
SEVENTH CITIZEN       0.00      0.00      0.00        10
   SICINIUS       0.13      0.81      0.23        91
SIXTH CITIZEN       0.00      0.00      0.00        10
THIRD CITIZEN       0.00      0.00      0.00        11
    VALERIA       0.00      0.00      0.00         9
   VIRGILIA       0.00      0.00      0.00        14
   VOLUMNIA       0.00      0.00      0.00        14

avg / total       0.05      0.13      0.06       693

=========================================================================================================

=========================================================================================================
Speaker: SICINIUS
Number of Total Listeners: 853

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
384 features selected out of 769 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00        26
    AEDILES       0.00      0.00      0.00        18
        ALL       0.08      0.02      0.03        46
BOTH CITIZENS       0.00      0.00      0.00        14
BOTH TRIBUNES       0.00      0.00      0.00        33
     BRUTUS       0.13      0.36      0.20       109
   COMINIUS       0.14      0.02      0.03        63
FIFTH CITIZEN       0.00      0.00      0.00        14
FIRST CITIZEN       0.00      0.00      0.00        35
FIRST SENATOR       0.00      0.00      0.00        47
FOURTH CITIZEN       0.00      0.00      0.00        14
     HERALD       0.00      0.00      0.00         8
    LARTIUS       0.00      0.00      0.00        42
    MARCIUS       0.13      0.03      0.05        70
   MENENIUS       0.14      0.68      0.23       111
  MESSENGER       0.00      0.00      0.00        20
 PATRICIANS       0.00      0.00      0.00        19
  PLEBEIANS       0.00      0.00      0.00        24
SECOND CITIZEN       0.00      0.00      0.00        23
SECOND MESSENGER       0.00      0.00      0.00         8
SECOND SENATOR       0.00      0.00      0.00        27
SEVENTH CITIZEN       0.00      0.00      0.00        14
SIXTH CITIZEN       0.00      0.00      0.00        14
THIRD CITIZEN       0.00      0.00      0.00        16
    VALERIA       0.00      0.00      0.00         8
   VIRGILIA       0.00      0.00      0.00        15
   VOLUMNIA       0.00      0.00      0.00        15

avg / total       0.06      0.14      0.06       853

=========================================================================================================

=========================================================================================================
Speaker: SECOND CITIZEN
Number of Total Listeners: 49

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
63 features selected out of 126 total
F1 mean: 0.09 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        11
FIRST CITIZEN       0.35      1.00      0.52        17
    MARCIUS       0.00      0.00      0.00         5
   MENENIUS       0.00      0.00      0.00         5
THIRD CITIZEN       0.00      0.00      0.00        11

avg / total       0.12      0.35      0.18        49

=========================================================================================================

=========================================================================================================
Speaker: COMINIUS
Number of Total Listeners: 328

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
408 features selected out of 817 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00        15
        ALL       0.00      0.00      0.00        14
BOTH TRIBUNES       0.00      0.00      0.00        18
     BRUTUS       0.18      0.28      0.22        39
FIRST CITIZEN       0.00      0.00      0.00         5
FIRST SENATOR       0.00      0.00      0.00        24
    LARTIUS       0.33      0.04      0.07        24
    MARCIUS       0.21      0.84      0.33        43
   MENENIUS       0.15      0.28      0.20        43
  MESSENGER       1.00      0.12      0.22        16
 PATRICIANS       0.00      0.00      0.00         5
  PLEBEIANS       0.00      0.00      0.00         9
SECOND CITIZEN       0.00      0.00      0.00         5
SECOND MESSENGER       0.00      0.00      0.00        11
SECOND SENATOR       0.00      0.00      0.00        11
   SICINIUS       0.22      0.05      0.08        39
   VOLUMNIA       0.00      0.00      0.00         7

avg / total       0.17      0.20      0.12       328

=========================================================================================================

=========================================================================================================
Speaker: PLEBEIANS
Number of Total Listeners: 123

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
31 features selected out of 63 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00         6
    AEDILES       0.00      0.00      0.00         7
        ALL       0.00      0.00      0.00         7
BOTH TRIBUNES       0.00      0.00      0.00         6
     BRUTUS       0.00      0.00      0.00        13
   COMINIUS       0.00      0.00      0.00        13
FIRST SENATOR       0.12      0.08      0.10        12
    LARTIUS       0.00      0.00      0.00         7
    MARCIUS       0.00      0.00      0.00        12
   MENENIUS       0.00      0.00      0.00        13
 PATRICIANS       0.00      0.00      0.00         7
SECOND SENATOR       0.00      0.00      0.00         7
   SICINIUS       0.10      0.92      0.19        13

avg / total       0.02      0.11      0.03       123

=========================================================================================================

=========================================================================================================
Speaker: FIRST SENATOR
Number of Total Listeners: 119

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
110 features selected out of 220 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
     BRUTUS       0.00      0.00      0.00        16
   COMINIUS       0.00      0.00      0.00        16
FIRST CITIZEN       0.00      0.00      0.00         6
    LARTIUS       0.00      0.00      0.00        12
    MARCIUS       0.17      0.25      0.20        16
   MENENIUS       0.15      0.82      0.25        17
SECOND SENATOR       1.00      0.18      0.31        11
   SICINIUS       0.00      0.00      0.00        16

avg / total       0.14      0.17      0.09       119

=========================================================================================================

=========================================================================================================
Speaker: VALERIA
Number of Total Listeners: 54

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
109 features selected out of 219 total
F1 mean: 0.12 (+/- 0.05)

             precision    recall  f1-score   support

GENTLEWOMAN       0.00      0.00      0.00        13
    MARCIUS       0.25      0.15      0.19        13
   VIRGILIA       0.00      0.00      0.00        14
   VOLUMNIA       0.26      0.86      0.40        14

avg / total       0.13      0.26      0.15        54

=========================================================================================================

=========================================================================================================
Speaker: MENENIUS
Number of Total Listeners: 917

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
679 features selected out of 1359 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00        17
    AEDILES       0.00      0.00      0.00        27
        ALL       0.32      0.18      0.23        51
BOTH TRIBUNES       0.33      0.04      0.08        46
     BRUTUS       0.14      0.34      0.20       115
   COMINIUS       0.15      0.03      0.04        79
FIRST CITIZEN       0.33      0.09      0.15        32
FIRST OFFICER       0.00      0.00      0.00        12
FIRST PATRICIAN       0.00      0.00      0.00         9
FIRST SENATOR       0.00      0.00      0.00        61
FIRST WATCH       0.00      0.00      0.00        13
    LARTIUS       0.00      0.00      0.00        38
    MARCIUS       0.21      0.20      0.20        75
  MESSENGER       0.00      0.00      0.00        13
 PATRICIANS       0.00      0.00      0.00        27
  PLEBEIANS       0.00      0.00      0.00        27
SECOND CITIZEN       0.33      0.05      0.08        22
SECOND MESSENGER       0.00      0.00      0.00        11
SECOND OFFICER       0.00      0.00      0.00        12
SECOND SENATOR       0.00      0.00      0.00        35
SECOND WATCH       0.43      0.23      0.30        13
   SICINIUS       0.15      0.62      0.24       122
    VALERIA       0.00      0.00      0.00        14
   VIRGILIA       0.00      0.00      0.00        19
   VOLUMNIA       0.00      0.00      0.00        27

avg / total       0.13      0.16      0.11       917

=========================================================================================================

=========================================================================================================
Speaker: MARCIUS
Number of Total Listeners: 930

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
963 features selected out of 1927 total
F1 mean: 0.00 (+/- 0.00)

             precision    recall  f1-score   support

     AEDILE       0.00      0.00      0.00        12
        ALL       0.19      0.21      0.20        47
   AUFIDIUS       0.28      0.55      0.37        33
BOTH CITIZENS       0.00      0.00      0.00         7
BOTH TRIBUNES       0.00      0.00      0.00        18
     BRUTUS       0.00      0.00      0.00        61
   COMINIUS       0.20      0.45      0.28        91
FIFTH CITIZEN       0.00      0.00      0.00        11
FIRST CITIZEN       0.00      0.00      0.00        30
FIRST CONSPIRATOR       0.00      0.00      0.00         8
 FIRST LORD       0.00      0.00      0.00         8
FIRST OFFICER       0.00      0.00      0.00         7
FIRST PATRICIAN       1.00      0.14      0.25        14
FIRST SENATOR       0.25      0.04      0.07        71
FIRST SERVANT       0.00      0.00      0.00        14
FOURTH CITIZEN       0.00      0.00      0.00        11
     HERALD       0.00      0.00      0.00         7
    LARTIUS       0.25      0.20      0.22        66
      LORDS       0.00      0.00      0.00         8
   MENENIUS       0.12      0.65      0.20        96
  MESSENGER       0.00      0.00      0.00        11
 PATRICIANS       0.00      0.00      0.00         5
  PLEBEIANS       0.00      0.00      0.00         8
SECOND CITIZEN       0.00      0.00      0.00        30
SECOND CONSPIRATOR       0.00      0.00      0.00         8
SECOND LORD       0.00      0.00      0.00         8
SECOND OFFICER       0.00      0.00      0.00         7
SECOND SENATOR       0.33      0.05      0.09        38
SECOND SERVANT       0.00      0.00      0.00        11
SEVENTH CITIZEN       0.00      0.00      0.00         6
   SICINIUS       0.00      0.00      0.00        61
SIXTH CITIZEN       0.00      0.00      0.00         6
THIRD CITIZEN       0.00      0.00      0.00        18
THIRD CONSPIRATOR       0.00      0.00      0.00         8
 THIRD LORD       0.00      0.00      0.00         8
THIRD SERVANT       0.50      0.07      0.12        14
    VALERIA       0.00      0.00      0.00         7
   VIRGILIA       0.20      0.17      0.18        24
   VOLUMNIA       0.33      0.06      0.11        32

avg / total       0.14      0.17      0.11       930

=========================================================================================================

=========================================================================================================
Speaker: THIRD SERVANT
Number of Total Listeners: 72

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
111 features selected out of 223 total
F1 mean: 0.06 (+/- 0.08)

             precision    recall  f1-score   support

   AUFIDIUS       0.00      0.00      0.00         9
       BOTH       0.20      0.12      0.15         8
FIRST SERVANT       0.00      0.00      0.00        20
    MARCIUS       0.29      0.90      0.44        20
SECOND SERVANT       0.20      0.07      0.10        15

avg / total       0.14      0.28      0.16        72

=========================================================================================================

=========================================================================================================
Speaker: VIRGILIA
Number of Total Listeners: 91

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
72 features selected out of 144 total
F1 mean: 0.06 (+/- 0.04)

             precision    recall  f1-score   support

     BRUTUS       0.00      0.00      0.00         5
GENTLEWOMAN       0.00      0.00      0.00        14
    MARCIUS       0.35      0.43      0.38        21
   MENENIUS       0.00      0.00      0.00         7
   SICINIUS       0.00      0.00      0.00         5
    VALERIA       0.25      0.07      0.11        15
   VOLUMNIA       0.26      0.67      0.38        24

avg / total       0.19      0.29      0.21        91

=========================================================================================================

=========================================================================================================
Speaker: VOLUMNIA
Number of Total Listeners: 244

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
457 features selected out of 914 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

   AUFIDIUS       0.33      0.12      0.18         8
BOTH TRIBUNES       0.00      0.00      0.00        14
     BRUTUS       0.00      0.00      0.00        23
   COMINIUS       0.00      0.00      0.00         9
FIRST PATRICIAN       0.00      0.00      0.00        13
FIRST SENATOR       0.00      0.00      0.00        10
GENTLEWOMAN       0.00      0.00      0.00         8
    MARCIUS       0.28      0.46      0.35        37
   MENENIUS       0.25      0.06      0.09        35
   SICINIUS       0.00      0.00      0.00        23
    VALERIA       0.00      0.00      0.00        20
   VIRGILIA       0.22      0.84      0.34        44

avg / total       0.13      0.23      0.13       244

=========================================================================================================

=========================================================================================================
Speaker: FIRST SERVANT
Number of Total Listeners: 67

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
71 features selected out of 142 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

   AUFIDIUS       0.00      0.00      0.00        14
       BOTH       0.00      0.00      0.00         7
    MARCIUS       0.24      0.75      0.37        16
SECOND SERVANT       0.22      0.27      0.24        15
THIRD SERVANT       0.00      0.00      0.00        15

avg / total       0.11      0.24      0.14        67

=========================================================================================================

=========================================================================================================
Speaker: BOTH TRIBUNES
Number of Total Listeners: 21

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
10 features selected out of 20 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

     BRUTUS       0.33      1.00      0.50         7
   MENENIUS       0.00      0.00      0.00         7
   SICINIUS       0.00      0.00      0.00         7

avg / total       0.11      0.33      0.17        21

=========================================================================================================

=========================================================================================================
Speaker: ALL
Number of Total Listeners: 38

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
33 features selected out of 66 total
F1 mean: 0.06 (+/- 0.03)

             precision    recall  f1-score   support

FIRST CITIZEN       0.25      1.00      0.40         8
FIRST SENATOR       0.50      0.17      0.25         6
    LARTIUS       0.00      0.00      0.00         5
    MARCIUS       0.50      0.33      0.40         6
SECOND CITIZEN       0.00      0.00      0.00         8
SECOND SENATOR       0.00      0.00      0.00         5

avg / total       0.21      0.29      0.19        38

=========================================================================================================

=========================================================================================================
Speaker: SECOND SERVANT
Number of Total Listeners: 59

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
75 features selected out of 151 total
F1 mean: 0.04 (+/- 0.07)

             precision    recall  f1-score   support

   AUFIDIUS       0.00      0.00      0.00        12
       BOTH       0.00      0.00      0.00         5
FIRST SERVANT       0.00      0.00      0.00        13
    MARCIUS       0.27      1.00      0.43        16
THIRD SERVANT       0.00      0.00      0.00        13

avg / total       0.07      0.27      0.12        59

=========================================================================================================

Play: 5

=========================================================================================================
Speaker: PHILARIO
Number of Total Listeners: 27

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
81 features selected out of 163 total
F1 mean: 0.15 (+/- 0.09)

             precision    recall  f1-score   support

  FRENCHMAN       0.00      0.00      0.00         6
    IACHIMO       0.45      0.82      0.58        11
  POSTHUMUS       0.57      0.40      0.47        10

avg / total       0.39      0.48      0.41        27

=========================================================================================================

=========================================================================================================
Speaker: PISANIO
Number of Total Listeners: 162

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
285 features selected out of 571 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

  ARVIRAGUS       0.00      0.00      0.00         7
   BELARIUS       0.00      0.00      0.00         7
     CLOTEN       0.00      0.00      0.00        14
  CORNELIUS       0.00      0.00      0.00         6
  CYMBELINE       1.00      0.08      0.14        13
  GUIDERIUS       0.00      0.00      0.00         7
    IACHIMO       0.00      0.00      0.00         8
     IMOGEN       0.34      0.95      0.50        40
       LADY       0.00      0.00      0.00         8
     LUCIUS       0.23      0.55      0.32        20
  MESSENGER       0.00      0.00      0.00        15
  POSTHUMUS       0.00      0.00      0.00         6
      QUEEN       0.00      0.00      0.00         5
 SOOTHSAYER       0.00      0.00      0.00         6

avg / total       0.19      0.31      0.17       162

=========================================================================================================

=========================================================================================================
Speaker: IACHIMO
Number of Total Listeners: 210

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
636 features selected out of 1273 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

  ARVIRAGUS       0.00      0.00      0.00         7
   BELARIUS       0.00      0.00      0.00         8
  CORNELIUS       0.00      0.00      0.00         7
  CYMBELINE       0.00      0.00      0.00         7
  FRENCHMAN       0.50      0.05      0.09        20
  GUIDERIUS       0.00      0.00      0.00         7
     IMOGEN       0.33      0.85      0.48        34
       LADY       0.00      0.00      0.00         7
     LUCIUS       0.00      0.00      0.00         8
   PHILARIO       0.39      0.71      0.50        41
    PISANIO       0.00      0.00      0.00        13
  POSTHUMUS       0.26      0.27      0.26        44
 SOOTHSAYER       0.00      0.00      0.00         7

avg / total       0.23      0.34      0.24       210

=========================================================================================================

=========================================================================================================
Speaker: GUIDERIUS
Number of Total Listeners: 224

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
263 features selected out of 526 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

  ARVIRAGUS       0.18      0.33      0.24        48
   BELARIUS       0.27      0.67      0.38        51
     CLOTEN       0.89      0.26      0.40        31
  CORNELIUS       0.00      0.00      0.00         8
  CYMBELINE       0.00      0.00      0.00         8
    IACHIMO       0.00      0.00      0.00         8
     IMOGEN       0.00      0.00      0.00        30
       LADY       0.00      0.00      0.00         8
     LUCIUS       0.00      0.00      0.00         8
    PISANIO       0.00      0.00      0.00         8
  POSTHUMUS       0.00      0.00      0.00         8
 SOOTHSAYER       0.00      0.00      0.00         8

avg / total       0.22      0.26      0.19       224

=========================================================================================================

=========================================================================================================
Speaker: CYMBELINE
Number of Total Listeners: 587

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
418 features selected out of 837 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

  ARVIRAGUS       0.00      0.00      0.00        53
   BELARIUS       0.11      0.08      0.09        53
     CLOTEN       0.00      0.00      0.00        17
  CORNELIUS       0.11      0.06      0.08        49
 FIRST LORD       0.00      0.00      0.00         9
  GUIDERIUS       0.00      0.00      0.00        53
    IACHIMO       0.00      0.00      0.00        42
     IMOGEN       0.15      0.35      0.21        51
       LADY       0.00      0.00      0.00        43
     LUCIUS       0.14      0.45      0.21        56
    PISANIO       0.13      0.49      0.21        57
  POSTHUMUS       0.00      0.00      0.00        43
      QUEEN       0.36      0.21      0.27        19
 SOOTHSAYER       0.00      0.00      0.00        42

avg / total       0.07      0.14      0.08       587

=========================================================================================================

=========================================================================================================
Speaker: IMOGEN
Number of Total Listeners: 425

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
683 features selected out of 1366 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

  ARVIRAGUS       0.20      0.06      0.09        34
   BELARIUS       0.21      0.12      0.15        34
       BOTH       0.20      0.20      0.20         5
     CLOTEN       0.14      0.12      0.13        17
  CORNELIUS       0.00      0.00      0.00        17
  CYMBELINE       0.20      0.34      0.25        38
 FIRST LORD       0.00      0.00      0.00        12
  GUIDERIUS       0.23      0.18      0.20        33
    IACHIMO       0.23      0.75      0.35        44
       LADY       0.25      0.06      0.10        33
     LUCIUS       0.00      0.00      0.00        21
  MESSENGER       0.00      0.00      0.00        12
    PISANIO       0.31      0.71      0.43        58
  POSTHUMUS       1.00      0.10      0.18        20
      QUEEN       0.00      0.00      0.00        14
SECOND LORD       0.00      0.00      0.00        12
 SOOTHSAYER       0.00      0.00      0.00        21

avg / total       0.21      0.25      0.18       425

=========================================================================================================

=========================================================================================================
Speaker: LUCIUS
Number of Total Listeners: 165

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
205 features selected out of 410 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

  ARVIRAGUS       0.00      0.00      0.00        15
   BELARIUS       0.12      0.53      0.20        17
       BOTH       0.00      0.00      0.00         9
    CAPTAIN       0.00      0.00      0.00         9
     CLOTEN       0.17      0.65      0.28        17
  CORNELIUS       0.00      0.00      0.00         6
  CYMBELINE       0.20      0.29      0.24        14
  GUIDERIUS       0.12      0.07      0.09        15
    IACHIMO       0.00      0.00      0.00         7
     IMOGEN       0.00      0.00      0.00        15
       LADY       0.00      0.00      0.00         6
    PISANIO       0.00      0.00      0.00         6
  POSTHUMUS       0.00      0.00      0.00         6
      QUEEN       0.00      0.00      0.00         8
 SOOTHSAYER       0.00      0.00      0.00        15

avg / total       0.06      0.15      0.08       165

=========================================================================================================

=========================================================================================================
Speaker: POSTHUMUS
Number of Total Listeners: 271

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
512 features selected out of 1025 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         8
  ARVIRAGUS       0.00      0.00      0.00         8
   BELARIUS       0.00      0.00      0.00         8
   BROTHERS       0.00      0.00      0.00         8
  CORNELIUS       0.00      0.00      0.00         8
  CYMBELINE       0.00      0.00      0.00        10
FIRST BROTHER       0.00      0.00      0.00         8
  FRENCHMAN       0.33      0.05      0.09        19
     GAOLER       0.00      0.00      0.00         7
  GUIDERIUS       0.00      0.00      0.00         8
    IACHIMO       0.20      0.58      0.30        50
     IMOGEN       0.23      0.40      0.29        15
    JUPITER       0.00      0.00      0.00         8
       LADY       0.00      0.00      0.00         8
       LORD       1.00      0.80      0.89         5
     LUCIUS       0.00      0.00      0.00         8
     MOTHER       0.00      0.00      0.00         8
   PHILARIO       0.27      0.47      0.34        45
    PISANIO       0.00      0.00      0.00         8
SECOND BROTHER       0.00      0.00      0.00         8
   SICILIUS       0.13      0.25      0.17         8
 SOOTHSAYER       0.00      0.00      0.00         8

avg / total       0.14      0.23      0.16       271

=========================================================================================================

=========================================================================================================
Speaker: BELARIUS
Number of Total Listeners: 273

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
510 features selected out of 1020 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

  ARVIRAGUS       0.21      0.44      0.29        55
     CLOTEN       1.00      0.06      0.11        18
  CORNELIUS       0.00      0.00      0.00        14
  CYMBELINE       0.00      0.00      0.00        16
  GUIDERIUS       0.21      0.60      0.31        55
    IACHIMO       0.00      0.00      0.00        14
     IMOGEN       0.00      0.00      0.00        29
       LADY       0.00      0.00      0.00        14
     LUCIUS       0.00      0.00      0.00        14
    PISANIO       0.00      0.00      0.00        16
  POSTHUMUS       0.00      0.00      0.00        14
 SOOTHSAYER       0.00      0.00      0.00        14

avg / total       0.15      0.21      0.13       273

=========================================================================================================

=========================================================================================================
Speaker: FIRST LORD
Number of Total Listeners: 24

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
64 features selected out of 128 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

     CLOTEN       0.50      1.00      0.67        12
SECOND LORD       0.00      0.00      0.00        12

avg / total       0.25      0.50      0.33        24

=========================================================================================================

=========================================================================================================
Speaker: SECOND LORD
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
103 features selected out of 207 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

     CLOTEN       0.50      1.00      0.67        21
 FIRST LORD       0.00      0.00      0.00        21

avg / total       0.25      0.50      0.33        42

=========================================================================================================

=========================================================================================================
Speaker: LADY
Number of Total Listeners: 32

Best model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=200, multi_class='ovr',
          penalty='l1', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=1)
25 features selected out of 50 total
F1 mean: 0.03 (+/- 0.10)

             precision    recall  f1-score   support

     CLOTEN       0.00      0.00      0.00         5
  CYMBELINE       0.29      0.33      0.31         6
 FIRST LORD       0.00      0.00      0.00         5
  MESSENGER       0.00      0.00      0.00         5
      QUEEN       0.20      0.83      0.32         6
SECOND LORD       0.00      0.00      0.00         5

avg / total       0.09      0.22      0.12        32

=========================================================================================================

=========================================================================================================
Speaker: CLOTEN
Number of Total Listeners: 256

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
362 features selected out of 724 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

  CYMBELINE       0.33      0.04      0.07        27
 FIRST LORD       0.22      0.86      0.35        49
  GUIDERIUS       1.00      0.40      0.57        10
     IMOGEN       0.00      0.00      0.00        11
       LADY       0.00      0.00      0.00        16
     LUCIUS       0.36      0.17      0.24        23
  MESSENGER       0.35      0.27      0.31        33
    PISANIO       0.00      0.00      0.00        14
      QUEEN       0.29      0.07      0.11        29
SECOND LORD       0.40      0.14      0.20        44

avg / total       0.29      0.27      0.20       256

=========================================================================================================

=========================================================================================================
Speaker: QUEEN
Number of Total Listeners: 58

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
277 features selected out of 555 total
F1 mean: 0.07 (+/- 0.05)

             precision    recall  f1-score   support

     CLOTEN       0.38      0.30      0.33        10
  CORNELIUS       1.00      0.57      0.73         7
  CYMBELINE       0.36      0.69      0.47        13
     IMOGEN       1.00      0.33      0.50         9
     LUCIUS       0.50      0.22      0.31         9
    PISANIO       0.50      0.70      0.58        10

avg / total       0.58      0.48      0.48        58

=========================================================================================================

=========================================================================================================
Speaker: ARVIRAGUS
Number of Total Listeners: 179

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
250 features selected out of 500 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

   BELARIUS       0.28      0.91      0.43        46
     CLOTEN       0.00      0.00      0.00        20
  CORNELIUS       0.00      0.00      0.00         5
  CYMBELINE       0.00      0.00      0.00         5
  GUIDERIUS       0.14      0.09      0.11        43
    IACHIMO       0.00      0.00      0.00         5
     IMOGEN       0.00      0.00      0.00        30
       LADY       0.00      0.00      0.00         5
     LUCIUS       0.00      0.00      0.00         5
    PISANIO       0.00      0.00      0.00         5
  POSTHUMUS       0.00      0.00      0.00         5
 SOOTHSAYER       0.00      0.00      0.00         5

avg / total       0.11      0.26      0.14       179

=========================================================================================================

=========================================================================================================
Speaker: SOOTHSAYER
Number of Total Listeners: 25

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
103 features selected out of 206 total
F1 mean: 0.07 (+/- 0.00)

             precision    recall  f1-score   support

  ARVIRAGUS       0.20      1.00      0.33         5
   BELARIUS       0.00      0.00      0.00         5
  GUIDERIUS       0.00      0.00      0.00         5
     IMOGEN       0.00      0.00      0.00         5
     LUCIUS       0.00      0.00      0.00         5

avg / total       0.04      0.20      0.07        25

=========================================================================================================

=========================================================================================================
Speaker: GAOLER
Number of Total Listeners: 63

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
101 features selected out of 202 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         8
   BROTHERS       0.00      0.00      0.00         8
FIRST BROTHER       0.13      1.00      0.23         8
    JUPITER       0.00      0.00      0.00         8
     MOTHER       0.00      0.00      0.00         8
  POSTHUMUS       0.00      0.00      0.00         7
SECOND BROTHER       0.00      0.00      0.00         8
   SICILIUS       0.00      0.00      0.00         8

avg / total       0.02      0.13      0.03        63

=========================================================================================================

=========================================================================================================
Speaker: CORNELIUS
Number of Total Listeners: 48

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
155 features selected out of 310 total
F1 mean: 0.02 (+/- 0.06)

             precision    recall  f1-score   support

  ARVIRAGUS       0.00      0.00      0.00         8
   BELARIUS       0.00      0.00      0.00         8
  CYMBELINE       0.00      0.00      0.00         8
  GUIDERIUS       0.00      0.00      0.00         8
    PISANIO       0.24      1.00      0.39        11
      QUEEN       1.00      0.40      0.57         5

avg / total       0.16      0.27      0.15        48

=========================================================================================================

Play: 6

=========================================================================================================
Speaker: GUILDENSTERN
Number of Total Listeners: 233

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
95 features selected out of 191 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        13
       BOTH       0.00      0.00      0.00         7
  CORNELIUS       0.00      0.00      0.00        12
FIRST PLAYER       0.00      0.00      0.00        15
     HAMLET       0.10      0.04      0.06        24
    HORATIO       0.10      0.08      0.09        13
       KING       0.33      0.04      0.06        28
    OPHELIA       0.00      0.00      0.00        15
   POLONIUS       0.00      0.00      0.00        25
   PROLOGUE       0.00      0.00      0.00        13
      QUEEN       0.12      0.11      0.11        27
ROSENCRANTZ       0.12      0.79      0.22        29
  VOLTEMAND       0.00      0.00      0.00        12

avg / total       0.08      0.12      0.06       233

=========================================================================================================

=========================================================================================================
Speaker: OSRIC
Number of Total Listeners: 68

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
98 features selected out of 197 total
F1 mean: 0.11 (+/- 0.01)

             precision    recall  f1-score   support

     HAMLET       0.37      1.00      0.54        25
    HORATIO       0.00      0.00      0.00        25
       KING       0.00      0.00      0.00         6
    LAERTES       0.00      0.00      0.00         6
       LORD       0.00      0.00      0.00         6

avg / total       0.14      0.37      0.20        68

=========================================================================================================

=========================================================================================================
Speaker: MARCELLUS
Number of Total Listeners: 80

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
125 features selected out of 251 total
F1 mean: 0.11 (+/- 0.03)

             precision    recall  f1-score   support

   BERNARDO       0.33      0.06      0.10        18
      GHOST       0.00      0.00      0.00        16
     HAMLET       0.00      0.00      0.00        15
    HORATIO       0.39      0.97      0.56        31

avg / total       0.23      0.39      0.24        80

=========================================================================================================

=========================================================================================================
Speaker: ROSENCRANTZ
Number of Total Listeners: 289

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
181 features selected out of 363 total
F1 mean: 0.02 (+/- 0.05)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
       BOTH       0.00      0.00      0.00        18
  CORNELIUS       0.00      0.00      0.00        27
FIRST PLAYER       0.00      0.00      0.00        11
GUILDENSTERN       0.15      0.59      0.24        41
     HAMLET       0.19      0.11      0.14        35
    HORATIO       0.00      0.00      0.00         6
       KING       0.15      0.45      0.23        38
    OPHELIA       0.00      0.00      0.00        10
   POLONIUS       0.00      0.00      0.00        33
   PROLOGUE       0.00      0.00      0.00         5
      QUEEN       0.00      0.00      0.00        33
  VOLTEMAND       0.00      0.00      0.00        27

avg / total       0.06      0.16      0.08       289

=========================================================================================================

=========================================================================================================
Speaker: CAPTAIN
Number of Total Listeners: 25

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
33 features selected out of 67 total
F1 mean: 0.10 (+/- 0.01)

             precision    recall  f1-score   support

 FORTINBRAS       0.28      1.00      0.44         7
GUILDENSTERN       0.00      0.00      0.00         6
     HAMLET       0.00      0.00      0.00         6
ROSENCRANTZ       0.00      0.00      0.00         6

avg / total       0.08      0.28      0.12        25

=========================================================================================================

=========================================================================================================
Speaker: FIRST PLAYER
Number of Total Listeners: 54

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
13 features selected out of 26 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

       BOTH       0.11      1.00      0.20         6
  CORNELIUS       0.00      0.00      0.00         6
GUILDENSTERN       0.00      0.00      0.00         6
     HAMLET       0.00      0.00      0.00         6
       KING       0.00      0.00      0.00         6
   POLONIUS       0.00      0.00      0.00         6
      QUEEN       0.00      0.00      0.00         6
ROSENCRANTZ       0.00      0.00      0.00         6
  VOLTEMAND       0.00      0.00      0.00         6

avg / total       0.01      0.11      0.02        54

=========================================================================================================

=========================================================================================================
Speaker: BERNARDO
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
71 features selected out of 143 total
F1 mean: 0.09 (+/- 0.09)

             precision    recall  f1-score   support

  FRANCISCO       1.00      0.17      0.29         6
      GHOST       0.00      0.00      0.00         8
    HORATIO       0.32      0.62      0.42        13
  MARCELLUS       0.36      0.38      0.37        13

avg / total       0.37      0.35      0.30        40

=========================================================================================================

=========================================================================================================
Speaker: BOTH
Number of Total Listeners: 46

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
14 features selected out of 28 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

  CORNELIUS       0.00      0.00      0.00         5
     HAMLET       0.17      1.00      0.30         8
    HORATIO       0.00      0.00      0.00         6
       KING       0.00      0.00      0.00         6
  MARCELLUS       0.00      0.00      0.00         6
   POLONIUS       0.00      0.00      0.00         5
      QUEEN       0.00      0.00      0.00         5
  VOLTEMAND       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        46

=========================================================================================================

=========================================================================================================
Speaker: LAERTES
Number of Total Listeners: 236

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
310 features selected out of 620 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        16
      CLOWN       0.00      0.00      0.00         6
  GENTLEMAN       0.00      0.00      0.00        16
     HAMLET       0.00      0.00      0.00        22
    HORATIO       0.23      0.16      0.19        37
       KING       0.24      0.98      0.39        49
       LORD       0.14      0.07      0.09        15
  MESSENGER       0.00      0.00      0.00        15
    OPHELIA       1.00      0.21      0.35        14
      OSRIC       0.00      0.00      0.00        11
      QUEEN       0.00      0.00      0.00        29
SECOND CLOWN       0.00      0.00      0.00         6

avg / total       0.15      0.25      0.14       236

=========================================================================================================

=========================================================================================================
Speaker: CLOWN
Number of Total Listeners: 75

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
165 features selected out of 331 total
F1 mean: 0.14 (+/- 0.16)

             precision    recall  f1-score   support

     HAMLET       0.00      0.00      0.00        21
    HORATIO       0.00      0.00      0.00        21
SECOND CLOWN       0.44      1.00      0.61        33

avg / total       0.19      0.44      0.27        75

=========================================================================================================

=========================================================================================================
Speaker: HAMLET
Number of Total Listeners: 1920

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
1427 features selected out of 2855 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        37
   BERNARDO       0.00      0.00      0.00        27
       BOTH       0.25      0.04      0.07        75
    CAPTAIN       0.00      0.00      0.00         6
      CLOWN       0.00      0.00      0.00        38
  CORNELIUS       0.12      0.01      0.02       104
FIRST PLAYER       0.00      0.00      0.00        60
 FORTINBRAS       0.00      0.00      0.00         7
      GHOST       0.33      0.03      0.05        34
GUILDENSTERN       0.13      0.03      0.05       120
    HORATIO       0.19      0.78      0.30       211
       KING       0.14      0.19      0.16       197
    LAERTES       0.14      0.02      0.03        61
       LORD       0.33      0.04      0.07        27
  MARCELLUS       0.00      0.00      0.00        55
    OPHELIA       0.00      0.00      0.00        96
      OSRIC       0.00      0.00      0.00        35
   POLONIUS       0.14      0.19      0.16       187
     PRIEST       0.00      0.00      0.00         7
   PROLOGUE       0.00      0.00      0.00        43
      QUEEN       0.15      0.27      0.19       201
ROSENCRANTZ       0.21      0.12      0.15       150
SECOND CLOWN       0.00      0.00      0.00        38
  VOLTEMAND       0.00      0.00      0.00       104

avg / total       0.12      0.17      0.11      1920

=========================================================================================================

=========================================================================================================
Speaker: KING
Number of Total Listeners: 433

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
681 features selected out of 1363 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        12
       BOTH       0.25      0.12      0.17         8
  CORNELIUS       0.00      0.00      0.00        20
FIRST PLAYER       0.00      0.00      0.00         9
  GENTLEMAN       0.00      0.00      0.00        16
GUILDENSTERN       0.33      0.03      0.05        38
     HAMLET       0.28      0.29      0.29        38
    HORATIO       0.14      0.06      0.08        36
    LAERTES       0.28      0.49      0.36        47
       LORD       0.00      0.00      0.00        12
  MESSENGER       0.50      0.07      0.12        15
    OPHELIA       0.00      0.00      0.00        22
      OSRIC       0.00      0.00      0.00         9
   POLONIUS       0.00      0.00      0.00        29
      QUEEN       0.18      0.76      0.30        59
ROSENCRANTZ       0.27      0.28      0.27        43
  VOLTEMAND       0.00      0.00      0.00        20

avg / total       0.17      0.22      0.15       433

=========================================================================================================

=========================================================================================================
Speaker: POLONIUS
Number of Total Listeners: 533

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
483 features selected out of 967 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
       BOTH       0.13      0.10      0.12        39
  CORNELIUS       0.17      0.02      0.04        42
FIRST PLAYER       0.00      0.00      0.00        16
      GHOST       0.00      0.00      0.00        19
GUILDENSTERN       0.17      0.02      0.04        51
     HAMLET       0.14      0.73      0.24        60
    HORATIO       0.17      0.04      0.06        28
       KING       0.15      0.16      0.16        55
  MARCELLUS       0.00      0.00      0.00        19
    OPHELIA       0.45      0.42      0.43        24
   PROLOGUE       0.00      0.00      0.00         6
      QUEEN       0.16      0.16      0.16        55
   REYNALDO       0.00      0.00      0.00        19
ROSENCRANTZ       0.16      0.11      0.13        53
  VOLTEMAND       0.00      0.00      0.00        42

avg / total       0.13      0.16      0.11       533

=========================================================================================================

=========================================================================================================
Speaker: ALL
Number of Total Listeners: 23

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
9 features selected out of 18 total
F1 mean: 0.10 (+/- 0.01)

             precision    recall  f1-score   support

    HORATIO       0.26      1.00      0.41         6
       KING       0.00      0.00      0.00         6
    LAERTES       0.00      0.00      0.00         5
      QUEEN       0.00      0.00      0.00         6

avg / total       0.07      0.26      0.11        23

=========================================================================================================

=========================================================================================================
Speaker: HORATIO
Number of Total Listeners: 466

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
397 features selected out of 794 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        10
   BERNARDO       0.15      0.05      0.08        38
       BOTH       0.00      0.00      0.00        16
      CLOWN       0.00      0.00      0.00        10
  CORNELIUS       0.00      0.00      0.00        22
      GHOST       0.33      0.09      0.14        23
     HAMLET       0.21      0.94      0.35        87
       KING       0.00      0.00      0.00        33
    LAERTES       0.00      0.00      0.00        29
       LORD       0.00      0.00      0.00         9
  MARCELLUS       0.23      0.23      0.23        62
    OPHELIA       0.00      0.00      0.00        26
      OSRIC       0.00      0.00      0.00         9
   POLONIUS       0.00      0.00      0.00        26
      QUEEN       1.00      0.03      0.06        34
SECOND CLOWN       0.00      0.00      0.00        10
  VOLTEMAND       0.00      0.00      0.00        22

avg / total       0.17      0.22      0.11       466

=========================================================================================================

=========================================================================================================
Speaker: OPHELIA
Number of Total Listeners: 343

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
223 features selected out of 447 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
       BOTH       0.00      0.00      0.00        18
  CORNELIUS       0.00      0.00      0.00        13
FIRST PLAYER       0.00      0.00      0.00        17
  GENTLEMAN       0.17      0.07      0.10        14
      GHOST       0.00      0.00      0.00         5
GUILDENSTERN       0.00      0.00      0.00        13
     HAMLET       0.00      0.00      0.00        32
    HORATIO       0.14      0.03      0.05        35
       KING       0.19      0.08      0.11        39
    LAERTES       1.00      0.11      0.20         9
  MARCELLUS       0.00      0.00      0.00         5
   POLONIUS       0.17      0.71      0.27        41
   PROLOGUE       0.00      0.00      0.00         7
      QUEEN       0.15      0.49      0.23        43
   REYNALDO       0.00      0.00      0.00         5
ROSENCRANTZ       0.00      0.00      0.00        29
  VOLTEMAND       0.00      0.00      0.00        13

avg / total       0.11      0.16      0.09       343

=========================================================================================================

=========================================================================================================
Speaker: QUEEN
Number of Total Listeners: 271

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
271 features selected out of 543 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
      CLOWN       0.00      0.00      0.00         5
  CORNELIUS       0.00      0.00      0.00        11
FIRST PLAYER       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00        11
      GHOST       0.00      0.00      0.00        10
GUILDENSTERN       0.00      0.00      0.00        15
     HAMLET       0.26      0.51      0.35        41
    HORATIO       0.40      0.09      0.14        23
       KING       0.25      0.41      0.31        37
    LAERTES       0.25      0.06      0.10        17
    OPHELIA       0.00      0.00      0.00        12
   POLONIUS       0.20      0.60      0.29        40
     PRIEST       0.00      0.00      0.00         5
ROSENCRANTZ       0.00      0.00      0.00        18
SECOND CLOWN       0.00      0.00      0.00         5
  VOLTEMAND       0.00      0.00      0.00        11

avg / total       0.15      0.23      0.16       271

=========================================================================================================

=========================================================================================================
Speaker: REYNALDO
Number of Total Listeners: 78

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
20 features selected out of 40 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

       BOTH       0.17      1.00      0.29        13
      GHOST       0.00      0.00      0.00        13
     HAMLET       0.00      0.00      0.00        13
    HORATIO       0.00      0.00      0.00        13
  MARCELLUS       0.00      0.00      0.00        13
   POLONIUS       0.00      0.00      0.00        13

avg / total       0.03      0.17      0.05        78

=========================================================================================================

Play: 7

=========================================================================================================
Speaker: HOSTESS
Number of Total Listeners: 116

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
96 features selected out of 193 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.22      0.83      0.34        24
   FALSTAFF       0.00      0.00      0.00        24
    FRANCIS       0.00      0.00      0.00         8
   GADSHILL       0.00      0.00      0.00         8
       PETO       0.00      0.00      0.00         8
      POINS       0.17      0.22      0.19        18
     PRINCE       0.00      0.00      0.00        18
    VINTNER       0.00      0.00      0.00         8

avg / total       0.07      0.21      0.10       116

=========================================================================================================

=========================================================================================================
Speaker: DOUGLAS
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
102 features selected out of 204 total
F1 mean: 0.17 (+/- 0.18)

             precision    recall  f1-score   support

    HOTSPUR       0.38      0.87      0.53        15
       KING       0.75      0.75      0.75         8
     VERNON       0.00      0.00      0.00         8
  WORCESTER       0.00      0.00      0.00        11

avg / total       0.28      0.45      0.33        42

=========================================================================================================

=========================================================================================================
Speaker: FALSTAFF
Number of Total Listeners: 686

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
686 features selected out of 1372 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.22      0.29      0.25       100
    BARDOPH       0.00      0.00      0.00         9
    DOUGLAS       0.33      0.20      0.25        10
    FRANCIS       0.00      0.00      0.00        57
   GADSHILL       0.00      0.00      0.00        67
    HOSTESS       0.12      0.02      0.03        54
    HOTSPUR       0.00      0.00      0.00         6
       KING       0.00      0.00      0.00         9
  LANCASTER       0.00      0.00      0.00         9
       PETO       0.17      0.01      0.03        67
      POINS       0.14      0.03      0.05        98
     PRINCE       0.21      0.84      0.34       131
    VINTNER       0.00      0.00      0.00        57
WESTMORELAND       0.00      0.00      0.00        12

avg / total       0.12      0.21      0.12       686

=========================================================================================================

=========================================================================================================
Speaker: VERNON
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
90 features selected out of 180 total
F1 mean: 0.18 (+/- 0.08)

             precision    recall  f1-score   support

    DOUGLAS       0.33      0.09      0.14        11
    HOTSPUR       0.00      0.00      0.00        11
  WORCESTER       0.35      0.92      0.51        12

avg / total       0.23      0.35      0.23        34

=========================================================================================================

=========================================================================================================
Speaker: HOTSPUR
Number of Total Listeners: 536

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
728 features selected out of 1457 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        27
      BLUNT       0.25      0.04      0.06        27
    DOUGLAS       0.34      0.29      0.32        41
    FRANCIS       0.00      0.00      0.00        27
   GADSHILL       0.00      0.00      0.00        27
  GLENDOWER       0.00      0.00      0.00        25
    HOSTESS       0.00      0.00      0.00        27
       KING       0.00      0.00      0.00        27
       LADY       0.50      0.16      0.24        19
  LANCASTER       0.00      0.00      0.00         5
  MESSENGER       0.00      0.00      0.00         5
   MORTIMER       0.00      0.00      0.00        27
NORTHUMBERLAND       0.00      0.00      0.00        22
       PETO       0.00      0.00      0.00        27
      POINS       0.00      0.00      0.00        27
     PRINCE       0.08      0.03      0.05        32
    SERVANT       0.50      0.11      0.18         9
     VERNON       0.00      0.00      0.00        23
    VINTNER       0.00      0.00      0.00        27
WESTMORELAND       0.00      0.00      0.00         5
  WORCESTER       0.16      0.93      0.27        80

avg / total       0.09      0.17      0.08       536

=========================================================================================================

=========================================================================================================
Speaker: POINS
Number of Total Listeners: 136

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
207 features selected out of 415 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        15
    BARDOPH       0.00      0.00      0.00         5
   FALSTAFF       0.00      0.00      0.00        25
    FRANCIS       0.00      0.00      0.00        14
   GADSHILL       0.00      0.00      0.00        15
       PETO       0.00      0.00      0.00        15
     PRINCE       0.26      1.00      0.42        36
    VINTNER       0.00      0.00      0.00        11

avg / total       0.07      0.26      0.11       136

=========================================================================================================

=========================================================================================================
Speaker: KING
Number of Total Listeners: 91

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
504 features selected out of 1009 total
F1 mean: 0.02 (+/- 0.04)

             precision    recall  f1-score   support

      BLUNT       0.41      0.44      0.42        16
   FALSTAFF       0.00      0.00      0.00         6
  LANCASTER       0.25      0.75      0.38        20
     PRINCE       0.67      0.35      0.46        17
     VERNON       0.00      0.00      0.00         7
WESTMORELAND       0.00      0.00      0.00        14
  WORCESTER       0.17      0.09      0.12        11

avg / total       0.27      0.32      0.26        91

=========================================================================================================

=========================================================================================================
Speaker: GLENDOWER
Number of Total Listeners: 258

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
168 features selected out of 337 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        23
    FRANCIS       0.00      0.00      0.00        23
   GADSHILL       0.00      0.00      0.00        23
    HOSTESS       0.00      0.00      0.00        23
    HOTSPUR       0.09      0.27      0.14        22
       LADY       0.00      0.00      0.00         6
   MORTIMER       0.00      0.00      0.00        23
       PETO       0.00      0.00      0.00        23
      POINS       0.09      0.74      0.16        23
     PRINCE       0.00      0.00      0.00        23
    VINTNER       0.00      0.00      0.00        23
  WORCESTER       0.00      0.00      0.00        23

avg / total       0.02      0.09      0.03       258

=========================================================================================================

=========================================================================================================
Speaker: SHERIFF
Number of Total Listeners: 45

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
24 features selected out of 49 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

   BARDOLPH       0.11      1.00      0.20         5
    CARRIER       0.00      0.00      0.00         5
    FRANCIS       0.00      0.00      0.00         5
   GADSHILL       0.00      0.00      0.00         5
    HOSTESS       0.00      0.00      0.00         5
       PETO       0.00      0.00      0.00         5
      POINS       0.00      0.00      0.00         5
     PRINCE       0.00      0.00      0.00         5
    VINTNER       0.00      0.00      0.00         5

avg / total       0.01      0.11      0.02        45

=========================================================================================================

=========================================================================================================
Speaker: BLUNT
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
97 features selected out of 194 total
F1 mean: 0.08 (+/- 0.11)

             precision    recall  f1-score   support

    DOUGLAS       0.32      0.88      0.47         8
    HOTSPUR       0.25      0.17      0.20         6
       KING       0.50      0.40      0.44         5
     VERNON       0.00      0.00      0.00         5
  WORCESTER       0.00      0.00      0.00         6

avg / total       0.22      0.33      0.24        30

=========================================================================================================

=========================================================================================================
Speaker: PETO
Number of Total Listeners: 46

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
31 features selected out of 63 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00         7
    FRANCIS       0.00      0.00      0.00         6
   GADSHILL       0.00      0.00      0.00         7
    HOSTESS       0.00      0.00      0.00         5
      POINS       0.17      1.00      0.30         8
     PRINCE       0.00      0.00      0.00         7
    VINTNER       0.00      0.00      0.00         6

avg / total       0.03      0.17      0.05        46

=========================================================================================================

=========================================================================================================
Speaker: NORTHUMBERLAND
Number of Total Listeners: 44

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
70 features selected out of 140 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

      BLUNT       0.25      1.00      0.40        11
    HOTSPUR       0.00      0.00      0.00        11
       KING       0.00      0.00      0.00        11
  WORCESTER       0.00      0.00      0.00        11

avg / total       0.06      0.25      0.10        44

=========================================================================================================

=========================================================================================================
Speaker: WORCESTER
Number of Total Listeners: 108

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
328 features selected out of 657 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

      BLUNT       0.00      0.00      0.00        18
    DOUGLAS       0.00      0.00      0.00        12
    HOTSPUR       0.31      0.97      0.47        30
       KING       0.33      0.21      0.26        19
NORTHUMBERLAND       0.00      0.00      0.00        16
     VERNON       1.00      0.15      0.27        13

avg / total       0.26      0.32      0.21       108

=========================================================================================================

=========================================================================================================
Speaker: FRANCIS
Number of Total Listeners: 25

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
28 features selected out of 57 total
F1 mean: 0.34 (+/- 0.07)

             precision    recall  f1-score   support

      POINS       0.00      0.00      0.00        11
     PRINCE       0.56      1.00      0.72        14

avg / total       0.31      0.56      0.40        25

=========================================================================================================

=========================================================================================================
Speaker: PRINCE
Number of Total Listeners: 760

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
676 features selected out of 1353 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.25      0.01      0.02        85
    BARDOPH       0.00      0.00      0.00         7
      BLUNT       0.00      0.00      0.00         6
    DOUGLAS       0.00      0.00      0.00        13
   FALSTAFF       0.21      0.64      0.32       122
    FRANCIS       0.17      0.06      0.09        71
   GADSHILL       0.00      0.00      0.00        68
    HOSTESS       0.00      0.00      0.00        56
    HOTSPUR       0.00      0.00      0.00         6
       KING       0.33      0.25      0.29        20
  LANCASTER       0.24      0.18      0.21        22
       PETO       0.00      0.00      0.00        68
      POINS       0.20      0.55      0.29       117
     VERNON       0.00      0.00      0.00         7
    VINTNER       0.00      0.00      0.00        65
WESTMORELAND       0.29      0.10      0.15        20
  WORCESTER       0.00      0.00      0.00         7

avg / total       0.13      0.21      0.12       760

=========================================================================================================

=========================================================================================================
Speaker: BARDOLPH
Number of Total Listeners: 68

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
58 features selected out of 116 total
F1 mean: 0.04 (+/- 0.01)

             precision    recall  f1-score   support

   FALSTAFF       0.37      0.92      0.52        12
    FRANCIS       0.00      0.00      0.00         6
   GADSHILL       0.00      0.00      0.00         6
    HOSTESS       0.00      0.00      0.00        10
       PETO       0.00      0.00      0.00         7
      POINS       0.16      0.55      0.24        11
     PRINCE       0.00      0.00      0.00        10
    VINTNER       0.00      0.00      0.00         6

avg / total       0.09      0.25      0.13        68

=========================================================================================================

=========================================================================================================
Speaker: MORTIMER
Number of Total Listeners: 146

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
138 features selected out of 277 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        13
    FRANCIS       0.00      0.00      0.00        13
   GADSHILL       0.00      0.00      0.00        13
  GLENDOWER       0.08      0.09      0.09        11
    HOSTESS       0.00      0.00      0.00        13
    HOTSPUR       0.09      0.25      0.13        12
       LADY       0.00      0.00      0.00         6
       PETO       0.00      0.00      0.00        13
      POINS       0.00      0.00      0.00        13
     PRINCE       0.00      0.00      0.00        13
    VINTNER       0.00      0.00      0.00        13
  WORCESTER       0.09      0.69      0.16        13

avg / total       0.02      0.09      0.03       146

=========================================================================================================

=========================================================================================================
Speaker: GADSHILL
Number of Total Listeners: 58

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
107 features selected out of 215 total
F1 mean: 0.08 (+/- 0.06)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00         6
CHAMBERLAIN       0.33      0.17      0.22         6
   FALSTAFF       0.20      0.50      0.29         6
FIRST CARRIER       0.40      0.91      0.56        11
       PETO       0.20      0.50      0.29         6
      POINS       0.00      0.00      0.00         6
     PRINCE       0.00      0.00      0.00         6
SECOND CARRIER       0.00      0.00      0.00        11

avg / total       0.15      0.29      0.19        58

=========================================================================================================

Play: 8

=========================================================================================================
Speaker: SHALLOW
Number of Total Listeners: 460

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
277 features selected out of 554 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

   BARDOLPH       0.17      0.47      0.25        66
   BULLCALF       0.00      0.00      0.00        43
       DAVY       0.00      0.00      0.00        21
   FALSTAFF       0.18      0.37      0.24        63
     FEEBLE       0.12      0.02      0.04        43
     MOULDY       0.00      0.00      0.00        43
       PAGE       0.25      0.08      0.12        26
     PISTOL       0.00      0.00      0.00        12
     SHADOW       0.00      0.00      0.00        43
    SILENCE       0.15      0.35      0.21        57
       WART       0.00      0.00      0.00        43

avg / total       0.09      0.17      0.11       460

=========================================================================================================

=========================================================================================================
Speaker: PRINCE HUMPHREY
Number of Total Listeners: 29

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 92 total
F1 mean: 0.21 (+/- 0.09)

             precision    recall  f1-score   support

   CLARENCE       0.35      0.80      0.48        10
       KING       0.33      0.22      0.27         9
    WARWICK       0.00      0.00      0.00        10

avg / total       0.22      0.34      0.25        29

=========================================================================================================

=========================================================================================================
Speaker: HOSTESS
Number of Total Listeners: 279

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
284 features selected out of 568 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        28
CHIEF JUSTICE       0.00      0.00      0.00        10
       DOLL       0.19      0.53      0.28        30
   FALSTAFF       0.14      0.54      0.22        35
       FANG       0.00      0.00      0.00        19
    FRANCIS       0.15      0.09      0.11        23
      GOWER       0.00      0.00      0.00         5
       PAGE       0.14      0.07      0.10        28
     PISTOL       0.00      0.00      0.00        16
      POINS       0.00      0.00      0.00         8
     PRINCE       0.00      0.00      0.00         8
SECOND DRAWER       0.25      0.08      0.12        25
      SNARE       0.39      0.37      0.38        19
THIRD DRAWER       0.00      0.00      0.00        25

avg / total       0.11      0.17      0.11       279

=========================================================================================================

=========================================================================================================
Speaker: DOLL
Number of Total Listeners: 200

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
169 features selected out of 339 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        18
   FALSTAFF       0.12      0.04      0.06        25
FIRST BEADLE       0.00      0.00      0.00         5
    FRANCIS       0.00      0.00      0.00        21
    HOSTESS       0.16      0.97      0.27        31
       PAGE       0.00      0.00      0.00        18
     PISTOL       0.00      0.00      0.00        18
      POINS       0.00      0.00      0.00         6
     PRINCE       0.00      0.00      0.00         6
SECOND DRAWER       0.00      0.00      0.00        26
THIRD DRAWER       0.00      0.00      0.00        26

avg / total       0.04      0.15      0.05       200

=========================================================================================================

=========================================================================================================
Speaker: SERVANT
Number of Total Listeners: 21

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
31 features selected out of 62 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

CHIEF JUSTICE       0.33      1.00      0.50         7
   FALSTAFF       0.00      0.00      0.00         7
       PAGE       0.00      0.00      0.00         7

avg / total       0.11      0.33      0.17        21

=========================================================================================================

=========================================================================================================
Speaker: PRINCE JOHN
Number of Total Listeners: 82

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
167 features selected out of 334 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

 ARCHBISHOP       0.33      0.12      0.18         8
CHIEF JUSTICE       0.00      0.00      0.00         7
   CLARENCE       0.00      0.00      0.00         5
   COLVILLE       0.00      0.00      0.00         9
   FALSTAFF       0.50      0.25      0.33        12
   HASTINGS       0.00      0.00      0.00         8
    MOWBRAY       0.25      0.12      0.17         8
    WARWICK       0.00      0.00      0.00         5
WESTMORELAND       0.28      0.95      0.43        20

avg / total       0.20      0.29      0.19        82

=========================================================================================================

=========================================================================================================
Speaker: WARWICK
Number of Total Listeners: 58

Best model LogisticRegression(C=0.59999999999999998, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
165 features selected out of 331 total
F1 mean: 0.03 (+/- 0.06)

             precision    recall  f1-score   support

CHIEF JUSTICE       0.67      0.67      0.67         6
   CLARENCE       0.33      0.19      0.24        16
       KING       0.42      0.95      0.58        19
PRINCE HUMPHREY       0.00      0.00      0.00        12
WESTMORELAND       0.00      0.00      0.00         5

avg / total       0.30      0.43      0.33        58

=========================================================================================================

=========================================================================================================
Speaker: DAVY
Number of Total Listeners: 61

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
83 features selected out of 167 total
F1 mean: 0.07 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        14
   FALSTAFF       0.23      1.00      0.37        14
       PAGE       0.00      0.00      0.00        14
    SHALLOW       0.00      0.00      0.00        14
    SILENCE       0.00      0.00      0.00         5

avg / total       0.05      0.23      0.09        61

=========================================================================================================

=========================================================================================================
Speaker: FALSTAFF
Number of Total Listeners: 1106

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
711 features selected out of 1422 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.13      0.80      0.23       132
   BULLCALF       0.00      0.00      0.00        42
CHIEF JUSTICE       0.23      0.13      0.16        54
   COLVILLE       0.54      0.54      0.54        13
       DAVY       0.00      0.00      0.00        14
       DOLL       0.00      0.00      0.00        44
       FANG       0.00      0.00      0.00        21
     FEEBLE       0.00      0.00      0.00        42
    FRANCIS       0.00      0.00      0.00        40
      GOWER       0.00      0.00      0.00        13
    HOSTESS       0.23      0.09      0.13        65
     MOULDY       0.00      0.00      0.00        42
       PAGE       0.20      0.41      0.27       107
     PISTOL       0.00      0.00      0.00        57
      POINS       0.00      0.00      0.00        20
     PRINCE       0.00      0.00      0.00        28
PRINCE JOHN       0.00      0.00      0.00        10
SECOND DRAWER       0.00      0.00      0.00        44
    SERVANT       0.33      0.04      0.06        28
     SHADOW       0.00      0.00      0.00        42
    SHALLOW       0.17      0.07      0.10        75
    SILENCE       0.00      0.00      0.00        57
      SNARE       0.00      0.00      0.00        21
THIRD DRAWER       0.00      0.00      0.00        44
       WART       0.00      0.00      0.00        42
WESTMORELAND       0.00      0.00      0.00         9

avg / total       0.09      0.16      0.08      1106

=========================================================================================================

=========================================================================================================
Speaker: FEEBLE
Number of Total Listeners: 56

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
35 features selected out of 70 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

   BARDOLPH       0.12      1.00      0.22         7
   BULLCALF       0.00      0.00      0.00         7
   FALSTAFF       0.00      0.00      0.00         7
     MOULDY       0.00      0.00      0.00         7
     SHADOW       0.00      0.00      0.00         7
    SHALLOW       0.00      0.00      0.00         7
    SILENCE       0.00      0.00      0.00         7
       WART       0.00      0.00      0.00         7

avg / total       0.02      0.12      0.03        56

=========================================================================================================

=========================================================================================================
Speaker: POINS
Number of Total Listeners: 102

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
139 features selected out of 278 total
F1 mean: 0.04 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        16
       DOLL       0.00      0.00      0.00         6
   FALSTAFF       0.00      0.00      0.00         6
    FRANCIS       0.00      0.00      0.00         6
    HOSTESS       0.00      0.00      0.00         6
       PAGE       0.00      0.00      0.00        16
     PISTOL       0.00      0.00      0.00         6
     PRINCE       0.27      1.00      0.43        28
SECOND DRAWER       0.00      0.00      0.00         6
THIRD DRAWER       0.00      0.00      0.00         6

avg / total       0.08      0.27      0.12       102

=========================================================================================================

=========================================================================================================
Speaker: CHIEF JUSTICE
Number of Total Listeners: 239

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
246 features selected out of 493 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        21
   CLARENCE       0.00      0.00      0.00         6
   FALSTAFF       0.21      0.98      0.34        46
       FANG       0.00      0.00      0.00        16
      GOWER       0.00      0.00      0.00         9
    HOSTESS       0.00      0.00      0.00        16
       PAGE       0.17      0.02      0.04        41
     PISTOL       0.00      0.00      0.00         5
     PRINCE       0.00      0.00      0.00         8
PRINCE JOHN       0.00      0.00      0.00         9
    SERVANT       0.00      0.00      0.00        25
    SHALLOW       0.00      0.00      0.00         5
      SNARE       0.00      0.00      0.00        16
    WARWICK       0.36      0.40      0.38        10
WESTMORELAND       0.20      0.17      0.18         6

avg / total       0.09      0.21      0.09       239

=========================================================================================================

=========================================================================================================
Speaker: MOWBRAY
Number of Total Listeners: 50

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
134 features selected out of 268 total
F1 mean: 0.13 (+/- 0.05)

             precision    recall  f1-score   support

 ARCHBISHOP       0.36      0.94      0.52        18
   HASTINGS       0.33      0.06      0.10        17
PRINCE JOHN       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00        10

avg / total       0.24      0.36      0.22        50

=========================================================================================================

=========================================================================================================
Speaker: NORTHUMBERLAND
Number of Total Listeners: 29

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
198 features selected out of 396 total
F1 mean: 0.10 (+/- 0.18)

             precision    recall  f1-score   support

LORD BARDOLPH       0.48      0.85      0.61        13
     MORTON       0.33      0.33      0.33         6
    TRAVERS       0.00      0.00      0.00        10

avg / total       0.28      0.45      0.34        29

=========================================================================================================

=========================================================================================================
Speaker: MOULDY
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
35 features selected out of 71 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

   BARDOLPH       0.12      1.00      0.22         5
   BULLCALF       0.00      0.00      0.00         5
   FALSTAFF       0.00      0.00      0.00         5
     FEEBLE       0.00      0.00      0.00         5
     SHADOW       0.00      0.00      0.00         5
    SHALLOW       0.00      0.00      0.00         5
    SILENCE       0.00      0.00      0.00         5
       WART       0.00      0.00      0.00         5

avg / total       0.02      0.12      0.03        40

=========================================================================================================

=========================================================================================================
Speaker: WESTMORELAND
Number of Total Listeners: 62

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
203 features selected out of 406 total
F1 mean: 0.12 (+/- 0.16)

             precision    recall  f1-score   support

 ARCHBISHOP       0.30      0.17      0.21        18
   HASTINGS       0.31      0.28      0.29        18
    MOWBRAY       0.29      0.56      0.38        18
PRINCE JOHN       1.00      0.12      0.22         8

avg / total       0.39      0.31      0.29        62

=========================================================================================================

=========================================================================================================
Speaker: HASTINGS
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
130 features selected out of 261 total
F1 mean: 0.19 (+/- 0.14)

             precision    recall  f1-score   support

 ARCHBISHOP       0.38      0.29      0.33        17
LORD BARDOLPH       0.00      0.00      0.00         8
    MOWBRAY       0.41      0.71      0.52        17

avg / total       0.32      0.40      0.35        42

=========================================================================================================

=========================================================================================================
Speaker: CLARENCE
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
65 features selected out of 130 total
F1 mean: 0.14 (+/- 0.05)

             precision    recall  f1-score   support

       KING       0.00      0.00      0.00        12
PRINCE HUMPHREY       0.00      0.00      0.00        11
    WARWICK       0.36      1.00      0.53        13

avg / total       0.13      0.36      0.19        36

=========================================================================================================

=========================================================================================================
Speaker: KING
Number of Total Listeners: 88

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
440 features selected out of 880 total
F1 mean: 0.10 (+/- 0.03)

             precision    recall  f1-score   support

   CLARENCE       0.25      0.04      0.07        26
     PRINCE       0.00      0.00      0.00         6
PRINCE HUMPHREY       0.00      0.00      0.00        24
    WARWICK       0.37      0.97      0.53        32

avg / total       0.21      0.36      0.21        88

=========================================================================================================

=========================================================================================================
Speaker: BULLCALF
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
38 features selected out of 76 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

   BARDOLPH       0.12      1.00      0.22         5
   FALSTAFF       0.00      0.00      0.00         5
     FEEBLE       0.00      0.00      0.00         5
     MOULDY       0.00      0.00      0.00         5
     SHADOW       0.00      0.00      0.00         5
    SHALLOW       0.00      0.00      0.00         5
    SILENCE       0.00      0.00      0.00         5
       WART       0.00      0.00      0.00         5

avg / total       0.02      0.12      0.03        40

=========================================================================================================

=========================================================================================================
Speaker: PRINCE
Number of Total Listeners: 271

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
459 features selected out of 918 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.15      0.11      0.13        35
CHIEF JUSTICE       0.22      0.33      0.27         6
   CLARENCE       0.20      0.15      0.17        13
       DOLL       0.00      0.00      0.00        14
   FALSTAFF       0.00      0.00      0.00        16
    FRANCIS       0.00      0.00      0.00        14
    HOSTESS       0.00      0.00      0.00        14
       KING       0.00      0.00      0.00         9
       PAGE       0.00      0.00      0.00        33
     PISTOL       0.00      0.00      0.00        16
      POINS       0.20      0.95      0.33        44
PRINCE HUMPHREY       0.22      0.18      0.20        11
PRINCE JOHN       0.00      0.00      0.00         5
SECOND DRAWER       0.00      0.00      0.00        14
THIRD DRAWER       0.00      0.00      0.00        14
    WARWICK       0.25      0.15      0.19        13

avg / total       0.09      0.20      0.10       271

=========================================================================================================

=========================================================================================================
Speaker: SILENCE
Number of Total Listeners: 125

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
54 features selected out of 109 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        13
   BULLCALF       0.00      0.00      0.00        12
       DAVY       0.00      0.00      0.00         8
   FALSTAFF       0.00      0.00      0.00        12
     FEEBLE       0.00      0.00      0.00        12
     MOULDY       0.00      0.00      0.00        12
       PAGE       0.20      0.10      0.13        10
     SHADOW       0.00      0.00      0.00        12
    SHALLOW       0.17      0.95      0.30        22
       WART       0.00      0.00      0.00        12

avg / total       0.05      0.18      0.06       125

=========================================================================================================

=========================================================================================================
Speaker: PISTOL
Number of Total Listeners: 193

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
163 features selected out of 326 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

   BARDOLPH       0.15      0.17      0.16        30
       DAVY       0.00      0.00      0.00        12
       DOLL       0.00      0.00      0.00        13
   FALSTAFF       0.17      0.74      0.27        31
    FRANCIS       0.00      0.00      0.00        13
    HOSTESS       0.00      0.00      0.00        13
       PAGE       0.14      0.08      0.10        25
SECOND DRAWER       0.00      0.00      0.00        13
    SHALLOW       0.00      0.00      0.00        18
    SILENCE       0.00      0.00      0.00        12
THIRD DRAWER       0.12      0.08      0.10        13

avg / total       0.08      0.16      0.09       193

=========================================================================================================

=========================================================================================================
Speaker: BARDOLPH
Number of Total Listeners: 175

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
90 features selected out of 181 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

   BULLCALF       0.14      0.11      0.12         9
       DOLL       0.00      0.00      0.00         7
   FALSTAFF       0.15      0.33      0.20        18
     FEEBLE       0.00      0.00      0.00         9
    FRANCIS       0.00      0.00      0.00         7
    HOSTESS       0.00      0.00      0.00         7
     MOULDY       0.00      0.00      0.00         9
       PAGE       0.19      0.95      0.32        20
     PISTOL       0.00      0.00      0.00         8
      POINS       0.00      0.00      0.00        11
     PRINCE       0.00      0.00      0.00        11
SECOND DRAWER       0.00      0.00      0.00         7
     SHADOW       0.00      0.00      0.00         9
    SHALLOW       0.14      0.21      0.17        14
    SILENCE       0.14      0.08      0.10        13
THIRD DRAWER       0.00      0.00      0.00         7
       WART       0.00      0.00      0.00         9

avg / total       0.07      0.17      0.08       175

=========================================================================================================

=========================================================================================================
Speaker: ARCHBISHOP
Number of Total Listeners: 72

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
271 features selected out of 542 total
F1 mean: 0.13 (+/- 0.07)

             precision    recall  f1-score   support

   HASTINGS       0.42      0.21      0.28        24
    MOWBRAY       0.32      0.79      0.46        24
PRINCE JOHN       1.00      0.11      0.20         9
WESTMORELAND       0.00      0.00      0.00        15

avg / total       0.37      0.35      0.27        72

=========================================================================================================

=========================================================================================================
Speaker: LORD BARDOLPH
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
181 features selected out of 363 total
F1 mean: 0.07 (+/- 0.03)

             precision    recall  f1-score   support

 ARCHBISHOP       0.33      0.17      0.22         6
   HASTINGS       0.33      0.67      0.44         6
    MOWBRAY       0.33      0.17      0.22         6
NORTHUMBERLAND       0.62      1.00      0.77        10
    TRAVERS       0.00      0.00      0.00         6

avg / total       0.36      0.47      0.38        34

=========================================================================================================

=========================================================================================================
Speaker: PAGE
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
72 features selected out of 145 total
F1 mean: 0.23 (+/- 0.17)

             precision    recall  f1-score   support

   BARDOLPH       0.35      0.70      0.47        10
   FALSTAFF       0.82      0.90      0.86        10
      POINS       0.33      0.14      0.20         7
     PRINCE       0.00      0.00      0.00         7

avg / total       0.41      0.50      0.43        34

=========================================================================================================

Play: 9

=========================================================================================================
Speaker: FRENCH SOLDIER
Number of Total Listeners: 20

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
35 features selected out of 70 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

        BOY       0.50      1.00      0.67        10
     PISTOL       0.00      0.00      0.00        10

avg / total       0.25      0.50      0.33        20

=========================================================================================================

=========================================================================================================
Speaker: HOSTESS
Number of Total Listeners: 41

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
110 features selected out of 221 total
F1 mean: 0.07 (+/- 0.07)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        11
        BOY       0.00      0.00      0.00         8
        NYM       0.27      1.00      0.42        11
     PISTOL       0.00      0.00      0.00        11

avg / total       0.07      0.27      0.11        41

=========================================================================================================

=========================================================================================================
Speaker: BOY
Number of Total Listeners: 44

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
147 features selected out of 294 total
F1 mean: 0.04 (+/- 0.07)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00         8
FRENCH SOLDIER       0.00      0.00      0.00         8
    HOSTESS       0.00      0.00      0.00         5
        NYM       0.00      0.00      0.00         8
     PISTOL       0.34      1.00      0.51        15

avg / total       0.12      0.34      0.17        44

=========================================================================================================

=========================================================================================================
Speaker: QUEEN ISABEL
Number of Total Listeners: 55

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 132 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

      ALICE       0.09      1.00      0.17         5
    BEDFORD       0.00      0.00      0.00         5
   BURGUNDY       0.00      0.00      0.00         5
     EXETER       0.00      0.00      0.00         5
FRENCH KING       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         5
  KATHERINE       0.00      0.00      0.00         5
 KING HENRY       0.00      0.00      0.00         5
      LORDS       0.00      0.00      0.00         5
    WARWICK       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00         5

avg / total       0.01      0.09      0.02        55

=========================================================================================================

=========================================================================================================
Speaker: BURGUNDY
Number of Total Listeners: 88

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
155 features selected out of 310 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

      ALICE       0.09      1.00      0.17         8
    BEDFORD       0.00      0.00      0.00         8
     EXETER       0.00      0.00      0.00         8
FRENCH KING       0.00      0.00      0.00         8
 GLOUCESTER       0.00      0.00      0.00         8
  KATHERINE       0.00      0.00      0.00         8
 KING HENRY       0.00      0.00      0.00         8
      LORDS       0.00      0.00      0.00         8
QUEEN ISABEL       0.00      0.00      0.00         8
    WARWICK       0.00      0.00      0.00         8
WESTMORELAND       0.00      0.00      0.00         8

avg / total       0.01      0.09      0.02        88

=========================================================================================================

=========================================================================================================
Speaker: NYM
Number of Total Listeners: 53

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
92 features selected out of 185 total
F1 mean: 0.10 (+/- 0.07)

             precision    recall  f1-score   support

   BARDOLPH       0.40      0.86      0.55        21
        BOY       0.00      0.00      0.00         5
    HOSTESS       0.00      0.00      0.00        10
     PISTOL       0.38      0.18      0.24        17

avg / total       0.28      0.40      0.29        53

=========================================================================================================

=========================================================================================================
Speaker: FLUELLEN
Number of Total Listeners: 232

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
359 features selected out of 719 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        10
     EXETER       0.00      0.00      0.00        17
 GLOUCESTER       0.00      0.00      0.00        23
      GOWER       0.29      0.99      0.45        67
       JAMY       0.00      0.00      0.00         6
 KING HENRY       0.00      0.00      0.00        22
  MACMORRIS       0.00      0.00      0.00         6
    MONTJOY       0.00      0.00      0.00        10
        NYM       0.00      0.00      0.00        10
     PISTOL       0.40      0.07      0.12        27
    WARWICK       0.00      0.00      0.00        18
   WILLIAMS       0.00      0.00      0.00        16

avg / total       0.13      0.29      0.14       232

=========================================================================================================

=========================================================================================================
Speaker: DAUPHIN
Number of Total Listeners: 90

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
241 features selected out of 483 total
F1 mean: 0.05 (+/- 0.08)

             precision    recall  f1-score   support

   BRITAINE       0.00      0.00      0.00         8
  CONSTABLE       0.33      0.64      0.44        28
FRENCH KING       0.00      0.00      0.00         8
    ORLEANS       0.00      0.00      0.00        23
   RAMBURES       0.36      0.57      0.44        23

avg / total       0.20      0.34      0.25        90

=========================================================================================================

=========================================================================================================
Speaker: SCROOP
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
37 features selected out of 74 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

    BEDFORD       0.17      1.00      0.29         5
  CAMBRIDGE       0.00      0.00      0.00         5
     EXETER       0.00      0.00      0.00         5
       GREY       0.00      0.00      0.00         5
 KING HENRY       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        30

=========================================================================================================

=========================================================================================================
Speaker: CANTERBURY
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
266 features selected out of 533 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

    BEDFORD       0.17      1.00      0.29         7
     EXETER       0.00      0.00      0.00         7
 GLOUCESTER       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         7
    WARWICK       0.00      0.00      0.00         7
WESTMORELAND       0.00      0.00      0.00         7

avg / total       0.03      0.17      0.05        42

=========================================================================================================

=========================================================================================================
Speaker: PISTOL
Number of Total Listeners: 165

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
264 features selected out of 529 total
F1 mean: 0.04 (+/- 0.05)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00        21
    BEDFORD       0.25      0.91      0.39        11
        BOY       0.50      0.60      0.55        20
  ERPINGHAM       0.00      0.00      0.00        11
   FLUELLEN       0.46      0.61      0.52        18
FRENCH SOLDIER       0.50      0.08      0.13        13
 GLOUCESTER       0.00      0.00      0.00        11
      GOWER       0.38      0.38      0.38        16
    HOSTESS       0.30      0.25      0.27        12
 KING HENRY       0.00      0.00      0.00        11
        NYM       0.35      0.81      0.49        21

avg / total       0.27      0.36      0.28       165

=========================================================================================================

=========================================================================================================
Speaker: WESTMORELAND
Number of Total Listeners: 33

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
73 features selected out of 146 total
F1 mean: 0.09 (+/- 0.11)

             precision    recall  f1-score   support

    BEDFORD       0.00      0.00      0.00         9
     EXETER       0.28      0.89      0.42         9
 GLOUCESTER       0.00      0.00      0.00         8
 KING HENRY       0.25      0.14      0.18         7

avg / total       0.13      0.27      0.15        33

=========================================================================================================

=========================================================================================================
Speaker: BATES
Number of Total Listeners: 56

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
52 features selected out of 104 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

    BEDFORD       0.12      1.00      0.22         7
      COURT       0.00      0.00      0.00         7
  ERPINGHAM       0.00      0.00      0.00         7
   FLUELLEN       0.00      0.00      0.00         7
 GLOUCESTER       0.00      0.00      0.00         7
      GOWER       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         7
   WILLIAMS       0.00      0.00      0.00         7

avg / total       0.02      0.12      0.03        56

=========================================================================================================

=========================================================================================================
Speaker: FRENCH KING
Number of Total Listeners: 129

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
197 features selected out of 394 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

      ALICE       0.00      0.00      0.00         7
    BEDFORD       0.00      0.00      0.00         7
   BRITAINE       0.00      0.00      0.00        12
   BURGUNDY       0.00      0.00      0.00         7
  CONSTABLE       0.00      0.00      0.00        12
    DAUPHIN       0.26      0.75      0.39        12
     EXETER       0.00      0.00      0.00        12
 GLOUCESTER       0.00      0.00      0.00         7
  KATHERINE       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         7
      LORDS       0.11      0.83      0.19        12
  MESSENGER       0.00      0.00      0.00         6
QUEEN ISABEL       0.00      0.00      0.00         7
    WARWICK       0.00      0.00      0.00         7
WESTMORELAND       0.00      0.00      0.00         7

avg / total       0.03      0.15      0.05       129

=========================================================================================================

=========================================================================================================
Speaker: CONSTABLE
Number of Total Listeners: 105

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
232 features selected out of 465 total
F1 mean: 0.13 (+/- 0.09)

             precision    recall  f1-score   support

    DAUPHIN       0.50      0.24      0.32        25
  MESSENGER       0.00      0.00      0.00         8
    ORLEANS       0.37      0.94      0.53        36
   RAMBURES       0.00      0.00      0.00        36

avg / total       0.24      0.38      0.26       105

=========================================================================================================

=========================================================================================================
Speaker: ALICE
Number of Total Listeners: 72

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
54 features selected out of 108 total
F1 mean: 0.04 (+/- 0.00)

             precision    recall  f1-score   support

    BEDFORD       0.00      0.00      0.00         5
   BURGUNDY       0.00      0.00      0.00         5
     EXETER       0.00      0.00      0.00         5
FRENCH KING       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         5
  KATHERINE       0.31      1.00      0.47        22
 KING HENRY       0.00      0.00      0.00         5
      LORDS       0.00      0.00      0.00         5
QUEEN ISABEL       0.00      0.00      0.00         5
    WARWICK       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00         5

avg / total       0.09      0.31      0.14        72

=========================================================================================================

=========================================================================================================
Speaker: EXETER
Number of Total Listeners: 89

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
259 features selected out of 518 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

    BEDFORD       0.33      0.09      0.14        11
   BRITAINE       0.00      0.00      0.00         5
  CONSTABLE       0.00      0.00      0.00         5
    DAUPHIN       0.00      0.00      0.00         5
FRENCH KING       0.17      0.17      0.17         6
 GLOUCESTER       0.25      0.67      0.36        12
 KING HENRY       0.30      0.46      0.36        13
      LORDS       0.17      0.67      0.27         6
  MESSENGER       0.00      0.00      0.00         5
    WARWICK       0.00      0.00      0.00        10
WESTMORELAND       0.50      0.18      0.27        11

avg / total       0.20      0.25      0.18        89

=========================================================================================================

=========================================================================================================
Speaker: KING HENRY
Number of Total Listeners: 1039

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
1078 features selected out of 2156 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

      ALICE       0.00      0.00      0.00        38
      BATES       0.00      0.00      0.00        19
    BEDFORD       0.12      0.16      0.13       103
   BURGUNDY       0.00      0.00      0.00        38
  CAMBRIDGE       0.00      0.00      0.00         9
 CANTERBURY       0.00      0.00      0.00         9
      COURT       0.00      0.00      0.00        19
        ELY       0.00      0.00      0.00         7
  ERPINGHAM       0.00      0.00      0.00        40
     EXETER       0.16      0.20      0.17       102
   FLUELLEN       0.00      0.00      0.00        58
FRENCH KING       0.00      0.00      0.00        38
 GLOUCESTER       0.14      0.79      0.24       133
      GOWER       0.14      0.03      0.05        59
       GREY       0.00      0.00      0.00         9
     HERALD       0.00      0.00      0.00         6
  KATHERINE       0.00      0.00      0.00        38
      LORDS       0.00      0.00      0.00        38
    MONTJOY       0.00      0.00      0.00        25
     PISTOL       0.00      0.00      0.00        10
QUEEN ISABEL       0.09      0.03      0.04        38
  SALISBURY       0.00      0.00      0.00         8
     SCROOP       0.00      0.00      0.00         9
    WARWICK       0.00      0.00      0.00        81
WESTMORELAND       0.17      0.01      0.03        67
   WILLIAMS       0.00      0.00      0.00        38

avg / total       0.07      0.14      0.07      1039

=========================================================================================================

=========================================================================================================
Speaker: CAMBRIDGE
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
40 features selected out of 80 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

    BEDFORD       0.17      1.00      0.29         5
     EXETER       0.00      0.00      0.00         5
       GREY       0.00      0.00      0.00         5
 KING HENRY       0.00      0.00      0.00         5
     SCROOP       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        30

=========================================================================================================

=========================================================================================================
Speaker: BARDOLPH
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 132 total
F1 mean: 0.08 (+/- 0.10)

             precision    recall  f1-score   support

        BOY       0.00      0.00      0.00         6
    HOSTESS       0.00      0.00      0.00         8
        NYM       0.38      1.00      0.55        16
     PISTOL       0.00      0.00      0.00        12

avg / total       0.15      0.38      0.21        42

=========================================================================================================

=========================================================================================================
Speaker: ORLEANS
Number of Total Listeners: 73

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
102 features selected out of 204 total
F1 mean: 0.12 (+/- 0.07)

             precision    recall  f1-score   support

  CONSTABLE       0.33      0.04      0.07        26
    DAUPHIN       0.00      0.00      0.00        13
  MESSENGER       0.00      0.00      0.00         5
   RAMBURES       0.40      0.97      0.57        29

avg / total       0.28      0.40      0.25        73

=========================================================================================================

=========================================================================================================
Speaker: KATHERINE
Number of Total Listeners: 183

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
112 features selected out of 224 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

      ALICE       0.18      1.00      0.31        33
    BEDFORD       0.00      0.00      0.00        15
   BURGUNDY       0.00      0.00      0.00        15
     EXETER       0.00      0.00      0.00        15
FRENCH KING       0.00      0.00      0.00        15
 GLOUCESTER       0.00      0.00      0.00        15
 KING HENRY       0.00      0.00      0.00        15
      LORDS       0.00      0.00      0.00        15
QUEEN ISABEL       0.00      0.00      0.00        15
    WARWICK       0.00      0.00      0.00        15
WESTMORELAND       0.00      0.00      0.00        15

avg / total       0.03      0.18      0.06       183

=========================================================================================================

=========================================================================================================
Speaker: MONTJOY
Number of Total Listeners: 44

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
126 features selected out of 253 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

     EXETER       0.00      0.00      0.00         6
   FLUELLEN       0.00      0.00      0.00         8
 GLOUCESTER       0.25      1.00      0.40        11
      GOWER       0.00      0.00      0.00         8
 KING HENRY       0.00      0.00      0.00        11

avg / total       0.06      0.25      0.10        44

=========================================================================================================

=========================================================================================================
Speaker: GOWER
Number of Total Listeners: 50

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
141 features selected out of 282 total
F1 mean: 0.17 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00         7
   FLUELLEN       0.52      1.00      0.68        26
        NYM       0.00      0.00      0.00         7
     PISTOL       0.00      0.00      0.00        10

avg / total       0.27      0.52      0.36        50

=========================================================================================================

=========================================================================================================
Speaker: WILLIAMS
Number of Total Listeners: 180

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
148 features selected out of 296 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

      BATES       0.00      0.00      0.00        14
    BEDFORD       0.00      0.00      0.00        14
      COURT       0.00      0.00      0.00        14
  ERPINGHAM       0.00      0.00      0.00        14
     EXETER       0.00      0.00      0.00         9
   FLUELLEN       0.15      0.11      0.13        27
 GLOUCESTER       0.00      0.00      0.00        23
      GOWER       0.16      0.82      0.27        28
 KING HENRY       0.12      0.09      0.10        23
    MONTJOY       0.00      0.00      0.00         5
    WARWICK       0.00      0.00      0.00         9

avg / total       0.06      0.16      0.07       180

=========================================================================================================

Play: 10

=========================================================================================================
Speaker: BASSET
Number of Total Listeners: 56

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
67 features selected out of 134 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

     EXETER       0.12      1.00      0.22         7
 GLOUCESTER       0.00      0.00      0.00         7
       KING       0.00      0.00      0.00         7
   SOMERSET       0.00      0.00      0.00         7
    SUFFOLK       0.00      0.00      0.00         7
     VERNON       0.00      0.00      0.00         7
    WARWICK       0.00      0.00      0.00         7
 WINCHESTER       0.00      0.00      0.00         7

avg / total       0.02      0.12      0.03        56

=========================================================================================================

=========================================================================================================
Speaker: BEDFORD
Number of Total Listeners: 61

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
183 features selected out of 367 total
F1 mean: 0.09 (+/- 0.02)

             precision    recall  f1-score   support

   BURGUNDY       0.00      0.00      0.00        11
     EXETER       0.00      0.00      0.00         8
 GLOUCESTER       0.20      0.25      0.22         8
  MESSENGER       0.20      0.29      0.24         7
     TALBOT       0.48      1.00      0.65        11
    WARWICK       0.22      0.50      0.31         8
 WINCHESTER       0.00      0.00      0.00         8

avg / total       0.16      0.31      0.21        61

=========================================================================================================

=========================================================================================================
Speaker: BASTARD
Number of Total Listeners: 49

Best model LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=200, multi_class='multinomial',
          penalty='l1', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=1)
92 features selected out of 185 total
F1 mean: 0.02 (+/- 0.05)

             precision    recall  f1-score   support

    ALENCON       0.24      0.92      0.38        12
   BURGUNDY       0.00      0.00      0.00         7
    CHARLES       0.33      0.10      0.15        10
    PUCELLE       0.00      0.00      0.00         6
   REIGNIER       0.00      0.00      0.00         8
     TALBOT       0.00      0.00      0.00         6

avg / total       0.13      0.24      0.12        49

=========================================================================================================

=========================================================================================================
Speaker: ALENCON
Number of Total Listeners: 77

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
132 features selected out of 264 total
F1 mean: 0.04 (+/- 0.06)

             precision    recall  f1-score   support

    BASTARD       0.22      0.13      0.17        15
    BEDFORD       0.00      0.00      0.00         5
   BURGUNDY       0.00      0.00      0.00         7
    CHARLES       0.29      0.38      0.32        16
    PUCELLE       0.00      0.00      0.00        12
   REIGNIER       0.23      0.65      0.34        17
     TALBOT       0.00      0.00      0.00         5

avg / total       0.15      0.25      0.18        77

=========================================================================================================

=========================================================================================================
Speaker: LUCY
Number of Total Listeners: 55

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
136 features selected out of 272 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

    ALENCON       0.00      0.00      0.00         5
    BASTARD       0.00      0.00      0.00         5
   BURGUNDY       0.00      0.00      0.00         5
    CHARLES       0.00      0.00      0.00         5
       JOHN       0.00      0.00      0.00         5
    OFFICER       0.00      0.00      0.00         5
    PUCELLE       0.00      0.00      0.00         5
    SERVANT       0.00      0.00      0.00         5
   SOMERSET       0.00      0.00      0.00         5
     TALBOT       0.18      1.00      0.31        10

avg / total       0.03      0.18      0.06        55

=========================================================================================================

=========================================================================================================
Speaker: TALBOT
Number of Total Listeners: 136

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
508 features selected out of 1017 total
F1 mean: 0.07 (+/- 0.03)

             precision    recall  f1-score   support

    BEDFORD       0.31      0.29      0.30        17
   BURGUNDY       0.34      0.67      0.45        18
    CAPTAIN       0.00      0.00      0.00         7
   COUNTESS       0.00      0.00      0.00         9
     EXETER       0.14      0.40      0.21         5
FIRST SENTINEL       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         5
       JOHN       0.57      1.00      0.72        13
       KING       0.00      0.00      0.00         5
  MESSENGER       0.33      0.77      0.47        13
     PORTER       0.00      0.00      0.00         9
    PUCELLE       1.00      0.20      0.33         5
  SALISBURY       1.00      0.60      0.75         5
   SOMERSET       0.14      0.20      0.17         5
    SUFFOLK       0.14      0.20      0.17         5
    WARWICK       0.00      0.00      0.00         5
 WINCHESTER       0.00      0.00      0.00         5

avg / total       0.26      0.35      0.27       136

=========================================================================================================

=========================================================================================================
Speaker: VERNON
Number of Total Listeners: 82

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
76 features selected out of 153 total
F1 mean: 0.01 (+/- 0.03)

             precision    recall  f1-score   support

     BASSET       0.00      0.00      0.00         8
     EXETER       0.00      0.00      0.00         8
 GLOUCESTER       0.00      0.00      0.00         8
       KING       0.00      0.00      0.00         8
PLANTAGENET       0.00      0.00      0.00         8
   SOMERSET       0.12      0.18      0.14        11
    SUFFOLK       0.00      0.00      0.00        11
    WARWICK       0.15      0.83      0.26        12
 WINCHESTER       0.00      0.00      0.00         8

avg / total       0.04      0.15      0.06        82

=========================================================================================================

=========================================================================================================
Speaker: WARWICK
Number of Total Listeners: 138

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
168 features selected out of 337 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     EXETER       0.00      0.00      0.00        12
FIRST KEEPER       0.00      0.00      0.00        10
 GLOUCESTER       0.00      0.00      0.00        12
       KING       0.00      0.00      0.00        12
   MORTIMER       0.00      0.00      0.00        10
PLANTAGENET       0.17      0.92      0.28        24
    PUCELLE       0.00      0.00      0.00         8
   SOMERSET       0.00      0.00      0.00        15
    SUFFOLK       0.00      0.00      0.00        15
     VERNON       0.33      0.33      0.33         6
 WINCHESTER       0.00      0.00      0.00        14

avg / total       0.04      0.17      0.06       138

=========================================================================================================

=========================================================================================================
Speaker: KING
Number of Total Listeners: 205

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
313 features selected out of 627 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

     BASSET       0.00      0.00      0.00         6
     EXETER       0.12      0.41      0.19        29
   FASTOLFE       0.00      0.00      0.00         9
FIRST KEEPER       0.00      0.00      0.00         9
 GLOUCESTER       0.16      0.55      0.25        29
   MORTIMER       0.00      0.00      0.00         9
PLANTAGENET       0.00      0.00      0.00        18
   SOMERSET       0.00      0.00      0.00        20
    SUFFOLK       0.11      0.04      0.06        23
     TALBOT       0.00      0.00      0.00         7
     VERNON       0.00      0.00      0.00         6
    WARWICK       0.00      0.00      0.00        20
 WINCHESTER       0.00      0.00      0.00        20

avg / total       0.05      0.14      0.07       205

=========================================================================================================

=========================================================================================================
Speaker: PLANTAGENET
Number of Total Listeners: 218

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
344 features selected out of 689 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     BASSET       0.00      0.00      0.00         6
     EXETER       0.00      0.00      0.00         9
   FASTOLFE       0.00      0.00      0.00         6
FIRST KEEPER       0.50      0.20      0.29        10
 GLOUCESTER       0.00      0.00      0.00         9
       KING       0.00      0.00      0.00         9
     LAWYER       0.00      0.00      0.00        17
  MESSENGER       1.00      0.80      0.89         5
   MORTIMER       0.00      0.00      0.00        10
    PUCELLE       0.50      0.24      0.32        17
   SOMERSET       0.00      0.00      0.00        21
    SUFFOLK       0.00      0.00      0.00        23
     VERNON       0.00      0.00      0.00        23
    WARWICK       0.19      0.95      0.31        40
 WINCHESTER       0.00      0.00      0.00        13

avg / total       0.12      0.22      0.12       218

=========================================================================================================

=========================================================================================================
Speaker: CHARLES
Number of Total Listeners: 178

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
264 features selected out of 528 total
F1 mean: 0.04 (+/- 0.05)

             precision    recall  f1-score   support

    ALENCON       0.23      0.66      0.34        41
    BASTARD       0.21      0.31      0.25        35
   BURGUNDY       0.00      0.00      0.00        18
       JOHN       0.00      0.00      0.00         6
    PUCELLE       0.00      0.00      0.00        33
   REIGNIER       0.30      0.10      0.15        29
    SERVANT       0.00      0.00      0.00         6
     TALBOT       0.00      0.00      0.00        10

avg / total       0.14      0.23      0.15       178

=========================================================================================================

=========================================================================================================
Speaker: BURGUNDY
Number of Total Listeners: 52

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
114 features selected out of 228 total
F1 mean: 0.06 (+/- 0.09)

             precision    recall  f1-score   support

    ALENCON       0.25      0.75      0.38         8
    BASTARD       0.00      0.00      0.00         8
    BEDFORD       0.50      0.11      0.18         9
    CHARLES       0.00      0.00      0.00         8
    PUCELLE       0.00      0.00      0.00         8
     TALBOT       0.38      0.91      0.54        11

avg / total       0.21      0.33      0.20        52

=========================================================================================================

=========================================================================================================
Speaker: SOMERSET
Number of Total Listeners: 138

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
148 features selected out of 296 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     EXETER       0.00      0.00      0.00         7
 GLOUCESTER       0.00      0.00      0.00         7
       KING       0.00      0.00      0.00         7
     LAWYER       0.20      0.07      0.11        14
       LUCY       0.33      0.20      0.25         5
    OFFICER       0.40      0.33      0.36         6
PLANTAGENET       0.16      0.95      0.28        21
    SUFFOLK       0.00      0.00      0.00        20
     TALBOT       0.33      0.17      0.22         6
     VERNON       0.00      0.00      0.00        17
    WARWICK       0.00      0.00      0.00        21
 WINCHESTER       0.00      0.00      0.00         7

avg / total       0.09      0.18      0.09       138

=========================================================================================================

=========================================================================================================
Speaker: COUNTESS
Number of Total Listeners: 33

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
110 features selected out of 220 total
F1 mean: 0.10 (+/- 0.12)

             precision    recall  f1-score   support

  MESSENGER       0.00      0.00      0.00        11
     PORTER       0.39      1.00      0.57        13
     TALBOT       0.00      0.00      0.00         9

avg / total       0.16      0.39      0.22        33

=========================================================================================================

=========================================================================================================
Speaker: EXETER
Number of Total Listeners: 43

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
150 features selected out of 301 total
F1 mean: 0.02 (+/- 0.04)

             precision    recall  f1-score   support

    BEDFORD       0.00      0.00      0.00         5
 GLOUCESTER       0.25      0.90      0.39        10
       KING       0.00      0.00      0.00         5
  MESSENGER       0.00      0.00      0.00         5
    WARWICK       0.29      0.22      0.25         9
 WINCHESTER       0.00      0.00      0.00         9

avg / total       0.12      0.26      0.14        43

=========================================================================================================

=========================================================================================================
Speaker: GLOUCESTER
Number of Total Listeners: 282

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
340 features selected out of 681 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

    BEDFORD       0.00      0.00      0.00         5
     EXETER       0.16      0.56      0.25        34
   FASTOLFE       0.00      0.00      0.00         5
FIRST KEEPER       0.00      0.00      0.00        12
FIRST SERVING MAN       0.33      0.31      0.32        13
FIRST WARDER       0.00      0.00      0.00        12
       KING       0.18      0.07      0.11        27
      MAYOR       0.00      0.00      0.00         8
   MORTIMER       0.00      0.00      0.00        12
PLANTAGENET       0.00      0.00      0.00        19
SECOND WARDER       0.00      0.00      0.00        12
   SOMERSET       0.00      0.00      0.00        20
    SUFFOLK       0.33      0.04      0.07        24
     TALBOT       0.00      0.00      0.00         7
    WARWICK       0.00      0.00      0.00        26
 WINCHESTER       0.16      0.60      0.25        35
  WOODVILLE       0.00      0.00      0.00        11

avg / total       0.10      0.17      0.09       282

=========================================================================================================

=========================================================================================================
Speaker: REIGNIER
Number of Total Listeners: 78

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
132 features selected out of 264 total
F1 mean: 0.01 (+/- 0.03)

             precision    recall  f1-score   support

    ALENCON       0.35      0.57      0.43        14
    BASTARD       0.00      0.00      0.00        10
    CHARLES       0.00      0.00      0.00        12
   MARGARET       0.00      0.00      0.00         8
PLANTAGENET       0.00      0.00      0.00         9
    PUCELLE       0.25      0.82      0.39        17
    SUFFOLK       0.00      0.00      0.00         8

avg / total       0.12      0.28      0.16        78

=========================================================================================================

=========================================================================================================
Speaker: PUCELLE
Number of Total Listeners: 161

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
400 features selected out of 801 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

    ALENCON       0.20      0.87      0.33        30
    BASTARD       0.25      0.14      0.18        29
    BEDFORD       0.00      0.00      0.00         7
   BURGUNDY       0.00      0.00      0.00        17
    CHARLES       0.00      0.00      0.00        30
PLANTAGENET       0.60      0.90      0.72        10
   REIGNIER       0.00      0.00      0.00        19
     TALBOT       1.00      0.08      0.15        12
    WARWICK       0.50      0.14      0.22         7

avg / total       0.22      0.25      0.16       161

=========================================================================================================

=========================================================================================================
Speaker: WINCHESTER
Number of Total Listeners: 153

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
193 features selected out of 386 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     EXETER       0.00      0.00      0.00        15
FIRST KEEPER       0.00      0.00      0.00         9
FIRST SERVING MAN       0.00      0.00      0.00         8
FIRST WARDER       0.00      0.00      0.00         8
 GLOUCESTER       0.16      0.87      0.27        23
       KING       0.00      0.00      0.00        12
      MAYOR       0.00      0.00      0.00         5
   MORTIMER       0.00      0.00      0.00         9
PLANTAGENET       0.00      0.00      0.00        12
SECOND WARDER       0.00      0.00      0.00         8
   SOMERSET       0.00      0.00      0.00        10
    SUFFOLK       0.00      0.00      0.00        10
    WARWICK       0.22      0.38      0.28        16
  WOODVILLE       0.00      0.00      0.00         8

avg / total       0.05      0.17      0.07       153

=========================================================================================================

=========================================================================================================
Speaker: MARGARET
Number of Total Listeners: 66

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
81 features selected out of 163 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

PLANTAGENET       0.33      1.00      0.50        22
    PUCELLE       0.00      0.00      0.00        22
    SUFFOLK       0.00      0.00      0.00        22

avg / total       0.11      0.33      0.17        66

=========================================================================================================

=========================================================================================================
Speaker: SUFFOLK
Number of Total Listeners: 135

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
303 features selected out of 606 total
F1 mean: 0.06 (+/- 0.06)

             precision    recall  f1-score   support

     EXETER       0.50      0.60      0.55         5
 GLOUCESTER       0.50      0.40      0.44         5
     LAWYER       0.00      0.00      0.00         6
   MARGARET       0.25      0.07      0.11        30
PLANTAGENET       0.29      0.92      0.44        36
    PUCELLE       0.33      0.03      0.06        30
   REIGNIER       0.00      0.00      0.00        11
     VERNON       0.00      0.00      0.00         6
    WARWICK       0.00      0.00      0.00         6

avg / total       0.24      0.30      0.19       135

=========================================================================================================

Play: 11

=========================================================================================================
Speaker: SMITH
Number of Total Listeners: 32

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
50 features selected out of 101 total
F1 mean: 0.10 (+/- 0.04)

             precision    recall  f1-score   support

       CADE       0.28      1.00      0.44         9
       DICK       0.00      0.00      0.00         8
     GEORGE       0.00      0.00      0.00         7
       JOHN       0.00      0.00      0.00         8

avg / total       0.08      0.28      0.12        32

=========================================================================================================

=========================================================================================================
Speaker: CLIFFORD
Number of Total Listeners: 124

Best model LogisticRegression(C=1.4000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
138 features selected out of 277 total
F1 mean: 0.01 (+/- 0.03)

             precision    recall  f1-score   support

 BUCKINGHAM       0.22      0.31      0.26        13
       CADE       0.08      0.08      0.08        12
     EDWARD       0.00      0.00      0.00        10
       IDEN       0.00      0.00      0.00        10
 KING HENRY       0.00      0.00      0.00        11
      QUEEN       0.00      0.00      0.00        11
    RICHARD       0.00      0.00      0.00        10
  SALISBURY       0.00      0.00      0.00         6
   SOMERSET       0.00      0.00      0.00        11
    WARWICK       0.00      0.00      0.00         6
       YORK       0.13      0.86      0.22        14
YOUNG CLIFFORD       0.00      0.00      0.00        10

avg / total       0.05      0.14      0.06       124

=========================================================================================================

=========================================================================================================
Speaker: LIEUTENANT
Number of Total Listeners: 66

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
154 features selected out of 308 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

FIRST GENTLEMAN       0.17      1.00      0.29        11
     MASTER       0.00      0.00      0.00        11
       MATE       0.00      0.00      0.00        11
SECOND GENTLEMAN       0.00      0.00      0.00        11
    SUFFOLK       0.00      0.00      0.00        11
   WHITMORE       0.00      0.00      0.00        11

avg / total       0.03      0.17      0.05        66

=========================================================================================================

=========================================================================================================
Speaker: CADE
Number of Total Listeners: 262

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
325 features selected out of 651 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.43      0.12      0.19        25
      CLERK       0.00      0.00      0.00         6
       DICK       0.21      0.82      0.33        51
     GEORGE       0.00      0.00      0.00        40
       JOHN       0.18      0.07      0.10        44
  MESSENGER       0.00      0.00      0.00         9
    MICHAEL       0.00      0.00      0.00        13
        SAY       0.00      0.00      0.00         9
      SMITH       0.14      0.11      0.12        45
   STAFFORD       0.00      0.00      0.00        10
WILLIAM STAFFORD       0.00      0.00      0.00        10

avg / total       0.13      0.20      0.12       262

=========================================================================================================

=========================================================================================================
Speaker: WARWICK
Number of Total Listeners: 181

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
257 features selected out of 514 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00         8
   CARDINAL       0.00      0.00      0.00        20
FIRST MURDERER       0.00      0.00      0.00        11
 KING HENRY       0.12      0.08      0.10        24
      QUEEN       0.00      0.00      0.00        21
  SALISBURY       0.16      0.86      0.27        29
SECOND MURDERER       0.00      0.00      0.00        11
   SOMERSET       0.00      0.00      0.00        21
    SUFFOLK       0.14      0.05      0.08        19
       YORK       0.75      0.18      0.29        17

avg / total       0.13      0.17      0.09       181

=========================================================================================================

=========================================================================================================
Speaker: SPIRIT
Number of Total Listeners: 20

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
25 features selected out of 51 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

BOLINGBROKE       0.25      1.00      0.40         5
    DUCHESS       0.00      0.00      0.00         5
       HUME       0.00      0.00      0.00         5
MARGERY JOURDAIN       0.00      0.00      0.00         5

avg / total       0.06      0.25      0.10        20

=========================================================================================================

=========================================================================================================
Speaker: WIFE
Number of Total Listeners: 56

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
26 features selected out of 52 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

   CARDINAL       0.12      1.00      0.22         7
 GLOUCESTER       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         7
      MAYOR       0.00      0.00      0.00         7
      QUEEN       0.00      0.00      0.00         7
    SIMPCOX       0.00      0.00      0.00         7
    SUFFOLK       0.00      0.00      0.00         7
   TOWNSMAN       0.00      0.00      0.00         7

avg / total       0.02      0.12      0.03        56

=========================================================================================================

=========================================================================================================
Speaker: RICHARD
Number of Total Listeners: 20

Best model LogisticRegression(C=0.80000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
68 features selected out of 137 total
F1 mean: 0.15 (+/- 0.22)

             precision    recall  f1-score   support

   CLIFFORD       0.29      0.40      0.33         5
   SOMERSET       0.00      0.00      0.00         5
       YORK       0.31      0.80      0.44         5
YOUNG CLIFFORD       0.00      0.00      0.00         5

avg / total       0.15      0.30      0.19        20

=========================================================================================================

=========================================================================================================
Speaker: YORK
Number of Total Listeners: 329

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
555 features selected out of 1110 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

BOLINGBROKE       0.00      0.00      0.00         7
 BUCKINGHAM       0.15      0.71      0.25        35
       CADE       0.00      0.00      0.00         8
   CARDINAL       0.00      0.00      0.00        19
   CLIFFORD       1.00      0.40      0.57        10
    DUCHESS       0.00      0.00      0.00         8
     EDWARD       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00        16
       HUME       0.00      0.00      0.00         7
       IDEN       0.00      0.00      0.00         8
 KING HENRY       0.00      0.00      0.00        25
MARGERY JOURDAIN       0.00      0.00      0.00         7
       POST       0.00      0.00      0.00         7
      QUEEN       0.13      0.12      0.12        33
    RICHARD       0.00      0.00      0.00         7
  SALISBURY       0.17      0.31      0.22        35
   SOMERSET       0.12      0.07      0.09        28
    SUFFOLK       0.12      0.04      0.06        25
    WARWICK       0.26      0.29      0.28        34
YOUNG CLIFFORD       0.00      0.00      0.00         5

avg / total       0.12      0.17      0.12       329

=========================================================================================================

=========================================================================================================
Speaker: WHITMORE
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
57 features selected out of 114 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

FIRST GENTLEMAN       0.17      1.00      0.29         8
 LIEUTENANT       0.00      0.00      0.00         8
     MASTER       0.00      0.00      0.00         8
       MATE       0.00      0.00      0.00         8
SECOND GENTLEMAN       0.00      0.00      0.00         8
    SUFFOLK       0.00      0.00      0.00         8

avg / total       0.03      0.17      0.05        48

=========================================================================================================

=========================================================================================================
Speaker: SAY
Number of Total Listeners: 62

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
114 features selected out of 228 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

       CADE       0.00      0.00      0.00        10
       DICK       0.00      0.00      0.00        10
     GEORGE       0.00      0.00      0.00        10
       JOHN       0.00      0.00      0.00        10
  MESSENGER       0.19      1.00      0.32        12
      SMITH       0.00      0.00      0.00        10

avg / total       0.04      0.19      0.06        62

=========================================================================================================

=========================================================================================================
Speaker: HORNER
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
40 features selected out of 80 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

 KING HENRY       0.17      1.00      0.29         5
      PETER       0.00      0.00      0.00         5
      QUEEN       0.00      0.00      0.00         5
  SALISBURY       0.00      0.00      0.00         5
    SUFFOLK       0.00      0.00      0.00         5
       YORK       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        30

=========================================================================================================

=========================================================================================================
Speaker: SOMERSET
Number of Total Listeners: 71

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 132 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

 BUCKINGHAM       0.14      0.11      0.12         9
   CARDINAL       0.13      0.25      0.17         8
 KING HENRY       0.00      0.00      0.00         9
      QUEEN       0.16      0.73      0.27        11
  SALISBURY       0.00      0.00      0.00         8
    SUFFOLK       0.00      0.00      0.00         9
    WARWICK       0.00      0.00      0.00         8
       YORK       0.00      0.00      0.00         9

avg / total       0.06      0.15      0.08        71

=========================================================================================================

=========================================================================================================
Speaker: PETER
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
62 features selected out of 125 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

     HORNER       0.00      0.00      0.00         6
 KING HENRY       0.00      0.00      0.00         6
      QUEEN       0.00      0.00      0.00         8
  SALISBURY       0.00      0.00      0.00         6
    SUFFOLK       0.20      1.00      0.33         8
       YORK       0.00      0.00      0.00         6

avg / total       0.04      0.20      0.07        40

=========================================================================================================

=========================================================================================================
Speaker: DUCHESS
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
221 features selected out of 443 total
F1 mean: 0.08 (+/- 0.03)

             precision    recall  f1-score   support

 GLOUCESTER       0.39      1.00      0.56        18
       HUME       1.00      0.33      0.50         6
SERVING MAN       0.00      0.00      0.00         8
    SHERIFF       0.00      0.00      0.00         8
    STANLEY       0.00      0.00      0.00         8

avg / total       0.27      0.42      0.27        48

=========================================================================================================

=========================================================================================================
Speaker: CARDINAL
Number of Total Listeners: 198

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
219 features selected out of 438 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
 BUCKINGHAM       0.00      0.00      0.00        17
 GLOUCESTER       0.00      0.00      0.00        24
 KING HENRY       0.17      0.31      0.22        26
      QUEEN       0.15      0.72      0.25        29
  SALISBURY       0.00      0.00      0.00        18
   SOMERSET       0.10      0.06      0.08        16
    SUFFOLK       0.00      0.00      0.00        29
    WARWICK       0.33      0.06      0.10        18
       YORK       0.00      0.00      0.00        16

avg / total       0.08      0.16      0.08       198

=========================================================================================================

=========================================================================================================
Speaker: BUCKINGHAM
Number of Total Listeners: 81

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
141 features selected out of 282 total
F1 mean: 0.07 (+/- 0.08)

             precision    recall  f1-score   support

   CARDINAL       0.25      0.14      0.18         7
 KING HENRY       0.29      0.60      0.39        15
      QUEEN       0.00      0.00      0.00        14
  SALISBURY       0.00      0.00      0.00         7
   SOMERSET       0.00      0.00      0.00         8
    SUFFOLK       0.00      0.00      0.00         8
    WARWICK       0.00      0.00      0.00         7
       YORK       0.26      0.80      0.39        15

avg / total       0.12      0.27      0.16        81

=========================================================================================================

=========================================================================================================
Speaker: WILLIAM STAFFORD
Number of Total Listeners: 40

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
21 features selected out of 42 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

        ALL       0.12      1.00      0.22         5
       CADE       0.00      0.00      0.00         5
       DICK       0.00      0.00      0.00         5
     GEORGE       0.00      0.00      0.00         5
       JOHN       0.00      0.00      0.00         5
    MICHAEL       0.00      0.00      0.00         5
      SMITH       0.00      0.00      0.00         5
   STAFFORD       0.00      0.00      0.00         5

avg / total       0.02      0.12      0.03        40

=========================================================================================================

=========================================================================================================
Speaker: STAFFORD
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 93 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

        ALL       0.12      1.00      0.22         6
       CADE       0.00      0.00      0.00         6
       DICK       0.00      0.00      0.00         6
     GEORGE       0.00      0.00      0.00         6
       JOHN       0.00      0.00      0.00         6
    MICHAEL       0.00      0.00      0.00         6
      SMITH       0.00      0.00      0.00         6
WILLIAM STAFFORD       0.00      0.00      0.00         6

avg / total       0.02      0.12      0.03        48

=========================================================================================================

=========================================================================================================
Speaker: ALL
Number of Total Listeners: 35

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
25 features selected out of 50 total
F1 mean: 0.04 (+/- 0.06)

             precision    recall  f1-score   support

 BUCKINGHAM       0.67      0.40      0.50         5
       CADE       0.25      0.89      0.39         9
       DICK       0.00      0.00      0.00         6
     GEORGE       0.00      0.00      0.00         5
       JOHN       0.00      0.00      0.00         5
      SMITH       0.00      0.00      0.00         5

avg / total       0.16      0.29      0.17        35

=========================================================================================================

=========================================================================================================
Speaker: QUEEN
Number of Total Listeners: 383

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
484 features selected out of 968 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00        25
       CADE       0.00      0.00      0.00         5
   CARDINAL       0.00      0.00      0.00        40
   CLIFFORD       0.00      0.00      0.00         5
    COMMONS       0.00      0.00      0.00        10
    DUCHESS       0.00      0.00      0.00         6
FIRST MURDERER       0.00      0.00      0.00        21
 GLOUCESTER       0.00      0.00      0.00        17
       IDEN       0.00      0.00      0.00         5
 KING HENRY       0.16      0.47      0.24        49
  SALISBURY       0.00      0.00      0.00        32
        SAY       0.00      0.00      0.00         5
SECOND MURDERER       0.00      0.00      0.00        21
   SOMERSET       0.15      0.12      0.14        40
    SUFFOLK       0.15      0.66      0.25        47
    WARWICK       0.00      0.00      0.00        29
       YORK       0.14      0.05      0.07        21
YOUNG CLIFFORD       0.00      0.00      0.00         5

avg / total       0.06      0.16      0.08       383

=========================================================================================================

=========================================================================================================
Speaker: SUFFOLK
Number of Total Listeners: 431

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
498 features selected out of 997 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00        15
   CARDINAL       0.13      0.16      0.14        45
    COMMONS       0.00      0.00      0.00         8
FIRST GENTLEMAN       0.00      0.00      0.00        12
FIRST MURDERER       0.50      0.05      0.09        21
 GLOUCESTER       0.00      0.00      0.00        26
 KING HENRY       0.11      0.03      0.04        38
 LIEUTENANT       0.00      0.00      0.00        12
     MASTER       0.00      0.00      0.00        12
       MATE       0.17      0.42      0.24        12
      PETER       0.00      0.00      0.00         5
      QUEEN       0.13      0.79      0.22        52
  SALISBURY       0.00      0.00      0.00        34
SECOND GENTLEMAN       0.00      0.00      0.00        12
SECOND MURDERER       0.00      0.00      0.00        21
   SOMERSET       0.00      0.00      0.00        36
   TOWNSMAN       0.00      0.00      0.00         5
    WARWICK       0.12      0.09      0.10        33
   WHITMORE       0.00      0.00      0.00        12
       YORK       0.00      0.00      0.00        20

avg / total       0.08      0.13      0.06       431

=========================================================================================================

=========================================================================================================
Speaker: DICK
Number of Total Listeners: 85

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
84 features selected out of 169 total
F1 mean: 0.08 (+/- 0.05)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
       CADE       0.28      0.83      0.41        23
     GEORGE       0.25      0.12      0.16        17
       JOHN       0.00      0.00      0.00        19
      SMITH       0.25      0.10      0.14        20

avg / total       0.18      0.27      0.18        85

=========================================================================================================

=========================================================================================================
Speaker: SALISBURY
Number of Total Listeners: 75

Best model LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=200, multi_class='multinomial',
          penalty='l1', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=1)
203 features selected out of 406 total
F1 mean: 0.06 (+/- 0.03)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00         7
 KING HENRY       0.50      0.08      0.14        12
      QUEEN       0.00      0.00      0.00        11
   SOMERSET       0.00      0.00      0.00         8
    SUFFOLK       0.00      0.00      0.00         8
    WARWICK       0.23      0.36      0.28        14
       YORK       0.22      0.73      0.33        15

avg / total       0.17      0.23      0.14        75

=========================================================================================================

=========================================================================================================
Speaker: SIMPCOX
Number of Total Listeners: 144

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
54 features selected out of 108 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

   CARDINAL       0.12      1.00      0.22        18
 GLOUCESTER       0.00      0.00      0.00        18
 KING HENRY       0.00      0.00      0.00        18
      MAYOR       0.00      0.00      0.00        18
      QUEEN       0.00      0.00      0.00        18
    SUFFOLK       0.00      0.00      0.00        18
   TOWNSMAN       0.00      0.00      0.00        18
       WIFE       0.00      0.00      0.00        18

avg / total       0.02      0.12      0.03       144

=========================================================================================================

=========================================================================================================
Speaker: KING HENRY
Number of Total Listeners: 537

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
497 features selected out of 994 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
 BUCKINGHAM       0.30      0.07      0.12        41
       CADE       0.00      0.00      0.00         9
   CARDINAL       0.20      0.15      0.17        52
   CLIFFORD       0.00      0.00      0.00        11
    DUCHESS       0.00      0.00      0.00         6
     EDWARD       0.00      0.00      0.00         5
FIRST MURDERER       0.00      0.00      0.00        13
 GLOUCESTER       0.00      0.00      0.00        31
     HORNER       0.00      0.00      0.00         5
       IDEN       0.00      0.00      0.00         9
      MAYOR       0.00      0.00      0.00         9
  MESSENGER       0.00      0.00      0.00         8
      PETER       0.00      0.00      0.00         5
      QUEEN       0.14      0.88      0.25        72
    RICHARD       0.00      0.00      0.00         5
  SALISBURY       0.14      0.08      0.10        38
        SAY       0.00      0.00      0.00         8
SECOND MURDERER       0.00      0.00      0.00        13
    SIMPCOX       0.00      0.00      0.00         9
   SOMERSET       0.12      0.02      0.04        42
    SUFFOLK       0.17      0.02      0.04        49
   TOWNSMAN       0.00      0.00      0.00        10
    WARWICK       0.00      0.00      0.00        33
       WIFE       0.00      0.00      0.00         9
       YORK       0.14      0.06      0.09        33
YOUNG CLIFFORD       0.00      0.00      0.00         6

avg / total       0.10      0.15      0.08       537

=========================================================================================================

=========================================================================================================
Speaker: GLOUCESTER
Number of Total Listeners: 460

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
491 features selected out of 982 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
     BEADLE       0.00      0.00      0.00         6
 BUCKINGHAM       0.11      0.06      0.07        18
   CARDINAL       0.12      0.36      0.18        53
    DUCHESS       0.44      0.44      0.44        16
 KING HENRY       0.14      0.27      0.18        55
      MAYOR       0.00      0.00      0.00        23
      QUEEN       0.00      0.00      0.00        55
  SALISBURY       0.11      0.05      0.07        21
SERVING MAN       1.00      0.22      0.36         9
    SHERIFF       0.00      0.00      0.00         7
    SIMPCOX       0.00      0.00      0.00        23
   SOMERSET       0.00      0.00      0.00        19
    STANLEY       0.00      0.00      0.00         7
    SUFFOLK       0.12      0.31      0.18        55
   TOWNSMAN       0.00      0.00      0.00        24
    WARWICK       0.11      0.05      0.07        19
       WIFE       0.00      0.00      0.00        23
       YORK       0.10      0.05      0.06        21

avg / total       0.10      0.14      0.10       460

=========================================================================================================

Play: 12

=========================================================================================================
Speaker: RICHARD
Number of Total Listeners: 470

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
593 features selected out of 1186 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   CLARENCE       0.33      0.02      0.03        56
   CLIFFORD       1.00      0.05      0.10        19
     EDWARD       0.21      0.99      0.35        96
FIRST MESSENGER       0.00      0.00      0.00         9
   HASTINGS       1.00      0.06      0.11        17
 KING HENRY       0.50      0.11      0.17        19
  LADY GREY       0.00      0.00      0.00        16
 LIEUTENANT       0.00      0.00      0.00         8
      MAYOR       0.00      0.00      0.00         5
  MESSENGER       0.00      0.00      0.00        19
   MONTAGUE       0.20      0.02      0.04        44
    NORFOLK       0.00      0.00      0.00        13
NORTHUMBERLAND       0.00      0.00      0.00        10
     OXFORD       0.00      0.00      0.00        14
PRINCE OF WALES       0.00      0.00      0.00        16
QUEEN ELIZABETH       0.00      0.00      0.00         5
QUEEN MARGARET       0.00      0.00      0.00        17
SECOND MESSENGER       0.00      0.00      0.00         9
   SOMERSET       0.00      0.00      0.00        20
 SOMERVILLE       0.00      0.00      0.00         9
    WARWICK       0.50      0.03      0.05        38
       YORK       0.00      0.00      0.00        11

avg / total       0.24      0.22      0.10       470

=========================================================================================================

=========================================================================================================
Speaker: MONTAGUE
Number of Total Listeners: 23

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
43 features selected out of 87 total
F1 mean: 0.16 (+/- 0.05)

             precision    recall  f1-score   support

     EDWARD       0.00      0.00      0.00         9
    RICHARD       0.41      1.00      0.58         9
    WARWICK       1.00      0.20      0.33         5

avg / total       0.38      0.43      0.30        23

=========================================================================================================

=========================================================================================================
Speaker: MESSENGER
Number of Total Listeners: 59

Best model LogisticRegression(C=0.40000000000000002, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
118 features selected out of 236 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

   CLARENCE       0.00      0.00      0.00         6
     EDWARD       0.20      0.40      0.27        10
   HASTINGS       0.00      0.00      0.00         6
   MONTAGUE       0.12      0.12      0.12         8
       POST       0.00      0.00      0.00         6
QUEEN ELIZABETH       0.00      0.00      0.00         6
    RICHARD       0.18      0.40      0.25        10
   SOMERSET       0.22      0.29      0.25         7

avg / total       0.11      0.19      0.13        59

=========================================================================================================

=========================================================================================================
Speaker: WARWICK
Number of Total Listeners: 601

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
574 features selected out of 1149 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       BONA       0.00      0.00      0.00        18
   CLARENCE       0.00      0.00      0.00        34
   CLIFFORD       0.00      0.00      0.00        27
     EDWARD       0.14      0.47      0.22        59
     EXETER       0.00      0.00      0.00        19
FIRST MESSENGER       0.50      0.12      0.19        17
FIRST WATCHMAN       0.00      0.00      0.00         5
 KING HENRY       0.00      0.00      0.00        31
      LEWIS       0.00      0.00      0.00        18
 LIEUTENANT       0.00      0.00      0.00         8
  MESSENGER       0.00      0.00      0.00        12
   MONTAGUE       0.14      0.40      0.21        55
    NORFOLK       0.00      0.00      0.00        25
NORTHUMBERLAND       0.00      0.00      0.00        20
     OXFORD       0.20      0.52      0.29        44
       POST       0.00      0.00      0.00         8
PRINCE OF WALES       0.00      0.00      0.00        22
QUEEN MARGARET       0.20      0.05      0.07        22
    RICHARD       0.14      0.28      0.18        58
SECOND MESSENGER       0.33      0.12      0.17        17
SECOND WATCHMAN       0.00      0.00      0.00         5
   SOMERSET       0.50      0.05      0.09        20
 SOMERVILLE       0.00      0.00      0.00        15
THIRD WATCHMAN       0.00      0.00      0.00         5
WESTMORELAND       0.00      0.00      0.00        16
       YORK       0.00      0.00      0.00        21

avg / total       0.10      0.16      0.10       601

=========================================================================================================

=========================================================================================================
Speaker: MONTGOMERY
Number of Total Listeners: 20

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
45 features selected out of 90 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

     EDWARD       0.25      1.00      0.40         5
   HASTINGS       0.00      0.00      0.00         5
      MAYOR       0.00      0.00      0.00         5
    RICHARD       0.00      0.00      0.00         5

avg / total       0.06      0.25      0.10        20

=========================================================================================================

=========================================================================================================
Speaker: PRINCE OF WALES
Number of Total Listeners: 74

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
112 features selected out of 224 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

   CLARENCE       0.00      0.00      0.00         5
   CLIFFORD       0.00      0.00      0.00         5
     EDWARD       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         6
NORTHUMBERLAND       0.00      0.00      0.00         5
     OXFORD       0.00      0.00      0.00        10
QUEEN MARGARET       0.22      1.00      0.36        16
    RICHARD       0.00      0.00      0.00         7
   SOMERSET       0.00      0.00      0.00         6
    WARWICK       0.00      0.00      0.00         7

avg / total       0.05      0.22      0.08        74

=========================================================================================================

=========================================================================================================
Speaker: NORTHUMBERLAND
Number of Total Listeners: 107

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
81 features selected out of 163 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   CLIFFORD       0.14      1.00      0.25        15
     EDWARD       0.00      0.00      0.00         8
     EXETER       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00         9
   MONTAGUE       0.00      0.00      0.00         8
    NORFOLK       0.00      0.00      0.00         8
PRINCE OF WALES       0.00      0.00      0.00         8
QUEEN MARGARET       0.00      0.00      0.00         8
    RICHARD       0.00      0.00      0.00         8
    WARWICK       0.00      0.00      0.00         8
WESTMORELAND       0.00      0.00      0.00         7
       YORK       0.00      0.00      0.00        13

avg / total       0.02      0.14      0.03       107

=========================================================================================================

=========================================================================================================
Speaker: WESTMORELAND
Number of Total Listeners: 60

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
36 features selected out of 72 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

   CLIFFORD       0.10      1.00      0.18         6
     EDWARD       0.00      0.00      0.00         6
     EXETER       0.00      0.00      0.00         6
 KING HENRY       0.00      0.00      0.00         6
   MONTAGUE       0.00      0.00      0.00         6
    NORFOLK       0.00      0.00      0.00         6
NORTHUMBERLAND       0.00      0.00      0.00         6
    RICHARD       0.00      0.00      0.00         6
    WARWICK       0.00      0.00      0.00         6
       YORK       0.00      0.00      0.00         6

avg / total       0.01      0.10      0.02        60

=========================================================================================================

=========================================================================================================
Speaker: EXETER
Number of Total Listeners: 107

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
51 features selected out of 102 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

   CLIFFORD       0.00      0.00      0.00        10
     EDWARD       0.00      0.00      0.00        10
 KING HENRY       0.12      0.62      0.21        13
   MONTAGUE       0.13      0.25      0.17        12
    NORFOLK       0.00      0.00      0.00        10
NORTHUMBERLAND       0.00      0.00      0.00        10
    RICHARD       0.00      0.00      0.00        10
    WARWICK       0.10      0.17      0.12        12
WESTMORELAND       0.00      0.00      0.00        10
       YORK       0.00      0.00      0.00        10

avg / total       0.04      0.12      0.06       107

=========================================================================================================

=========================================================================================================
Speaker: CLARENCE
Number of Total Listeners: 167

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
223 features selected out of 446 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

     EDWARD       0.24      0.81      0.37        32
   HASTINGS       0.00      0.00      0.00         6
 KING HENRY       0.00      0.00      0.00         7
  LADY GREY       0.00      0.00      0.00         8
   MONTAGUE       0.22      0.10      0.14        20
     OXFORD       0.20      0.07      0.10        15
PRINCE OF WALES       0.00      0.00      0.00         7
QUEEN MARGARET       0.00      0.00      0.00         7
    RICHARD       0.26      0.21      0.23        29
   SOMERSET       0.20      0.10      0.13        21
    WARWICK       0.20      0.13      0.16        15

avg / total       0.18      0.23      0.17       167

=========================================================================================================

=========================================================================================================
Speaker: LADY GREY
Number of Total Listeners: 72

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
85 features selected out of 170 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

   CLARENCE       0.33      1.00      0.50        24
     EDWARD       0.00      0.00      0.00        24
    RICHARD       0.00      0.00      0.00        24

avg / total       0.11      0.33      0.17        72

=========================================================================================================

=========================================================================================================
Speaker: YORK
Number of Total Listeners: 224

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
275 features selected out of 551 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

   CLIFFORD       0.25      0.05      0.08        20
     EDWARD       0.14      0.65      0.23        31
     EXETER       0.00      0.00      0.00        14
 KING HENRY       0.00      0.00      0.00        14
   MONTAGUE       0.17      0.14      0.16        28
    NORFOLK       0.00      0.00      0.00        20
NORTHUMBERLAND       0.25      0.15      0.19        20
PRINCE OF WALES       0.25      0.33      0.29         6
QUEEN MARGARET       0.00      0.00      0.00         6
    RICHARD       0.21      0.23      0.22        31
    WARWICK       0.00      0.00      0.00        20
WESTMORELAND       0.00      0.00      0.00        14

avg / total       0.12      0.17      0.11       224

=========================================================================================================

=========================================================================================================
Speaker: OXFORD
Number of Total Listeners: 31

Best model LogisticRegression(C=0.30000000000000004, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
96 features selected out of 192 total
F1 mean: 0.09 (+/- 0.15)

             precision    recall  f1-score   support

PRINCE OF WALES       0.00      0.00      0.00         7
QUEEN MARGARET       0.33      0.25      0.29         8
   SOMERSET       0.38      0.43      0.40         7
    WARWICK       0.47      0.89      0.62         9

avg / total       0.31      0.42      0.34        31

=========================================================================================================

=========================================================================================================
Speaker: SOMERSET
Number of Total Listeners: 28

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
86 features selected out of 172 total
F1 mean: 0.05 (+/- 0.13)

             precision    recall  f1-score   support

   CLARENCE       0.50      0.17      0.25         6
   MONTAGUE       0.00      0.00      0.00         5
     OXFORD       0.38      1.00      0.56        10
    WARWICK       0.00      0.00      0.00         7

avg / total       0.24      0.39      0.25        28

=========================================================================================================

=========================================================================================================
Speaker: CLIFFORD
Number of Total Listeners: 212

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
221 features selected out of 443 total
F1 mean: 0.02 (+/- 0.04)

             precision    recall  f1-score   support

   CLARENCE       0.00      0.00      0.00         6
     EDWARD       0.00      0.00      0.00        15
     EXETER       0.00      0.00      0.00         9
 KING HENRY       0.00      0.00      0.00        18
  MESSENGER       0.00      0.00      0.00         7
   MONTAGUE       0.00      0.00      0.00        15
    NORFOLK       0.00      0.00      0.00        15
NORTHUMBERLAND       0.12      0.92      0.21        24
PRINCE OF WALES       0.25      0.07      0.11        15
QUEEN MARGARET       0.00      0.00      0.00        15
    RICHARD       0.18      0.12      0.15        16
    RUTLAND       0.50      0.56      0.53         9
      TUTOR       0.50      0.11      0.18         9
    WARWICK       0.00      0.00      0.00        15
WESTMORELAND       0.00      0.00      0.00         9
       YORK       0.00      0.00      0.00        15

avg / total       0.09      0.15      0.07       212

=========================================================================================================

=========================================================================================================
Speaker: QUEEN MARGARET
Number of Total Listeners: 326

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
457 features selected out of 914 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       BONA       0.00      0.00      0.00        19
   CLARENCE       0.00      0.00      0.00        14
   CLIFFORD       0.00      0.00      0.00        20
     EDWARD       0.00      0.00      0.00        21
     EXETER       0.00      0.00      0.00         7
 KING HENRY       0.00      0.00      0.00        15
      LEWIS       0.00      0.00      0.00        19
  MESSENGER       0.00      0.00      0.00         8
   MONTAGUE       0.00      0.00      0.00        11
    NORFOLK       0.00      0.00      0.00        11
NORTHUMBERLAND       0.00      0.00      0.00        20
     OXFORD       0.20      0.03      0.05        32
       POST       0.00      0.00      0.00         6
PRINCE OF WALES       0.16      0.98      0.28        52
    RICHARD       0.00      0.00      0.00        15
   SOMERSET       0.20      0.08      0.11        13
    WARWICK       0.00      0.00      0.00        25
WESTMORELAND       0.00      0.00      0.00         6
       YORK       0.00      0.00      0.00        12

avg / total       0.05      0.16      0.05       326

=========================================================================================================

=========================================================================================================
Speaker: EDWARD
Number of Total Listeners: 607

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
595 features selected out of 1190 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   CLARENCE       0.26      0.10      0.14        90
   CLIFFORD       0.00      0.00      0.00        13
FIRST MESSENGER       0.00      0.00      0.00        12
   HASTINGS       0.33      0.05      0.09        37
   HUNTSMAN       0.00      0.00      0.00         5
 KING HENRY       0.00      0.00      0.00         8
  LADY GREY       0.00      0.00      0.00        32
      MAYOR       0.00      0.00      0.00         9
  MESSENGER       0.00      0.00      0.00        23
   MONTAGUE       0.00      0.00      0.00        46
 MONTGOMERY       0.00      0.00      0.00         6
    NORFOLK       0.00      0.00      0.00         8
NORTHUMBERLAND       0.00      0.00      0.00         7
     OXFORD       0.20      0.05      0.07        22
       POST       0.00      0.00      0.00         9
PRINCE OF WALES       0.00      0.00      0.00        16
QUEEN ELIZABETH       0.00      0.00      0.00        15
QUEEN MARGARET       0.00      0.00      0.00        18
    RICHARD       0.21      0.93      0.35       126
SECOND MESSENGER       0.00      0.00      0.00        12
   SOMERSET       0.00      0.00      0.00        37
 SOMERVILLE       0.00      0.00      0.00        12
    WARWICK       0.33      0.11      0.16        38
       YORK       0.00      0.00      0.00         6

avg / total       0.13      0.22      0.11       607

=========================================================================================================

=========================================================================================================
Speaker: LEWIS
Number of Total Listeners: 100

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
142 features selected out of 284 total
F1 mean: 0.05 (+/- 0.06)

             precision    recall  f1-score   support

       BONA       0.21      1.00      0.35        21
     OXFORD       0.00      0.00      0.00        21
PRINCE OF WALES       0.00      0.00      0.00        21
QUEEN MARGARET       0.00      0.00      0.00        21
    WARWICK       0.00      0.00      0.00        16

avg / total       0.04      0.21      0.07       100

=========================================================================================================

=========================================================================================================
Speaker: KING HENRY
Number of Total Listeners: 436

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
479 features selected out of 959 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

   CLARENCE       0.00      0.00      0.00        14
   CLIFFORD       0.19      0.15      0.17        33
     EDWARD       0.00      0.00      0.00        29
     EXETER       0.10      0.21      0.13        34
     FATHER       0.50      0.50      0.50         6
FIRST KEEPER       0.50      0.67      0.57        12
 LIEUTENANT       0.25      0.17      0.20        12
   MONTAGUE       0.00      0.00      0.00        41
    NORFOLK       0.00      0.00      0.00        29
NORTHUMBERLAND       0.00      0.00      0.00        33
     OXFORD       0.00      0.00      0.00        12
PRINCE OF WALES       0.00      0.00      0.00        13
QUEEN MARGARET       0.00      0.00      0.00        13
    RICHARD       0.15      0.39      0.22        36
SECOND KEEPER       0.50      0.08      0.14        12
   SOMERSET       0.00      0.00      0.00         6
        SON       0.00      0.00      0.00         6
    WARWICK       0.12      0.61      0.20        41
WESTMORELAND       0.00      0.00      0.00        27
       YORK       0.00      0.00      0.00        27

avg / total       0.09      0.15      0.09       436

=========================================================================================================

Play: 13

=========================================================================================================
Speaker: BRANDON
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
34 features selected out of 69 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

ABERGAVENNY       0.17      1.00      0.29         6
 BUCKINGHAM       0.00      0.00      0.00         6
    NORFOLK       0.00      0.00      0.00         6
  SECRETARY       0.00      0.00      0.00         6
   SERGEANT       0.00      0.00      0.00         6
     WOLSEY       0.00      0.00      0.00         6

avg / total       0.03      0.17      0.05        36

=========================================================================================================

=========================================================================================================
Speaker: BUCKINGHAM
Number of Total Listeners: 80

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
234 features selected out of 468 total
F1 mean: 0.07 (+/- 0.09)

             precision    recall  f1-score   support

ABERGAVENNY       0.31      0.48      0.37        23
    BRANDON       0.00      0.00      0.00         5
    NORFOLK       0.28      0.48      0.35        23
  SECRETARY       0.25      0.08      0.12        12
   SERGEANT       0.00      0.00      0.00         5
     WOLSEY       0.00      0.00      0.00        12

avg / total       0.20      0.29      0.23        80

=========================================================================================================

=========================================================================================================
Speaker: CHAMBERLAIN
Number of Total Listeners: 112

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
220 features selected out of 441 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

       ANNE       0.45      0.36      0.40        14
  GUILDFORD       0.00      0.00      0.00        10
       KING       0.00      0.00      0.00         6
     LOVELL       0.38      0.16      0.22        19
    NORFOLK       0.44      0.64      0.52        11
     SANDYS       0.26      0.81      0.39        21
    SERVANT       0.00      0.00      0.00         7
    SUFFOLK       0.27      0.30      0.29        10
     SURREY       0.00      0.00      0.00         6
     WOLSEY       0.00      0.00      0.00         8

avg / total       0.24      0.31      0.24       112

=========================================================================================================

=========================================================================================================
Speaker: KING
Number of Total Listeners: 436

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
582 features selected out of 1164 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
       ANNE       0.00      0.00      0.00         6
   CAMPEIUS       0.00      0.00      0.00        14
CHAMBERLAIN       0.14      0.17      0.15        29
 CHANCELLOR       0.00      0.00      0.00         5
    CRANMER       0.24      0.33      0.28        30
   CROMWELL       0.00      0.00      0.00         5
   GARDINER       0.40      0.16      0.23        25
     GARTER       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00         8
GENTLEMAN USHER       0.00      0.00      0.00         8
  GUILDFORD       0.00      0.00      0.00         6
     KEEPER       0.00      0.00      0.00         8
    LINCOLN       0.00      0.00      0.00         8
     LOVELL       0.16      0.38      0.23        45
    NORFOLK       0.13      0.11      0.12        46
QUEEN KATHARINE       0.00      0.00      0.00        22
     SANDYS       0.00      0.00      0.00         6
     SCRIBE       0.00      0.00      0.00         8
  SECRETARY       0.00      0.00      0.00         7
   SERGEANT       0.00      0.00      0.00         8
    SERVANT       0.00      0.00      0.00         6
    SUFFOLK       0.20      0.50      0.29        52
     SURREY       0.00      0.00      0.00        14
   SURVEYOR       0.00      0.00      0.00        12
     WOLSEY       0.14      0.23      0.18        48

avg / total       0.12      0.18      0.13       436

=========================================================================================================

=========================================================================================================
Speaker: QUEEN KATHARINE
Number of Total Listeners: 281

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
507 features selected out of 1014 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

   CAMPEIUS       0.12      0.17      0.14        23
   CAPUCIUS       0.33      0.17      0.22         6
    CRANMER       0.00      0.00      0.00        23
      CRIER       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00        10
GENTLEMAN USHER       0.00      0.00      0.00        23
   GRIFFITH       0.59      0.94      0.72        18
       KING       0.13      0.41      0.19        32
    LINCOLN       0.00      0.00      0.00        23
     LOVELL       0.00      0.00      0.00         9
    NORFOLK       0.00      0.00      0.00         9
   PATIENCE       0.00      0.00      0.00         8
     SCRIBE       0.00      0.00      0.00        23
  SECRETARY       0.00      0.00      0.00         5
   SERGEANT       0.12      0.09      0.10        23
    SUFFOLK       0.00      0.00      0.00         9
     WOLSEY       0.14      0.41      0.20        32

avg / total       0.09      0.18      0.12       281

=========================================================================================================

=========================================================================================================
Speaker: FIRST GENTLEMAN
Number of Total Listeners: 61

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
189 features selected out of 378 total
F1 mean: 0.14 (+/- 0.02)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00         7
     LOVELL       0.00      0.00      0.00         7
     SANDYS       0.00      0.00      0.00         7
SECOND GENTLEMAN       0.54      1.00      0.70        33
       VAUX       0.00      0.00      0.00         7

avg / total       0.29      0.54      0.38        61

=========================================================================================================

=========================================================================================================
Speaker: CRANMER
Number of Total Listeners: 96

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
251 features selected out of 503 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
CHAMBERLAIN       0.00      0.00      0.00         7
 CHANCELLOR       0.00      0.00      0.00         7
   CROMWELL       0.00      0.00      0.00         7
   GARDINER       0.15      0.50      0.24        12
     GARTER       0.00      0.00      0.00         5
     KEEPER       1.00      0.10      0.18        10
       KING       0.20      0.67      0.31        12
    NORFOLK       0.25      0.17      0.20        12
    SUFFOLK       0.12      0.08      0.10        12
     SURREY       0.00      0.00      0.00         7

avg / total       0.20      0.19      0.12        96

=========================================================================================================

=========================================================================================================
Speaker: ANNE
Number of Total Listeners: 22

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
117 features selected out of 235 total
F1 mean: 0.37 (+/- 0.07)

             precision    recall  f1-score   support

CHAMBERLAIN       1.00      0.14      0.25         7
   OLD LADY       0.71      1.00      0.83        15

avg / total       0.81      0.73      0.65        22

=========================================================================================================

=========================================================================================================
Speaker: CROMWELL
Number of Total Listeners: 148

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
100 features selected out of 201 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

CHAMBERLAIN       0.14      0.81      0.24        21
 CHANCELLOR       0.00      0.00      0.00         9
    CRANMER       0.00      0.00      0.00         7
   GARDINER       0.00      0.00      0.00         9
     KEEPER       0.00      0.00      0.00         9
       KING       0.00      0.00      0.00         9
     LOVELL       0.00      0.00      0.00         9
    NORFOLK       0.14      0.14      0.14        21
    SUFFOLK       0.00      0.00      0.00        21
     SURREY       0.12      0.05      0.07        21
     WOLSEY       0.00      0.00      0.00        12

avg / total       0.06      0.14      0.06       148

=========================================================================================================

=========================================================================================================
Speaker: SURREY
Number of Total Listeners: 110

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
158 features selected out of 316 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

CHAMBERLAIN       0.23      0.88      0.36        24
       KING       0.00      0.00      0.00        13
     LOVELL       0.17      0.08      0.11        12
    NORFOLK       0.00      0.00      0.00        24
    SUFFOLK       0.00      0.00      0.00        24
     WOLSEY       0.17      0.15      0.16        13

avg / total       0.09      0.22      0.11       110

=========================================================================================================

=========================================================================================================
Speaker: NORFOLK
Number of Total Listeners: 156

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
366 features selected out of 733 total
F1 mean: 0.05 (+/- 0.06)

             precision    recall  f1-score   support

ABERGAVENNY       0.40      0.24      0.30        17
 BUCKINGHAM       0.43      0.35      0.39        17
CHAMBERLAIN       0.25      0.60      0.35        30
       KING       0.00      0.00      0.00        11
     LOVELL       0.00      0.00      0.00         7
  SECRETARY       0.00      0.00      0.00         7
    SUFFOLK       0.25      0.43      0.32        30
     SURREY       0.00      0.00      0.00        19
     WOLSEY       0.25      0.11      0.15        18

avg / total       0.22      0.28      0.22       156

=========================================================================================================

=========================================================================================================
Speaker: CHANCELLOR
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
78 features selected out of 157 total
F1 mean: 0.04 (+/- 0.00)

             precision    recall  f1-score   support

CHAMBERLAIN       0.14      1.00      0.25         6
   CROMWELL       0.00      0.00      0.00         6
   GARDINER       0.00      0.00      0.00         6
     KEEPER       0.00      0.00      0.00         6
    NORFOLK       0.00      0.00      0.00         6
    SUFFOLK       0.00      0.00      0.00         6
     SURREY       0.00      0.00      0.00         6

avg / total       0.02      0.14      0.04        42

=========================================================================================================

=========================================================================================================
Speaker: GARDINER
Number of Total Listeners: 119

Best model LogisticRegression(C=0.40000000000000002, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
192 features selected out of 384 total
F1 mean: 0.11 (+/- 0.05)

             precision    recall  f1-score   support

CHAMBERLAIN       0.13      0.33      0.19        15
 CHANCELLOR       0.00      0.00      0.00        14
    CRANMER       0.12      0.09      0.11        11
   CROMWELL       0.00      0.00      0.00        14
     KEEPER       0.00      0.00      0.00        14
     LOVELL       1.00      1.00      1.00         7
    NORFOLK       0.00      0.00      0.00        15
    SUFFOLK       0.14      0.47      0.22        15
     SURREY       0.12      0.14      0.13        14

avg / total       0.12      0.18      0.14       119

=========================================================================================================

=========================================================================================================
Speaker: SURVEYOR
Number of Total Listeners: 54

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
142 features selected out of 284 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

       KING       0.17      1.00      0.29         9
     LOVELL       0.00      0.00      0.00         9
    NORFOLK       0.00      0.00      0.00         9
QUEEN KATHARINE       0.00      0.00      0.00         9
    SUFFOLK       0.00      0.00      0.00         9
     WOLSEY       0.00      0.00      0.00         9

avg / total       0.03      0.17      0.05        54

=========================================================================================================

=========================================================================================================
Speaker: SECOND GENTLEMAN
Number of Total Listeners: 68

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
175 features selected out of 351 total
F1 mean: 0.12 (+/- 0.02)

             precision    recall  f1-score   support

 BUCKINGHAM       0.00      0.00      0.00         6
FIRST GENTLEMAN       0.54      1.00      0.70        37
     LOVELL       0.00      0.00      0.00         6
     SANDYS       0.00      0.00      0.00         6
THIRD GENTLEMAN       0.00      0.00      0.00         7
       VAUX       0.00      0.00      0.00         6

avg / total       0.30      0.54      0.38        68

=========================================================================================================

=========================================================================================================
Speaker: WOLSEY
Number of Total Listeners: 520

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
570 features selected out of 1141 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00        16
   CAMPEIUS       0.12      0.04      0.06        25
CHAMBERLAIN       0.16      0.31      0.21        55
    CRANMER       0.00      0.00      0.00        17
   CROMWELL       0.00      0.00      0.00        13
   GARDINER       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00         7
GENTLEMAN USHER       0.00      0.00      0.00        17
  GUILDFORD       0.00      0.00      0.00        16
       KING       0.14      0.78      0.24        67
    LINCOLN       0.00      0.00      0.00        17
     LOVELL       0.17      0.02      0.04        48
    NORFOLK       0.26      0.12      0.17        48
QUEEN KATHARINE       0.00      0.00      0.00        22
     SANDYS       0.00      0.00      0.00        16
     SCRIBE       0.00      0.00      0.00        17
  SECRETARY       0.00      0.00      0.00         6
   SERGEANT       0.00      0.00      0.00        17
    SERVANT       0.00      0.00      0.00        15
    SUFFOLK       0.16      0.07      0.09        45
     SURREY       0.00      0.00      0.00        31

avg / total       0.09      0.15      0.08       520

=========================================================================================================

=========================================================================================================
Speaker: SANDYS
Number of Total Listeners: 52

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
109 features selected out of 218 total
F1 mean: 0.09 (+/- 0.10)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00        10
CHAMBERLAIN       0.33      0.94      0.49        17
  GUILDFORD       0.00      0.00      0.00        10
     LOVELL       0.25      0.07      0.11        15

avg / total       0.18      0.33      0.19        52

=========================================================================================================

=========================================================================================================
Speaker: CAMPEIUS
Number of Total Listeners: 96

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
119 features selected out of 238 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

CHAMBERLAIN       0.00      0.00      0.00         5
    CRANMER       0.00      0.00      0.00         9
GENTLEMAN USHER       0.00      0.00      0.00         9
       KING       0.12      0.07      0.09        14
    LINCOLN       0.00      0.00      0.00         9
    NORFOLK       0.00      0.00      0.00         5
QUEEN KATHARINE       0.00      0.00      0.00         8
     SCRIBE       0.00      0.00      0.00         9
   SERGEANT       0.00      0.00      0.00         9
    SUFFOLK       0.00      0.00      0.00         5
     WOLSEY       0.15      0.93      0.25        14

avg / total       0.04      0.15      0.05        96

=========================================================================================================

=========================================================================================================
Speaker: LOVELL
Number of Total Listeners: 35

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
151 features selected out of 302 total
F1 mean: 0.14 (+/- 0.16)

             precision    recall  f1-score   support

CHAMBERLAIN       0.00      0.00      0.00         9
   GARDINER       0.75      0.90      0.82        10
       KING       0.00      0.00      0.00         5
     SANDYS       0.48      1.00      0.65        11

avg / total       0.36      0.57      0.44        35

=========================================================================================================

=========================================================================================================
Speaker: SUFFOLK
Number of Total Listeners: 104

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
174 features selected out of 348 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

CHAMBERLAIN       0.27      0.67      0.38        27
   GARDINER       0.00      0.00      0.00         5
       KING       0.33      0.20      0.25        10
     LOVELL       0.00      0.00      0.00         8
    NORFOLK       0.32      0.30      0.31        27
     SURREY       0.17      0.05      0.08        19
     WOLSEY       0.00      0.00      0.00         8

avg / total       0.22      0.28      0.22       104

=========================================================================================================

=========================================================================================================
Speaker: THIRD GENTLEMAN
Number of Total Listeners: 20

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
135 features selected out of 270 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

FIRST GENTLEMAN       0.50      1.00      0.67        10
SECOND GENTLEMAN       0.00      0.00      0.00        10

avg / total       0.25      0.50      0.33        20

=========================================================================================================

Play: 14

=========================================================================================================
Speaker: BASTARD
Number of Total Listeners: 483

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
717 features selected out of 1435 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00        29
    AUSTRIA       1.00      0.05      0.09        21
      BIGOT       0.00      0.00      0.00        19
     BLANCH       0.00      0.00      0.00        16
  CHATILLON       0.00      0.00      0.00        28
    CITIZEN       0.00      0.00      0.00        19
  CONSTANCE       0.00      0.00      0.00        15
     ELINOR       0.00      0.00      0.00        38
      ESSEX       0.00      0.00      0.00        20
     GURNEY       0.00      0.00      0.00         6
     HUBERT       0.56      0.43      0.49        23
  KING JOHN       0.16      0.67      0.26        60
KING PHILIP       0.00      0.00      0.00        22
LADY FAULCONBRIDGE       0.00      0.00      0.00         6
      LEWIS       0.00      0.00      0.00        14
  MESSENGER       0.00      0.00      0.00         5
   PANDULPH       0.00      0.00      0.00        10
   PEMBROKE       0.14      0.02      0.04        44
      PETER       0.00      0.00      0.00         5
PRINCE HENRY       0.00      0.00      0.00         7
     ROBERT       0.14      0.05      0.07        20
  SALISBURY       0.16      0.59      0.26        56

avg / total       0.13      0.18      0.10       483

=========================================================================================================

=========================================================================================================
Speaker: BIGOT
Number of Total Listeners: 23

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
23 features selected out of 46 total
F1 mean: 0.10 (+/- 0.01)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00         6
    BASTARD       0.00      0.00      0.00         5
   PEMBROKE       0.00      0.00      0.00         6
  SALISBURY       0.26      1.00      0.41         6

avg / total       0.07      0.26      0.11        23

=========================================================================================================

=========================================================================================================
Speaker: PANDULPH
Number of Total Listeners: 114

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
287 features selected out of 574 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00         8
    AUSTRIA       0.00      0.00      0.00         8
    BASTARD       0.00      0.00      0.00        10
     BLANCH       0.00      0.00      0.00         8
    CITIZEN       0.00      0.00      0.00         8
  CONSTANCE       0.00      0.00      0.00        10
     ELINOR       0.00      0.00      0.00         8
  KING JOHN       1.00      0.20      0.33        10
KING PHILIP       0.00      0.00      0.00        11
      LEWIS       0.19      1.00      0.32        21
  SALISBURY       0.00      0.00      0.00        12

avg / total       0.12      0.20      0.09       114

=========================================================================================================

=========================================================================================================
Speaker: HUBERT
Number of Total Listeners: 149

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
244 features selected out of 489 total
F1 mean: 0.04 (+/- 0.06)

             precision    recall  f1-score   support

     ARTHUR       0.33      0.79      0.46        33
    BASTARD       0.33      0.68      0.45        31
      BIGOT       0.00      0.00      0.00        10
     ELINOR       0.00      0.00      0.00         5
EXECUTIONER       0.67      0.20      0.31        20
  KING JOHN       0.00      0.00      0.00        12
   PEMBROKE       0.00      0.00      0.00        16
      PETER       0.00      0.00      0.00         6
  SALISBURY       0.00      0.00      0.00        16

avg / total       0.23      0.34      0.24       149

=========================================================================================================

=========================================================================================================
Speaker: CITIZEN
Number of Total Listeners: 39

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
125 features selected out of 250 total
F1 mean: 0.05 (+/- 0.05)

             precision    recall  f1-score   support

    AUSTRIA       0.00      0.00      0.00         7
    BASTARD       0.25      0.11      0.15         9
     ELINOR       0.00      0.00      0.00         5
  KING JOHN       0.23      0.89      0.36         9
KING PHILIP       0.00      0.00      0.00         9

avg / total       0.11      0.23      0.12        39

=========================================================================================================

=========================================================================================================
Speaker: PEMBROKE
Number of Total Listeners: 58

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
180 features selected out of 360 total
F1 mean: 0.03 (+/- 0.06)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00         7
    BASTARD       0.00      0.00      0.00         6
      BIGOT       0.00      0.00      0.00        11
     HUBERT       0.00      0.00      0.00         6
  KING JOHN       0.50      0.12      0.20         8
  SALISBURY       0.34      0.95      0.50        20

avg / total       0.19      0.34      0.20        58

=========================================================================================================

=========================================================================================================
Speaker: LEWIS
Number of Total Listeners: 79

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
226 features selected out of 453 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

    AUSTRIA       0.00      0.00      0.00         7
    BASTARD       0.14      0.20      0.17        10
     BLANCH       0.00      0.00      0.00         6
    CITIZEN       0.00      0.00      0.00         7
     ELINOR       0.00      0.00      0.00         7
  KING JOHN       0.00      0.00      0.00         7
KING PHILIP       0.17      0.12      0.14         8
   PANDULPH       0.29      0.94      0.44        17
  SALISBURY       0.67      0.20      0.31        10

avg / total       0.18      0.27      0.17        79

=========================================================================================================

=========================================================================================================
Speaker: KING PHILIP
Number of Total Listeners: 279

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
343 features selected out of 686 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     ARTHUR       0.22      0.08      0.12        25
    AUSTRIA       0.20      0.20      0.20        30
    BASTARD       0.25      0.14      0.18        28
     BLANCH       0.00      0.00      0.00        24
  CHATILLON       0.00      0.00      0.00        14
    CITIZEN       0.00      0.00      0.00        26
  CONSTANCE       0.13      0.41      0.20        29
     ELINOR       0.00      0.00      0.00        26
  KING JOHN       0.12      0.39      0.19        31
      LEWIS       0.23      0.33      0.27        21
   PANDULPH       0.50      0.06      0.11        16
  SALISBURY       0.00      0.00      0.00         9

avg / total       0.14      0.16      0.12       279

=========================================================================================================

=========================================================================================================
Speaker: ARTHUR
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
180 features selected out of 361 total
F1 mean: 0.33 (+/- 0.00)

             precision    recall  f1-score   support

EXECUTIONER       0.50      1.00      0.67        18
     HUBERT       0.00      0.00      0.00        18

avg / total       0.25      0.50      0.33        36

=========================================================================================================

=========================================================================================================
Speaker: KING JOHN
Number of Total Listeners: 494

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
607 features selected out of 1215 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00        31
    AUSTRIA       0.00      0.00      0.00        27
    BASTARD       0.16      0.74      0.26        66
     BLANCH       0.00      0.00      0.00        24
  CHATILLON       0.00      0.00      0.00        27
    CITIZEN       0.33      0.08      0.12        26
  CONSTANCE       0.00      0.00      0.00        20
     ELINOR       0.17      0.33      0.22        51
      ESSEX       0.00      0.00      0.00        16
     HUBERT       0.32      0.20      0.24        30
KING PHILIP       0.33      0.03      0.06        30
      LEWIS       0.00      0.00      0.00        12
  MESSENGER       0.00      0.00      0.00        11
   PANDULPH       1.00      0.11      0.20         9
   PEMBROKE       0.25      0.02      0.04        42
      PETER       0.00      0.00      0.00        13
     ROBERT       0.00      0.00      0.00         9
  SALISBURY       0.32      0.30      0.31        50

avg / total       0.17      0.19      0.12       494

=========================================================================================================

=========================================================================================================
Speaker: ELINOR
Number of Total Listeners: 142

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
129 features selected out of 259 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00        12
    AUSTRIA       0.00      0.00      0.00        10
    BASTARD       0.00      0.00      0.00        19
     BLANCH       0.00      0.00      0.00         9
  CHATILLON       0.00      0.00      0.00        16
  CONSTANCE       0.00      0.00      0.00         9
      ESSEX       0.00      0.00      0.00         9
  KING JOHN       0.15      1.00      0.27        22
KING PHILIP       0.00      0.00      0.00        10
   PEMBROKE       0.00      0.00      0.00         9
     ROBERT       0.00      0.00      0.00         6
  SALISBURY       0.00      0.00      0.00        11

avg / total       0.02      0.15      0.04       142

=========================================================================================================

=========================================================================================================
Speaker: PRINCE HENRY
Number of Total Listeners: 27

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
77 features selected out of 155 total
F1 mean: 0.09 (+/- 0.09)

             precision    recall  f1-score   support

      BIGOT       0.25      0.43      0.32         7
  KING JOHN       0.00      0.00      0.00         5
   PEMBROKE       0.00      0.00      0.00         7
  SALISBURY       0.33      0.62      0.43         8

avg / total       0.16      0.30      0.21        27

=========================================================================================================

=========================================================================================================
Speaker: CONSTANCE
Number of Total Listeners: 276

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
411 features selected out of 823 total
F1 mean: 0.01 (+/- 0.03)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00        28
    AUSTRIA       0.12      0.07      0.09        28
    BASTARD       0.00      0.00      0.00        18
     BLANCH       0.12      0.08      0.09        26
  CHATILLON       0.00      0.00      0.00         8
    CITIZEN       0.00      0.00      0.00        18
     ELINOR       0.00      0.00      0.00        26
  KING JOHN       0.00      0.00      0.00        26
KING PHILIP       0.13      0.81      0.23        36
      LEWIS       0.13      0.12      0.12        26
   PANDULPH       0.00      0.00      0.00        18
  SALISBURY       0.00      0.00      0.00        18

avg / total       0.05      0.13      0.06       276

=========================================================================================================

=========================================================================================================
Speaker: BLANCH
Number of Total Listeners: 87

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
101 features selected out of 202 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ARTHUR       0.00      0.00      0.00         7
    AUSTRIA       0.00      0.00      0.00         9
    BASTARD       0.00      0.00      0.00         9
    CITIZEN       0.00      0.00      0.00         8
  CONSTANCE       0.00      0.00      0.00         7
     ELINOR       0.00      0.00      0.00         9
  KING JOHN       0.00      0.00      0.00         9
KING PHILIP       0.10      1.00      0.19         9
      LEWIS       0.00      0.00      0.00         8
   PANDULPH       0.00      0.00      0.00         6
  SALISBURY       0.00      0.00      0.00         6

avg / total       0.01      0.10      0.02        87

=========================================================================================================

=========================================================================================================
Speaker: AUSTRIA
Number of Total Listeners: 121

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
87 features selected out of 175 total
F1 mean: 0.01 (+/- 0.03)

             precision    recall  f1-score   support

     ARTHUR       0.17      0.14      0.15        14
    BASTARD       0.00      0.00      0.00        11
     BLANCH       0.00      0.00      0.00        12
  CHATILLON       0.00      0.00      0.00         5
    CITIZEN       0.00      0.00      0.00        10
  CONSTANCE       0.00      0.00      0.00        13
     ELINOR       0.00      0.00      0.00        12
  KING JOHN       0.12      0.15      0.14        13
KING PHILIP       0.13      0.75      0.22        16
      LEWIS       0.00      0.00      0.00         8
  SALISBURY       0.00      0.00      0.00         7

avg / total       0.05      0.13      0.06       121

=========================================================================================================

=========================================================================================================
Speaker: SALISBURY
Number of Total Listeners: 118

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
252 features selected out of 504 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

     ARTHUR       0.40      0.22      0.29        18
    BASTARD       0.00      0.00      0.00        16
      BIGOT       0.00      0.00      0.00        25
     HUBERT       0.00      0.00      0.00         9
  KING JOHN       0.00      0.00      0.00        13
   PEMBROKE       0.29      0.97      0.44        32
PRINCE HENRY       0.00      0.00      0.00         5

avg / total       0.14      0.30      0.16       118

=========================================================================================================

=========================================================================================================
Speaker: LADY FAULCONBRIDGE
Number of Total Listeners: 45

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
43 features selected out of 86 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

    BASTARD       0.11      1.00      0.20         5
  CHATILLON       0.00      0.00      0.00         5
     ELINOR       0.00      0.00      0.00         5
      ESSEX       0.00      0.00      0.00         5
     GURNEY       0.00      0.00      0.00         5
  KING JOHN       0.00      0.00      0.00         5
   PEMBROKE       0.00      0.00      0.00         5
     ROBERT       0.00      0.00      0.00         5
  SALISBURY       0.00      0.00      0.00         5

avg / total       0.01      0.11      0.02        45

=========================================================================================================

Play: 15

=========================================================================================================
Speaker: PORTIA
Number of Total Listeners: 63

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
181 features selected out of 363 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

     BRUTUS       0.00      0.00      0.00         6
      CASCA       0.00      0.00      0.00         6
    CASSIUS       0.00      0.00      0.00         6
      CINNA       0.00      0.00      0.00         6
     DECIUS       0.00      0.00      0.00         6
     LUCIUS       0.25      1.00      0.41        16
   METELLUS       0.00      0.00      0.00         6
 SOOTHSAYER       0.00      0.00      0.00         5
  TREBONIUS       0.00      0.00      0.00         6

avg / total       0.06      0.25      0.10        63

=========================================================================================================

=========================================================================================================
Speaker: FIRST CITIZEN
Number of Total Listeners: 108

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
45 features selected out of 90 total
F1 mean: 0.04 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        13
     ANTONY       0.14      0.08      0.10        13
    CASSIUS       0.00      0.00      0.00        14
   CITIZENS       0.00      0.00      0.00        14
FOURTH CITIZEN       0.00      0.00      0.00        18
SECOND CITIZEN       0.00      0.00      0.00        18
THIRD CITIZEN       0.17      0.94      0.29        18

avg / total       0.05      0.17      0.06       108

=========================================================================================================

=========================================================================================================
Speaker: SERVANT
Number of Total Listeners: 82

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
67 features selected out of 135 total
F1 mean: 0.00 (+/- 0.01)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00         6
ARTEMIDORUS       0.00      0.00      0.00         5
     BRUTUS       0.00      0.00      0.00         5
     CAESAR       0.16      0.62      0.25         8
      CASCA       0.00      0.00      0.00         5
    CASSIUS       0.12      0.75      0.21         8
      CINNA       0.00      0.00      0.00         5
     DECIUS       0.00      0.00      0.00         5
     LUCIUS       0.00      0.00      0.00         5
   METELLUS       0.00      0.00      0.00         5
   POPILIUS       0.00      0.00      0.00         5
     PORTIA       0.00      0.00      0.00         5
    PUBLIUS       0.00      0.00      0.00         5
 SOOTHSAYER       0.00      0.00      0.00         5
  TREBONIUS       0.00      0.00      0.00         5

avg / total       0.03      0.13      0.04        82

=========================================================================================================

=========================================================================================================
Speaker: VARRO
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
12 features selected out of 25 total
F1 mean: 0.03 (+/- 0.00)

             precision    recall  f1-score   support

     BRUTUS       0.12      1.00      0.22         6
    CASSIUS       0.00      0.00      0.00         6
    CLAUDIO       0.00      0.00      0.00         6
   LUCILIUS       0.00      0.00      0.00         6
     LUCIUS       0.00      0.00      0.00         6
    MESSALA       0.00      0.00      0.00         6
       POET       0.00      0.00      0.00         6
   TITINIUS       0.00      0.00      0.00         6

avg / total       0.02      0.12      0.03        48

=========================================================================================================

=========================================================================================================
Speaker: FOURTH CITIZEN
Number of Total Listeners: 97

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
49 features selected out of 99 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        11
     ANTONY       0.00      0.00      0.00        11
    CASSIUS       0.00      0.00      0.00        11
      CINNA       0.00      0.00      0.00         5
   CITIZENS       0.00      0.00      0.00        11
FIRST CITIZEN       0.16      1.00      0.28        16
SECOND CITIZEN       0.00      0.00      0.00        16
THIRD CITIZEN       0.00      0.00      0.00        16

avg / total       0.03      0.16      0.05        97

=========================================================================================================

=========================================================================================================
Speaker: DECIUS
Number of Total Listeners: 67

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
100 features selected out of 201 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

ARTEMIDORUS       0.00      0.00      0.00         5
     BRUTUS       0.00      0.00      0.00         8
     CAESAR       0.22      0.78      0.34         9
      CASCA       0.00      0.00      0.00         7
    CASSIUS       0.00      0.00      0.00         8
      CINNA       0.00      0.00      0.00         5
     LUCIUS       0.14      0.62      0.23         8
   METELLUS       0.00      0.00      0.00         7
     PORTIA       0.00      0.00      0.00         5
 SOOTHSAYER       0.00      0.00      0.00         5

avg / total       0.05      0.18      0.07        67

=========================================================================================================

=========================================================================================================
Speaker: MESSALA
Number of Total Listeners: 86

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
83 features selected out of 167 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00         5
     BRUTUS       0.24      0.29      0.26        14
    CASSIUS       0.23      0.94      0.37        17
   LUCILIUS       0.00      0.00      0.00        12
     LUCIUS       0.00      0.00      0.00         8
   OCTAVIUS       0.00      0.00      0.00         5
       POET       0.00      0.00      0.00         8
   TITINIUS       0.00      0.00      0.00        17

avg / total       0.08      0.23      0.12        86

=========================================================================================================

=========================================================================================================
Speaker: BRUTUS
Number of Total Listeners: 1217

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
704 features selected out of 1408 total
F1 mean: 0.00 (+/- 0.00)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00        44
ARTEMIDORUS       0.00      0.00      0.00        23
     CAESAR       0.00      0.00      0.00        47
  CALPURNIA       0.00      0.00      0.00        24
      CASCA       0.11      0.02      0.03        66
    CASSIUS       0.14      0.88      0.24       163
       CATO       0.00      0.00      0.00         5
     CICERO       0.00      0.00      0.00        22
      CINNA       0.00      0.00      0.00        42
   CITIZENS       0.00      0.00      0.00         5
    CLAUDIO       0.00      0.00      0.00        16
     CLITUS       0.25      0.10      0.14        10
  DARDANIUS       0.25      0.30      0.27        10
     DECIUS       0.00      0.00      0.00        68
FIRST CITIZEN       0.00      0.00      0.00         5
FOURTH CITIZEN       0.00      0.00      0.00         5
      GHOST       0.00      0.00      0.00        10
   LIGARIUS       0.00      0.00      0.00         6
   LUCILIUS       0.00      0.00      0.00        66
     LUCIUS       0.17      0.23      0.19       111
    MESSALA       0.22      0.04      0.07        50
  MESSENGER       0.00      0.00      0.00        11
   METELLUS       0.17      0.02      0.04        44
   OCTAVIUS       0.00      0.00      0.00        11
   PINDARUS       0.00      0.00      0.00        10
       POET       0.11      0.02      0.04        45
   POPILIUS       0.00      0.00      0.00        23
     PORTIA       0.00      0.00      0.00        57
    PUBLIUS       0.00      0.00      0.00        25
SECOND CITIZEN       0.17      0.20      0.18         5
 SOOTHSAYER       0.00      0.00      0.00        45
     STRATO       0.00      0.00      0.00        10
THIRD CITIZEN       0.00      0.00      0.00         5
   TITINIUS       0.25      0.01      0.03        70
  TREBONIUS       0.00      0.00      0.00        32
      VARRO       0.00      0.00      0.00        16
  VOLUMNIUS       0.00      0.00      0.00        10

avg / total       0.08      0.15      0.06      1217

=========================================================================================================

=========================================================================================================
Speaker: LIGARIUS
Number of Total Listeners: 45

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 92 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

     BRUTUS       0.11      1.00      0.20         5
      CASCA       0.00      0.00      0.00         5
    CASSIUS       0.00      0.00      0.00         5
      CINNA       0.00      0.00      0.00         5
     DECIUS       0.00      0.00      0.00         5
     LUCIUS       0.00      0.00      0.00         5
   METELLUS       0.00      0.00      0.00         5
     PORTIA       0.00      0.00      0.00         5
  TREBONIUS       0.00      0.00      0.00         5

avg / total       0.01      0.11      0.02        45

=========================================================================================================

=========================================================================================================
Speaker: LUCIUS
Number of Total Listeners: 92

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
61 features selected out of 123 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

     BRUTUS       0.22      1.00      0.36        20
    CASSIUS       0.00      0.00      0.00        11
    CLAUDIO       0.00      0.00      0.00         8
   LUCILIUS       0.00      0.00      0.00        10
    MESSALA       0.00      0.00      0.00        10
       POET       0.00      0.00      0.00        10
     PORTIA       1.00      0.20      0.33         5
   TITINIUS       0.00      0.00      0.00        10
      VARRO       0.00      0.00      0.00         8

avg / total       0.10      0.23      0.10        92

=========================================================================================================

=========================================================================================================
Speaker: CAESAR
Number of Total Listeners: 294

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
246 features selected out of 493 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00        16
ARTEMIDORUS       0.00      0.00      0.00        10
     BRUTUS       0.11      0.07      0.09        28
  CALPURNIA       0.23      0.43      0.30        28
      CASCA       0.00      0.00      0.00        28
    CASSIUS       0.00      0.00      0.00        24
     CICERO       0.00      0.00      0.00        14
      CINNA       0.00      0.00      0.00        11
     DECIUS       0.11      0.73      0.19        33
     LUCIUS       0.00      0.00      0.00        10
   METELLUS       0.00      0.00      0.00        14
   POPILIUS       0.00      0.00      0.00         7
     PORTIA       0.00      0.00      0.00        24
    PUBLIUS       0.00      0.00      0.00        11
    SERVANT       0.00      0.00      0.00        12
 SOOTHSAYER       0.00      0.00      0.00        24

avg / total       0.04      0.13      0.06       294

=========================================================================================================

=========================================================================================================
Speaker: ANTONY
Number of Total Listeners: 384

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
458 features selected out of 916 total
F1 mean: 0.00 (+/- 0.00)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        20
ARTEMIDORUS       0.00      0.00      0.00        10
     BRUTUS       0.11      0.10      0.10        21
     CAESAR       0.00      0.00      0.00        15
  CALPURNIA       0.00      0.00      0.00         5
      CASCA       0.00      0.00      0.00        15
    CASSIUS       0.11      0.92      0.19        39
      CINNA       0.00      0.00      0.00        11
   CITIZENS       0.14      0.05      0.07        20
     DECIUS       0.00      0.00      0.00        15
FIRST CITIZEN       0.00      0.00      0.00        20
FOURTH CITIZEN       0.00      0.00      0.00        20
    LEPIDUS       0.00      0.00      0.00         5
   LUCILIUS       1.00      0.12      0.22         8
     LUCIUS       0.00      0.00      0.00        10
    MESSALA       0.00      0.00      0.00         6
  MESSENGER       0.00      0.00      0.00         7
   METELLUS       0.00      0.00      0.00        11
   OCTAVIUS       0.54      0.50      0.52        14
   POPILIUS       0.00      0.00      0.00        10
     PORTIA       0.00      0.00      0.00        14
    PUBLIUS       0.00      0.00      0.00        11
SECOND CITIZEN       0.00      0.00      0.00        20
    SERVANT       0.00      0.00      0.00         7
 SOOTHSAYER       0.00      0.00      0.00        14
THIRD CITIZEN       0.14      0.05      0.07        20
   TITINIUS       0.00      0.00      0.00         5
  TREBONIUS       0.00      0.00      0.00        11

avg / total       0.07      0.12      0.06       384

=========================================================================================================

=========================================================================================================
Speaker: CASSIUS
Number of Total Listeners: 801

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
602 features selected out of 1204 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

     ANTONY       0.11      0.03      0.04        40
ARTEMIDORUS       0.00      0.00      0.00        19
     BRUTUS       0.16      0.93      0.27       117
     CAESAR       0.00      0.00      0.00        43
  CALPURNIA       0.00      0.00      0.00        24
      CASCA       0.20      0.22      0.21        65
     CICERO       0.18      0.05      0.08        39
      CINNA       0.22      0.07      0.11        29
     DECIUS       0.00      0.00      0.00        52
   LUCILIUS       0.00      0.00      0.00        37
     LUCIUS       0.00      0.00      0.00        58
    MESSALA       0.00      0.00      0.00        21
  MESSENGER       0.00      0.00      0.00        11
   METELLUS       0.00      0.00      0.00        26
   OCTAVIUS       0.00      0.00      0.00        11
   PINDARUS       1.00      0.22      0.36         9
       POET       0.00      0.00      0.00        22
   POPILIUS       0.00      0.00      0.00        18
     PORTIA       0.00      0.00      0.00        43
    PUBLIUS       0.00      0.00      0.00        19
 SOOTHSAYER       0.00      0.00      0.00        43
   TITINIUS       0.60      0.07      0.13        40
  TREBONIUS       0.00      0.00      0.00        15

avg / total       0.10      0.17      0.08       801

=========================================================================================================

=========================================================================================================
Speaker: CASCA
Number of Total Listeners: 232

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
245 features selected out of 490 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00        19
     BRUTUS       0.00      0.00      0.00        25
     CAESAR       0.00      0.00      0.00        21
  CALPURNIA       0.00      0.00      0.00        19
    CASSIUS       0.16      0.77      0.26        35
     CICERO       0.19      0.36      0.25        33
      CINNA       0.00      0.00      0.00         7
     DECIUS       0.00      0.00      0.00        25
     LUCIUS       0.00      0.00      0.00         6
     PORTIA       0.00      0.00      0.00        21
 SOOTHSAYER       0.00      0.00      0.00        21

avg / total       0.05      0.17      0.08       232

=========================================================================================================

=========================================================================================================
Speaker: OCTAVIUS
Number of Total Listeners: 74

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
106 features selected out of 212 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

     ANTONY       0.26      1.00      0.41        19
     BRUTUS       0.00      0.00      0.00        10
    CASSIUS       0.00      0.00      0.00         6
    LEPIDUS       0.00      0.00      0.00         6
   LUCILIUS       0.00      0.00      0.00         9
    MESSALA       0.00      0.00      0.00        10
  MESSENGER       0.00      0.00      0.00         8
   TITINIUS       0.00      0.00      0.00         6

avg / total       0.07      0.26      0.10        74

=========================================================================================================

=========================================================================================================
Speaker: THIRD CITIZEN
Number of Total Listeners: 94

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
51 features selected out of 102 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        11
     ANTONY       0.00      0.00      0.00        11
    CASSIUS       0.00      0.00      0.00        12
   CITIZENS       0.00      0.00      0.00        12
FIRST CITIZEN       0.00      0.00      0.00        16
FOURTH CITIZEN       0.00      0.00      0.00        16
SECOND CITIZEN       0.17      1.00      0.29        16

avg / total       0.03      0.17      0.05        94

=========================================================================================================

=========================================================================================================
Speaker: METELLUS
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
50 features selected out of 101 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

     BRUTUS       0.17      1.00      0.29         5
      CASCA       0.00      0.00      0.00         5
    CASSIUS       0.00      0.00      0.00         5
      CINNA       0.00      0.00      0.00         5
     DECIUS       0.00      0.00      0.00         5
     LUCIUS       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        30

=========================================================================================================

=========================================================================================================
Speaker: ALL
Number of Total Listeners: 83

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
22 features selected out of 45 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     ANTONY       0.00      0.00      0.00        11
    CASSIUS       0.14      1.00      0.25        12
   CITIZENS       0.00      0.00      0.00        12
FIRST CITIZEN       0.00      0.00      0.00        12
FOURTH CITIZEN       0.00      0.00      0.00        12
SECOND CITIZEN       0.00      0.00      0.00        12
THIRD CITIZEN       0.00      0.00      0.00        12

avg / total       0.02      0.14      0.04        83

=========================================================================================================

=========================================================================================================
Speaker: CINNA
Number of Total Listeners: 76

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 133 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

     BRUTUS       0.00      0.00      0.00         7
      CASCA       0.20      0.91      0.33        11
    CASSIUS       0.17      0.09      0.12        11
     DECIUS       0.00      0.00      0.00         7
FIRST CITIZEN       0.25      0.43      0.32         7
FOURTH CITIZEN       0.25      0.14      0.18         7
     LUCIUS       0.00      0.00      0.00         7
   METELLUS       0.00      0.00      0.00         5
SECOND CITIZEN       0.25      0.14      0.18         7
THIRD CITIZEN       0.00      0.00      0.00         7

avg / total       0.12      0.21      0.13        76

=========================================================================================================

=========================================================================================================
Speaker: CLITUS
Number of Total Listeners: 32

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
28 features selected out of 56 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

     BRUTUS       0.25      1.00      0.40         8
  DARDANIUS       0.00      0.00      0.00         8
     STRATO       0.00      0.00      0.00         8
  VOLUMNIUS       0.00      0.00      0.00         8

avg / total       0.06      0.25      0.10        32

=========================================================================================================

=========================================================================================================
Speaker: SECOND CITIZEN
Number of Total Listeners: 108

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
49 features selected out of 98 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        13
     ANTONY       0.00      0.00      0.00        13
    CASSIUS       0.00      0.00      0.00        14
   CITIZENS       0.00      0.00      0.00        14
FIRST CITIZEN       0.00      0.00      0.00        18
FOURTH CITIZEN       0.00      0.00      0.00        18
THIRD CITIZEN       0.17      1.00      0.29        18

avg / total       0.03      0.17      0.05       108

=========================================================================================================

Play: 16

=========================================================================================================
Speaker: CORNWALL
Number of Total Listeners: 257

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
108 features selected out of 217 total
F1 mean: 0.05 (+/- 0.03)

             precision    recall  f1-score   support

      EDGAR       0.00      0.00      0.00         5
     EDMUND       0.26      0.42      0.32        43
       FOOL       0.00      0.00      0.00        10
  GENTLEMAN       0.00      0.00      0.00        10
 GLOUCESTER       0.20      0.02      0.04        44
    GONERIL       0.20      0.04      0.07        23
       KENT       0.00      0.00      0.00        26
       LEAR       0.00      0.00      0.00        10
     OSWALD       0.00      0.00      0.00        38
      REGAN       0.18      0.69      0.29        48

avg / total       0.13      0.21      0.12       257

=========================================================================================================

=========================================================================================================
Speaker: ALBANY
Number of Total Listeners: 327

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
113 features selected out of 226 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

    CAPTAIN       0.00      0.00      0.00        31
   CORDELIA       0.00      0.00      0.00        32
      EDGAR       0.00      0.00      0.00        24
     EDMUND       0.14      0.21      0.16        38
       FOOL       0.00      0.00      0.00         8
  GENTLEMAN       0.00      0.00      0.00        19
    GONERIL       0.22      0.80      0.35        40
     HERALD       0.00      0.00      0.00        22
       KENT       0.12      0.05      0.07        19
     KNIGHT       0.00      0.00      0.00         8
       LEAR       0.13      0.38      0.19        40
     OSWALD       0.00      0.00      0.00         8
      REGAN       0.00      0.00      0.00        38

avg / total       0.07      0.17      0.09       327

=========================================================================================================

=========================================================================================================
Speaker: DOCTOR
Number of Total Listeners: 27

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
19 features selected out of 39 total
F1 mean: 0.08 (+/- 0.08)

             precision    recall  f1-score   support

   CORDELIA       0.30      1.00      0.46         8
  GENTLEMAN       0.00      0.00      0.00         7
       KENT       0.00      0.00      0.00         7
       LEAR       0.00      0.00      0.00         5

avg / total       0.09      0.30      0.14        27

=========================================================================================================

=========================================================================================================
Speaker: CORDELIA
Number of Total Listeners: 154

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
58 features selected out of 116 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        12
   CORNWALL       0.00      0.00      0.00        12
     DOCTOR       0.00      0.00      0.00        17
     EDMUND       0.00      0.00      0.00        13
  GENTLEMAN       0.00      0.00      0.00        15
 GLOUCESTER       0.00      0.00      0.00        12
    GONERIL       0.00      0.00      0.00        12
       KENT       0.18      1.00      0.30        27
       LEAR       0.00      0.00      0.00        22
      REGAN       0.00      0.00      0.00        12

avg / total       0.03      0.18      0.05       154

=========================================================================================================

=========================================================================================================
Speaker: BURGUNDY
Number of Total Listeners: 50

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
11 features selected out of 22 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

     ALBANY       0.10      1.00      0.18         5
   CORDELIA       0.00      0.00      0.00         5
   CORNWALL       0.00      0.00      0.00         5
     EDMUND       0.00      0.00      0.00         5
     FRANCE       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         5
    GONERIL       0.00      0.00      0.00         5
       KENT       0.00      0.00      0.00         5
       LEAR       0.00      0.00      0.00         5
      REGAN       0.00      0.00      0.00         5

avg / total       0.01      0.10      0.02        50

=========================================================================================================

=========================================================================================================
Speaker: EDMUND
Number of Total Listeners: 209

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
141 features selected out of 283 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        18
    CAPTAIN       0.00      0.00      0.00        16
   CORDELIA       0.00      0.00      0.00        18
   CORNWALL       0.00      0.00      0.00         8
      EDGAR       0.16      0.24      0.19        29
  GENTLEMAN       0.00      0.00      0.00         5
 GLOUCESTER       0.40      0.92      0.56        38
    GONERIL       0.00      0.00      0.00        12
     HERALD       0.00      0.00      0.00        11
       KENT       0.00      0.00      0.00         8
       LEAR       0.00      0.00      0.00        18
      REGAN       0.21      0.57      0.30        28

avg / total       0.12      0.28      0.17       209

=========================================================================================================

=========================================================================================================
Speaker: FOOL
Number of Total Listeners: 190

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
160 features selected out of 321 total
F1 mean: 0.08 (+/- 0.01)

             precision    recall  f1-score   support

      EDGAR       0.00      0.00      0.00        12
  GENTLEMAN       0.00      0.00      0.00         7
 GLOUCESTER       0.00      0.00      0.00         7
    GONERIL       0.00      0.00      0.00         6
       KENT       0.26      0.18      0.21        56
     KNIGHT       0.00      0.00      0.00        22
       LEAR       0.32      0.83      0.46        58
     OSWALD       0.00      0.00      0.00        22

avg / total       0.17      0.31      0.20       190

=========================================================================================================

=========================================================================================================
Speaker: GENTLEMAN
Number of Total Listeners: 132

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
89 features selected out of 178 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

     ALBANY       0.50      0.44      0.47         9
   CORDELIA       0.00      0.00      0.00         8
   CORNWALL       0.00      0.00      0.00         5
     DOCTOR       0.00      0.00      0.00         5
      EDGAR       0.00      0.00      0.00        12
       FOOL       0.00      0.00      0.00         8
 GLOUCESTER       0.00      0.00      0.00        14
    GONERIL       0.00      0.00      0.00        11
       KENT       0.43      0.73      0.54        22
       LEAR       0.22      0.76      0.34        25
     OSWALD       0.00      0.00      0.00         5
      REGAN       0.00      0.00      0.00         8

avg / total       0.15      0.30      0.19       132

=========================================================================================================

=========================================================================================================
Speaker: EDGAR
Number of Total Listeners: 347

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
192 features selected out of 384 total
F1 mean: 0.04 (+/- 0.01)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        21
    CAPTAIN       0.00      0.00      0.00        18
   CORDELIA       0.00      0.00      0.00        18
     EDMUND       0.14      0.03      0.05        31
       FOOL       0.00      0.00      0.00        22
  GENTLEMAN       0.00      0.00      0.00        23
 GLOUCESTER       0.30      0.93      0.45        68
    GONERIL       0.00      0.00      0.00         6
     HERALD       0.00      0.00      0.00        18
       KENT       0.00      0.00      0.00        30
       LEAR       0.17      0.39      0.24        57
    OLD MAN       0.00      0.00      0.00         8
     OSWALD       0.00      0.00      0.00         6
      REGAN       0.00      0.00      0.00        21

avg / total       0.10      0.25      0.13       347

=========================================================================================================

=========================================================================================================
Speaker: GONERIL
Number of Total Listeners: 273

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
113 features selected out of 227 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ALBANY       0.19      0.62      0.29        32
   BURGUNDY       0.00      0.00      0.00         6
    CAPTAIN       0.00      0.00      0.00         9
   CORDELIA       0.00      0.00      0.00        16
   CORNWALL       0.00      0.00      0.00        16
     EDMUND       0.33      0.04      0.07        24
       FOOL       0.00      0.00      0.00        18
     FRANCE       0.00      0.00      0.00         6
  GENTLEMAN       0.00      0.00      0.00         8
 GLOUCESTER       0.00      0.00      0.00        14
       KENT       0.00      0.00      0.00        25
     KNIGHT       0.00      0.00      0.00        11
       LEAR       0.15      0.47      0.22        34
     OSWALD       0.28      0.28      0.28        25
      REGAN       0.20      0.21      0.20        29

avg / total       0.12      0.18      0.12       273

=========================================================================================================

=========================================================================================================
Speaker: OSWALD
Number of Total Listeners: 76

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
69 features selected out of 138 total
F1 mean: 0.06 (+/- 0.06)

             precision    recall  f1-score   support

      EDGAR       0.00      0.00      0.00         5
     EDMUND       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         8
    GONERIL       0.00      0.00      0.00         7
       KENT       0.28      0.94      0.44        18
     KNIGHT       0.00      0.00      0.00         5
       LEAR       0.00      0.00      0.00        10
      REGAN       0.56      0.69      0.62        13

avg / total       0.16      0.34      0.21        76

=========================================================================================================

=========================================================================================================
Speaker: REGAN
Number of Total Listeners: 365

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
149 features selected out of 298 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        16
   BURGUNDY       0.00      0.00      0.00         5
    CAPTAIN       0.00      0.00      0.00         7
   CORDELIA       0.00      0.00      0.00        13
   CORNWALL       0.17      0.50      0.25        48
      EDGAR       0.00      0.00      0.00         5
     EDMUND       0.20      0.60      0.31        45
       FOOL       0.00      0.00      0.00        18
     FRANCE       0.00      0.00      0.00         5
  GENTLEMAN       0.00      0.00      0.00        18
 GLOUCESTER       0.15      0.11      0.12        47
    GONERIL       0.14      0.10      0.12        41
       KENT       0.00      0.00      0.00        28
       LEAR       0.17      0.03      0.05        31
     OSWALD       0.50      0.29      0.37        38

avg / total       0.15      0.20      0.14       365

=========================================================================================================

=========================================================================================================
Speaker: FRANCE
Number of Total Listeners: 50

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
14 features selected out of 28 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

     ALBANY       0.10      1.00      0.18         5
   BURGUNDY       0.00      0.00      0.00         5
   CORDELIA       0.00      0.00      0.00         5
   CORNWALL       0.00      0.00      0.00         5
     EDMUND       0.00      0.00      0.00         5
 GLOUCESTER       0.00      0.00      0.00         5
    GONERIL       0.00      0.00      0.00         5
       KENT       0.00      0.00      0.00         5
       LEAR       0.00      0.00      0.00         5
      REGAN       0.00      0.00      0.00         5

avg / total       0.01      0.10      0.02        50

=========================================================================================================

=========================================================================================================
Speaker: LEAR
Number of Total Listeners: 856

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
281 features selected out of 562 total
F1 mean: 0.02 (+/- 0.00)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        40
   BURGUNDY       0.00      0.00      0.00         7
    CAPTAIN       0.00      0.00      0.00        11
   CORDELIA       0.00      0.00      0.00        45
   CORNWALL       0.00      0.00      0.00        44
     DOCTOR       0.00      0.00      0.00         8
      EDGAR       0.00      0.00      0.00        51
     EDMUND       0.00      0.00      0.00        37
       FOOL       0.50      0.01      0.02       106
     FRANCE       0.00      0.00      0.00         7
  GENTLEMAN       0.00      0.00      0.00        59
 GLOUCESTER       0.45      0.06      0.11        83
    GONERIL       0.00      0.00      0.00        45
     HERALD       0.00      0.00      0.00        11
       KENT       0.20      0.99      0.33       166
     KNIGHT       0.00      0.00      0.00        43
     OSWALD       0.00      0.00      0.00        38
      REGAN       0.00      0.00      0.00        55

avg / total       0.14      0.20      0.08       856

=========================================================================================================

=========================================================================================================
Speaker: KENT
Number of Total Listeners: 516

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
212 features selected out of 424 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     ALBANY       0.00      0.00      0.00        21
    CAPTAIN       0.00      0.00      0.00        13
   CORDELIA       0.00      0.00      0.00        29
   CORNWALL       0.00      0.00      0.00        30
     DOCTOR       0.00      0.00      0.00         8
      EDGAR       0.00      0.00      0.00        28
     EDMUND       0.29      0.05      0.08        42
       FOOL       0.50      0.02      0.04        45
  GENTLEMAN       0.33      0.14      0.20        50
 GLOUCESTER       0.19      0.10      0.13        48
    GONERIL       0.00      0.00      0.00        14
     HERALD       0.00      0.00      0.00        13
     KNIGHT       0.00      0.00      0.00        14
       LEAR       0.17      0.90      0.28        82
     OSWALD       0.38      0.17      0.23        36
      REGAN       0.00      0.00      0.00        43

avg / total       0.17      0.18      0.10       516

=========================================================================================================

=========================================================================================================
Speaker: GLOUCESTER
Number of Total Listeners: 330

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
199 features selected out of 398 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

   CORNWALL       0.12      0.04      0.06        28
      EDGAR       0.31      0.99      0.47        70
     EDMUND       0.32      0.57      0.41        54
       FOOL       0.00      0.00      0.00        19
  GENTLEMAN       0.00      0.00      0.00        13
    GONERIL       0.00      0.00      0.00        16
       KENT       0.25      0.03      0.06        32
       LEAR       0.00      0.00      0.00        36
    OLD MAN       0.00      0.00      0.00        12
     OSWALD       0.00      0.00      0.00        22
      REGAN       0.00      0.00      0.00        28

avg / total       0.15      0.31      0.18       330

=========================================================================================================

Play: 17

=========================================================================================================
Speaker: KING
Number of Total Listeners: 780

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
447 features selected out of 894 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00        12
    BEROWNE       0.14      0.91      0.25       114
      BOYET       0.00      0.00      0.00        55
    COSTARD       0.00      0.00      0.00        54
       DULL       0.00      0.00      0.00        20
     DUMAIN       0.15      0.06      0.09        99
 FIRST LORD       0.00      0.00      0.00        11
 HOLOFERNES       0.00      0.00      0.00         9
 JAQUENETTA       0.00      0.00      0.00        20
  KATHARINE       0.00      0.00      0.00        56
 LONGAVILLE       0.18      0.04      0.07       100
    MARCADE       0.00      0.00      0.00         8
      MARIA       0.00      0.00      0.00        56
       MOTH       0.00      0.00      0.00        45
  NATHANIEL       0.00      0.00      0.00         9
PRINCESS OF FRANCE       0.00      0.00      0.00        56
   ROSALINE       0.00      0.00      0.00        56

avg / total       0.06      0.15      0.06       780

=========================================================================================================

=========================================================================================================
Speaker: MOTH
Number of Total Listeners: 178

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
233 features selected out of 466 total
F1 mean: 0.05 (+/- 0.01)

             precision    recall  f1-score   support

     ARMADO       0.39      1.00      0.56        70
    BEROWNE       0.00      0.00      0.00         5
      BOYET       0.00      0.00      0.00         7
    COSTARD       0.00      0.00      0.00        23
       DULL       0.00      0.00      0.00        14
 HOLOFERNES       0.00      0.00      0.00        12
  KATHARINE       0.00      0.00      0.00         7
       KING       0.00      0.00      0.00         7
      MARIA       0.00      0.00      0.00         7
  NATHANIEL       0.00      0.00      0.00        12
PRINCESS OF FRANCE       0.00      0.00      0.00         7
   ROSALINE       0.00      0.00      0.00         7

avg / total       0.15      0.39      0.22       178

=========================================================================================================

=========================================================================================================
Speaker: MARIA
Number of Total Listeners: 117

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
105 features selected out of 211 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

    BEROWNE       0.00      0.00      0.00        10
      BOYET       0.00      0.00      0.00        16
    COSTARD       0.00      0.00      0.00         6
     DUMAIN       0.00      0.00      0.00         6
 FIRST LORD       0.00      0.00      0.00         6
  KATHARINE       0.00      0.00      0.00        19
       KING       0.00      0.00      0.00        10
       MOTH       0.00      0.00      0.00         6
PRINCESS OF FRANCE       0.00      0.00      0.00        19
   ROSALINE       0.16      1.00      0.28        19

avg / total       0.03      0.16      0.05       117

=========================================================================================================

=========================================================================================================
Speaker: PRINCESS OF FRANCE
Number of Total Listeners: 795

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
471 features selected out of 942 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00        16
    BEROWNE       0.00      0.00      0.00        61
      BOYET       0.12      0.13      0.12        94
    COSTARD       0.00      0.00      0.00        28
     DUMAIN       0.07      0.02      0.03        52
 FIRST LORD       0.00      0.00      0.00        21
   FORESTER       0.00      0.00      0.00        18
 HOLOFERNES       0.00      0.00      0.00        11
  KATHARINE       0.14      0.38      0.20       104
       KING       0.00      0.00      0.00        61
 LONGAVILLE       0.00      0.00      0.00        52
    MARCADE       0.00      0.00      0.00         9
      MARIA       0.00      0.00      0.00       104
       MOTH       0.00      0.00      0.00        47
  NATHANIEL       0.00      0.00      0.00        13
   ROSALINE       0.13      0.49      0.21       104

avg / total       0.05      0.13      0.07       795

=========================================================================================================

=========================================================================================================
Speaker: NATHANIEL
Number of Total Listeners: 48

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
153 features selected out of 307 total
F1 mean: 0.16 (+/- 0.08)

             precision    recall  f1-score   support

    COSTARD       1.00      0.22      0.36         9
       DULL       0.38      0.82      0.52        17
 HOLOFERNES       0.33      0.18      0.23        17
 JAQUENETTA       0.00      0.00      0.00         5

avg / total       0.44      0.40      0.33        48

=========================================================================================================

=========================================================================================================
Speaker: BOYET
Number of Total Listeners: 610

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
398 features selected out of 796 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00        13
    BEROWNE       0.00      0.00      0.00        52
    COSTARD       0.00      0.00      0.00        28
     DUMAIN       0.00      0.00      0.00        24
 FIRST LORD       0.00      0.00      0.00        25
   FORESTER       0.00      0.00      0.00        17
 HOLOFERNES       0.00      0.00      0.00        10
  KATHARINE       0.13      0.56      0.21        79
       KING       0.14      0.04      0.06        53
 LONGAVILLE       0.00      0.00      0.00        29
      MARIA       0.16      0.04      0.06        79
       MOTH       0.00      0.00      0.00        31
  NATHANIEL       0.00      0.00      0.00        12
PRINCESS OF FRANCE       0.12      0.37      0.18        79
   ROSALINE       0.25      0.01      0.02        79

avg / total       0.10      0.13      0.07       610

=========================================================================================================

=========================================================================================================
Speaker: JAQUENETTA
Number of Total Listeners: 35

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
36 features selected out of 73 total
F1 mean: 0.10 (+/- 0.11)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00         6
    COSTARD       0.37      1.00      0.54        13
       DULL       0.00      0.00      0.00        10
       MOTH       0.00      0.00      0.00         6

avg / total       0.14      0.37      0.20        35

=========================================================================================================

=========================================================================================================
Speaker: KATHARINE
Number of Total Listeners: 253

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
133 features selected out of 266 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

    BEROWNE       0.00      0.00      0.00        25
      BOYET       0.00      0.00      0.00        27
     DUMAIN       0.00      0.00      0.00        20
 FIRST LORD       0.00      0.00      0.00        13
       KING       0.00      0.00      0.00        25
 LONGAVILLE       0.00      0.00      0.00        19
      MARIA       0.15      0.43      0.22        37
       MOTH       0.00      0.00      0.00        13
PRINCESS OF FRANCE       0.15      0.38      0.21        37
   ROSALINE       0.14      0.19      0.16        37

avg / total       0.06      0.15      0.09       253

=========================================================================================================

=========================================================================================================
Speaker: ROSALINE
Number of Total Listeners: 454

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
303 features selected out of 606 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

    BEROWNE       0.00      0.00      0.00        44
      BOYET       0.17      0.06      0.08        53
    COSTARD       0.00      0.00      0.00        10
     DUMAIN       0.00      0.00      0.00        27
 FIRST LORD       0.00      0.00      0.00         8
   FORESTER       0.00      0.00      0.00         6
  KATHARINE       0.15      0.74      0.25        66
       KING       0.11      0.02      0.04        44
 LONGAVILLE       0.00      0.00      0.00        27
      MARIA       0.12      0.05      0.07        66
       MOTH       0.00      0.00      0.00        37
PRINCESS OF FRANCE       0.15      0.15      0.15        66

avg / total       0.09      0.15      0.08       454

=========================================================================================================

=========================================================================================================
Speaker: ARMADO
Number of Total Listeners: 415

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
362 features selected out of 725 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

    BEROWNE       0.00      0.00      0.00        19
      BOYET       0.00      0.00      0.00        19
    COSTARD       0.11      0.08      0.09        52
       DULL       0.00      0.00      0.00        22
     DUMAIN       0.00      0.00      0.00        19
 HOLOFERNES       0.00      0.00      0.00        29
 JAQUENETTA       0.00      0.00      0.00         6
  KATHARINE       0.00      0.00      0.00        19
       KING       0.00      0.00      0.00        19
 LONGAVILLE       0.00      0.00      0.00        19
    MARCADE       0.00      0.00      0.00         5
      MARIA       0.00      0.00      0.00        19
       MOTH       0.26      0.96      0.41       101
  NATHANIEL       0.00      0.00      0.00        29
PRINCESS OF FRANCE       0.00      0.00      0.00        19
   ROSALINE       0.00      0.00      0.00        19

avg / total       0.08      0.24      0.11       415

=========================================================================================================

=========================================================================================================
Speaker: BEROWNE
Number of Total Listeners: 1125

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
772 features selected out of 1544 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00        33
      BOYET       0.00      0.00      0.00        84
    COSTARD       0.00      0.00      0.00        77
       DULL       0.00      0.00      0.00        10
     DUMAIN       0.17      0.06      0.09       128
 FIRST LORD       0.00      0.00      0.00        18
 HOLOFERNES       0.00      0.00      0.00        24
 JAQUENETTA       0.20      0.06      0.09        17
  KATHARINE       0.00      0.00      0.00        85
       KING       0.13      0.86      0.22       149
 LONGAVILLE       0.19      0.08      0.12       134
    MARCADE       0.00      0.00      0.00         8
      MARIA       0.00      0.00      0.00        85
       MOTH       0.31      0.07      0.11        76
  NATHANIEL       0.00      0.00      0.00        27
PRINCESS OF FRANCE       0.00      0.00      0.00        85
   ROSALINE       0.00      0.00      0.00        85

avg / total       0.08      0.14      0.06      1125

=========================================================================================================

=========================================================================================================
Speaker: DUMAIN
Number of Total Listeners: 479

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
138 features selected out of 276 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00        27
    BEROWNE       0.11      0.85      0.19        53
      BOYET       0.00      0.00      0.00        33
    COSTARD       0.00      0.00      0.00        34
 HOLOFERNES       0.00      0.00      0.00        27
 JAQUENETTA       0.00      0.00      0.00         7
  KATHARINE       0.00      0.00      0.00        33
       KING       0.09      0.08      0.08        53
 LONGAVILLE       0.25      0.08      0.12        50
    MARCADE       0.00      0.00      0.00         5
      MARIA       0.00      0.00      0.00        33
       MOTH       0.00      0.00      0.00        31
  NATHANIEL       0.00      0.00      0.00        27
PRINCESS OF FRANCE       0.00      0.00      0.00        33
   ROSALINE       0.00      0.00      0.00        33

avg / total       0.05      0.11      0.04       479

=========================================================================================================

=========================================================================================================
Speaker: COSTARD
Number of Total Listeners: 490

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
301 features selected out of 602 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

     ARMADO       0.50      0.04      0.07        26
    BEROWNE       0.14      0.72      0.23        54
      BOYET       0.00      0.00      0.00        32
       DULL       0.21      0.10      0.13        31
     DUMAIN       0.00      0.00      0.00        46
   FORESTER       0.00      0.00      0.00        12
 HOLOFERNES       0.00      0.00      0.00         9
 JAQUENETTA       0.00      0.00      0.00         6
  KATHARINE       0.00      0.00      0.00        32
       KING       0.00      0.00      0.00        46
 LONGAVILLE       0.16      0.09      0.11        46
      MARIA       0.17      0.28      0.21        32
       MOTH       0.21      0.53      0.30        43
  NATHANIEL       0.00      0.00      0.00        11
PRINCESS OF FRANCE       0.00      0.00      0.00        32
   ROSALINE       0.00      0.00      0.00        32

avg / total       0.10      0.16      0.09       490

=========================================================================================================

=========================================================================================================
Speaker: HOLOFERNES
Number of Total Listeners: 296

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
328 features selected out of 656 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     ARMADO       0.08      0.03      0.05        30
    BEROWNE       0.00      0.00      0.00        10
      BOYET       0.00      0.00      0.00        10
    COSTARD       0.00      0.00      0.00        39
       DULL       0.36      0.11      0.17        44
     DUMAIN       0.00      0.00      0.00        10
 JAQUENETTA       0.00      0.00      0.00         9
  KATHARINE       0.00      0.00      0.00        10
       KING       0.00      0.00      0.00        10
 LONGAVILLE       0.00      0.00      0.00        10
      MARIA       0.00      0.00      0.00        10
       MOTH       0.08      0.03      0.05        30
  NATHANIEL       0.18      0.87      0.30        54
PRINCESS OF FRANCE       0.00      0.00      0.00        10
   ROSALINE       0.00      0.00      0.00        10

avg / total       0.10      0.18      0.09       296

=========================================================================================================

=========================================================================================================
Speaker: DULL
Number of Total Listeners: 26

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
72 features selected out of 144 total
F1 mean: 0.34 (+/- 0.18)

             precision    recall  f1-score   support

    COSTARD       0.78      0.88      0.82         8
 HOLOFERNES       0.00      0.00      0.00         9
  NATHANIEL       0.47      0.89      0.62         9

avg / total       0.40      0.58      0.47        26

=========================================================================================================

=========================================================================================================
Speaker: LONGAVILLE
Number of Total Listeners: 272

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
138 features selected out of 276 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

     ARMADO       0.00      0.00      0.00         8
    BEROWNE       0.00      0.00      0.00        41
      BOYET       0.00      0.00      0.00        19
    COSTARD       0.00      0.00      0.00        15
     DUMAIN       0.33      0.03      0.06        32
 FIRST LORD       0.00      0.00      0.00         5
 HOLOFERNES       0.00      0.00      0.00         8
 JAQUENETTA       0.00      0.00      0.00         5
  KATHARINE       0.00      0.00      0.00        19
       KING       0.15      0.98      0.26        41
      MARIA       0.00      0.00      0.00        19
       MOTH       0.00      0.00      0.00        14
  NATHANIEL       0.00      0.00      0.00         8
PRINCESS OF FRANCE       0.00      0.00      0.00        19
   ROSALINE       0.00      0.00      0.00        19

avg / total       0.06      0.15      0.05       272

=========================================================================================================

Play: 18

=========================================================================================================
Speaker: THIRD WITCH
Number of Total Listeners: 27

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
49 features selected out of 99 total
F1 mean: 0.17 (+/- 0.06)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
FIRST WITCH       0.41      1.00      0.58        11
SECOND WITCH       0.00      0.00      0.00        11

avg / total       0.17      0.41      0.24        27

=========================================================================================================

=========================================================================================================
Speaker: LENNOX
Number of Total Listeners: 47

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
73 features selected out of 146 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
LADY MACBETH       0.00      0.00      0.00         5
    MACBETH       0.30      1.00      0.47        14
    MACDUFF       0.00      0.00      0.00         6
     PORTER       0.00      0.00      0.00         6
       ROSS       1.00      0.17      0.29         6
      THIRD       0.00      0.00      0.00         5

avg / total       0.22      0.32      0.18        47

=========================================================================================================

=========================================================================================================
Speaker: MACDUFF
Number of Total Listeners: 147

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
301 features selected out of 602 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

     BANQUO       0.00      0.00      0.00         5
LADY MACBETH       0.00      0.00      0.00         6
     LENNOX       0.27      0.18      0.21        17
    MACBETH       0.33      0.12      0.18        16
    MALCOLM       0.35      1.00      0.52        39
    OLD MAN       0.00      0.00      0.00         7
     PORTER       0.33      0.12      0.18        16
       ROSS       0.50      0.21      0.29        29
     SIWARD       0.00      0.00      0.00         7
YOUNG SIWARD       1.00      0.20      0.33         5

avg / total       0.33      0.36      0.27       147

=========================================================================================================

=========================================================================================================
Speaker: DOCTOR
Number of Total Listeners: 25

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
82 features selected out of 165 total
F1 mean: 0.34 (+/- 0.09)

             precision    recall  f1-score   support

GENTLEWOMAN       0.60      1.00      0.75        15
LADY MACBETH       0.00      0.00      0.00        10

avg / total       0.36      0.60      0.45        25

=========================================================================================================

=========================================================================================================
Speaker: MALCOLM
Number of Total Listeners: 71

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
340 features selected out of 680 total
F1 mean: 0.08 (+/- 0.07)

             precision    recall  f1-score   support

  DONALBAIN       0.00      0.00      0.00         6
     LENNOX       0.50      0.22      0.31         9
    MACDUFF       0.49      0.97      0.65        32
       ROSS       0.50      0.12      0.19        17
     SIWARD       0.00      0.00      0.00         7

avg / total       0.40      0.49      0.38        71

=========================================================================================================

=========================================================================================================
Speaker: LADY MACBETH
Number of Total Listeners: 147

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
311 features selected out of 622 total
F1 mean: 0.04 (+/- 0.01)

             precision    recall  f1-score   support

     BANQUO       0.00      0.00      0.00         5
     DOCTOR       0.50      0.50      0.50         6
FIRST MURTHERER       0.00      0.00      0.00        13
GENTLEWOMAN       0.00      0.00      0.00         6
     LENNOX       0.25      0.10      0.14        20
      LORDS       0.00      0.00      0.00        14
    MACBETH       0.35      1.00      0.51        46
    MACDUFF       0.00      0.00      0.00         6
  MURTHERER       0.00      0.00      0.00        13
       ROSS       0.00      0.00      0.00        18

avg / total       0.16      0.35      0.20       147

=========================================================================================================

=========================================================================================================
Speaker: SIWARD
Number of Total Listeners: 24

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
73 features selected out of 146 total
F1 mean: 0.10 (+/- 0.18)

             precision    recall  f1-score   support

    MACDUFF       0.00      0.00      0.00         6
    MALCOLM       0.46      1.00      0.63        11
       ROSS       0.00      0.00      0.00         7

avg / total       0.21      0.46      0.29        24

=========================================================================================================

=========================================================================================================
Speaker: BANQUO
Number of Total Listeners: 147

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
215 features selected out of 430 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        12
      ANGUS       0.00      0.00      0.00         8
  ATTENDANT       0.00      0.00      0.00         5
FIRST WITCH       0.00      0.00      0.00        12
    FLEANCE       1.00      0.20      0.33        10
LADY MACBETH       0.00      0.00      0.00         7
     LENNOX       0.00      0.00      0.00         9
    MACBETH       0.18      1.00      0.31        25
    MACDUFF       0.33      0.11      0.17         9
    OLD MAN       0.00      0.00      0.00         6
       ROSS       0.25      0.07      0.11        15
SECOND WITCH       0.00      0.00      0.00        12
    SERVANT       0.00      0.00      0.00         5
THIRD WITCH       0.00      0.00      0.00        12

avg / total       0.14      0.20      0.10       147

=========================================================================================================

=========================================================================================================
Speaker: FIRST WITCH
Number of Total Listeners: 76

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
126 features selected out of 252 total
F1 mean: 0.12 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        11
     HECATE       0.00      0.00      0.00         8
    MACBETH       0.00      0.00      0.00        11
SECOND WITCH       0.33      0.04      0.08        23
THIRD WITCH       0.30      0.96      0.46        23

avg / total       0.19      0.30      0.16        76

=========================================================================================================

=========================================================================================================
Speaker: ALL
Number of Total Listeners: 42

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
44 features selected out of 89 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

FIRST WITCH       0.00      0.00      0.00        10
     HECATE       0.00      0.00      0.00         5
    MACBETH       0.29      0.71      0.42         7
SECOND WITCH       0.00      0.00      0.00        10
THIRD WITCH       0.28      0.70      0.40        10

avg / total       0.12      0.29      0.16        42

=========================================================================================================

=========================================================================================================
Speaker: DUNCAN
Number of Total Listeners: 100

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
144 features selected out of 288 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

      ANGUS       0.00      0.00      0.00         9
     BANQUO       0.17      0.22      0.19         9
  DONALBAIN       0.00      0.00      0.00        20
     LENNOX       0.20      0.90      0.33        20
    MALCOLM       0.00      0.00      0.00        20
       ROSS       0.00      0.00      0.00        13
   SERGEANT       0.00      0.00      0.00         9

avg / total       0.06      0.20      0.08       100

=========================================================================================================

=========================================================================================================
Speaker: MACBETH
Number of Total Listeners: 578

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
800 features selected out of 1600 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.20      0.43      0.28        30
      ANGUS       0.00      0.00      0.00        10
  ATTENDANT       0.12      0.07      0.09        15
     BANQUO       0.25      0.17      0.20        35
     DOCTOR       0.60      0.27      0.37        11
  DONALBAIN       0.00      0.00      0.00         7
FIRST MURTHERER       0.00      0.00      0.00        30
FIRST WITCH       0.00      0.00      0.00        23
    FLEANCE       0.50      0.14      0.22         7
     HECATE       0.00      0.00      0.00        10
LADY MACBETH       0.20      0.82      0.33        72
     LENNOX       0.19      0.33      0.24        61
      LORDS       0.00      0.00      0.00        25
    MACDUFF       0.25      0.12      0.16        33
    MALCOLM       0.00      0.00      0.00        12
  MURTHERER       0.00      0.00      0.00        19
    OLD MAN       0.00      0.00      0.00        15
     PORTER       0.00      0.00      0.00        13
       ROSS       0.15      0.13      0.14        55
SECOND MURTHERER       0.00      0.00      0.00         7
SECOND WITCH       0.00      0.00      0.00        23
    SERVANT       0.00      0.00      0.00        10
     SEYTON       0.71      0.45      0.56        11
     SIWARD       0.00      0.00      0.00         5
      THIRD       0.00      0.00      0.00         7
THIRD WITCH       0.17      0.04      0.07        23
YOUNG SIWARD       0.40      0.22      0.29         9

avg / total       0.15      0.21      0.15       578

=========================================================================================================

=========================================================================================================
Speaker: FIRST MURTHERER
Number of Total Listeners: 87

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
55 features selected out of 111 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

  ATTENDANT       0.00      0.00      0.00         7
     BANQUO       0.00      0.00      0.00         5
LADY MACBETH       0.00      0.00      0.00        10
     LENNOX       0.00      0.00      0.00        10
    MACBETH       0.00      0.00      0.00        10
    MACDUFF       0.00      0.00      0.00         7
    OLD MAN       0.00      0.00      0.00         7
       ROSS       0.25      0.20      0.22        10
SECOND MURTHERER       0.18      1.00      0.30        14
THIRD MURTHERER       0.00      0.00      0.00         7

avg / total       0.06      0.18      0.07        87

=========================================================================================================

=========================================================================================================
Speaker: SECOND WITCH
Number of Total Listeners: 41

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 92 total
F1 mean: 0.13 (+/- 0.08)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         8
FIRST WITCH       0.30      0.21      0.25        14
    MACBETH       0.00      0.00      0.00         5
THIRD WITCH       0.35      0.79      0.49        14

avg / total       0.22      0.34      0.25        41

=========================================================================================================

=========================================================================================================
Speaker: ROSS
Number of Total Listeners: 62

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
231 features selected out of 463 total
F1 mean: 0.09 (+/- 0.08)

             precision    recall  f1-score   support

     LENNOX       0.50      0.14      0.22         7
    MACBETH       1.00      0.40      0.57         5
    MACDUFF       0.43      0.80      0.56        20
    MALCOLM       0.58      0.55      0.56        20
    OLD MAN       1.00      0.20      0.33        10

avg / total       0.62      0.52      0.49        62

=========================================================================================================

Play: 19

=========================================================================================================
Speaker: PORTIA
Number of Total Listeners: 592

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
674 features selected out of 1348 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
    ANTONIO       0.00      0.00      0.00        55
    ARRAGON       0.00      0.00      0.00         8
   BASSANIO       0.16      0.07      0.10        69
      CLERK       0.00      0.00      0.00        39
DUKE OF VENICE       0.00      0.00      0.00        39
   GRATIANO       0.13      0.04      0.06        71
    JESSICA       0.14      0.03      0.05        37
  LAUNCELOT       0.00      0.00      0.00        24
    LORENZO       0.00      0.00      0.00        37
    NERISSA       0.20      0.92      0.32       113
PRINCE OF MOROCCO       1.00      0.14      0.25         7
    SALERIO       0.00      0.00      0.00        45
    SHYLOCK       0.00      0.00      0.00        39

avg / total       0.09      0.19      0.09       592

=========================================================================================================

=========================================================================================================
Speaker: SOLANIO
Number of Total Listeners: 22

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
146 features selected out of 292 total
F1 mean: 0.42 (+/- 0.05)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00         5
    SALERIO       0.77      1.00      0.87        17

avg / total       0.60      0.77      0.67        22

=========================================================================================================

=========================================================================================================
Speaker: ANTONIO
Number of Total Listeners: 196

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
311 features selected out of 622 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

   BASSANIO       0.21      0.90      0.34        39
      CLERK       0.00      0.00      0.00         7
DUKE OF VENICE       0.00      0.00      0.00        11
   GRATIANO       0.23      0.11      0.15        27
    JESSICA       0.00      0.00      0.00         6
  LAUNCELOT       0.00      0.00      0.00         6
    LORENZO       0.00      0.00      0.00        14
    NERISSA       0.00      0.00      0.00        13
     PORTIA       0.00      0.00      0.00        13
    SALERIO       0.15      0.09      0.11        22
    SHYLOCK       0.00      0.00      0.00        23
    SOLANIO       0.67      0.27      0.38        15

avg / total       0.14      0.22      0.13       196

=========================================================================================================

=========================================================================================================
Speaker: LAUNCELOT
Number of Total Listeners: 71

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
225 features selected out of 450 total
F1 mean: 0.08 (+/- 0.06)

             precision    recall  f1-score   support

   BASSANIO       0.00      0.00      0.00         8
      GOBBO       0.59      0.95      0.73        21
    JESSICA       0.54      0.76      0.63        17
   LEONARDO       0.00      0.00      0.00         8
    LORENZO       0.58      0.58      0.58        12
    SHYLOCK       1.00      0.20      0.33         5

avg / total       0.47      0.58      0.49        71

=========================================================================================================

=========================================================================================================
Speaker: NERISSA
Number of Total Listeners: 105

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
175 features selected out of 350 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        10
   BASSANIO       0.00      0.00      0.00        13
   GRATIANO       0.33      0.07      0.11        15
    JESSICA       0.00      0.00      0.00        12
  LAUNCELOT       0.00      0.00      0.00        10
    LORENZO       0.00      0.00      0.00        12
     PORTIA       0.32      1.00      0.49        33

avg / total       0.15      0.32      0.17       105

=========================================================================================================

=========================================================================================================
Speaker: JESSICA
Number of Total Listeners: 39

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
162 features selected out of 324 total
F1 mean: 0.13 (+/- 0.06)

             precision    recall  f1-score   support

   GRATIANO       0.00      0.00      0.00         6
  LAUNCELOT       1.00      0.44      0.62         9
    LORENZO       0.51      1.00      0.68        18
    SALERIO       0.00      0.00      0.00         6

avg / total       0.47      0.56      0.46        39

=========================================================================================================

=========================================================================================================
Speaker: GRATIANO
Number of Total Listeners: 234

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
306 features selected out of 612 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         6
    ANTONIO       0.25      0.08      0.12        26
   BASSANIO       0.17      0.86      0.28        37
      CLERK       0.00      0.00      0.00         9
DUKE OF VENICE       0.00      0.00      0.00        11
      GOBBO       0.00      0.00      0.00         7
    JESSICA       0.00      0.00      0.00        10
  LAUNCELOT       0.00      0.00      0.00        17
    LORENZO       1.00      0.06      0.11        18
    NERISSA       0.19      0.11      0.14        28
     PORTIA       0.00      0.00      0.00        26
    SALERIO       0.35      0.32      0.33        22
    SHYLOCK       0.00      0.00      0.00        11
    SOLANIO       0.00      0.00      0.00         6

avg / total       0.19      0.19      0.11       234

=========================================================================================================

=========================================================================================================
Speaker: GOBBO
Number of Total Listeners: 31

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
80 features selected out of 160 total
F1 mean: 0.24 (+/- 0.06)

             precision    recall  f1-score   support

   BASSANIO       0.00      0.00      0.00         6
  LAUNCELOT       0.61      1.00      0.76        19
   LEONARDO       0.00      0.00      0.00         6

avg / total       0.38      0.61      0.47        31

=========================================================================================================

=========================================================================================================
Speaker: SHYLOCK
Number of Total Listeners: 338

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
489 features selected out of 979 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

    ANTONIO       0.22      0.27      0.24        49
   BASSANIO       0.22      0.61      0.33        54
      CLERK       0.00      0.00      0.00        24
DUKE OF VENICE       0.00      0.00      0.00        33
   GRATIANO       0.00      0.00      0.00        33
    JESSICA       0.67      0.40      0.50         5
  LAUNCELOT       0.67      0.40      0.50         5
        MAN       0.00      0.00      0.00         9
    NERISSA       0.00      0.00      0.00        27
     PORTIA       0.00      0.00      0.00        24
    SALERIO       0.19      0.46      0.27        48
    SOLANIO       0.33      0.22      0.27        18
      TUBAL       0.00      0.00      0.00         9

avg / total       0.13      0.22      0.15       338

=========================================================================================================

=========================================================================================================
Speaker: DUKE OF VENICE
Number of Total Listeners: 114

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
120 features selected out of 241 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        18
   BASSANIO       0.00      0.00      0.00        18
      CLERK       0.00      0.00      0.00         8
   GRATIANO       0.00      0.00      0.00        18
    NERISSA       0.00      0.00      0.00        11
     PORTIA       0.00      0.00      0.00         8
    SALERIO       0.16      1.00      0.27        18
    SHYLOCK       0.00      0.00      0.00        15

avg / total       0.02      0.16      0.04       114

=========================================================================================================

=========================================================================================================
Speaker: LORENZO
Number of Total Listeners: 125

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
289 features selected out of 579 total
F1 mean: 0.06 (+/- 0.03)

             precision    recall  f1-score   support

   GRATIANO       0.40      0.44      0.42        18
    JESSICA       0.38      0.95      0.54        37
  LAUNCELOT       0.30      0.15      0.20        20
    NERISSA       0.00      0.00      0.00         9
     PORTIA       0.00      0.00      0.00         9
    SALERIO       0.33      0.06      0.11        16
    SOLANIO       0.00      0.00      0.00         8
   STEPHANO       0.00      0.00      0.00         8

avg / total       0.26      0.38      0.27       125

=========================================================================================================

=========================================================================================================
Speaker: SALERIO
Number of Total Listeners: 70

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
218 features selected out of 436 total
F1 mean: 0.09 (+/- 0.04)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00         7
   BASSANIO       0.33      0.22      0.27         9
   GRATIANO       0.38      0.33      0.36        15
    LORENZO       0.00      0.00      0.00        11
    SHYLOCK       0.00      0.00      0.00         6
    SOLANIO       0.43      1.00      0.60        22

avg / total       0.26      0.41      0.30        70

=========================================================================================================

=========================================================================================================
Speaker: BASSANIO
Number of Total Listeners: 359

Best model LogisticRegression(C=0.40000000000000002, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
481 features selected out of 963 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.25      0.08      0.12        13
    ANTONIO       0.18      0.28      0.22        39
      CLERK       0.00      0.00      0.00        11
DUKE OF VENICE       0.00      0.00      0.00        17
      GOBBO       0.33      0.18      0.24        11
   GRATIANO       0.18      0.65      0.28        55
    JESSICA       0.00      0.00      0.00        18
  LAUNCELOT       0.33      0.18      0.24        22
   LEONARDO       0.00      0.00      0.00         6
    LORENZO       0.16      0.12      0.14        24
    NERISSA       0.16      0.07      0.10        40
     PORTIA       0.13      0.05      0.07        39
    SALERIO       0.20      0.03      0.06        30
    SHYLOCK       0.73      0.39      0.51        28
    SOLANIO       0.00      0.00      0.00         6

avg / total       0.20      0.21      0.17       359

=========================================================================================================

=========================================================================================================
Speaker: TUBAL
Number of Total Listeners: 32

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
37 features selected out of 74 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

        MAN       0.25      1.00      0.40         8
    SALERIO       0.00      0.00      0.00         8
    SHYLOCK       0.00      0.00      0.00         8
    SOLANIO       0.00      0.00      0.00         8

avg / total       0.06      0.25      0.10        32

=========================================================================================================

Play: 20

=========================================================================================================
Speaker: SIMPLE
Number of Total Listeners: 33

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
86 features selected out of 173 total
F1 mean: 0.35 (+/- 0.32)

             precision    recall  f1-score   support

      EVANS       1.00      0.50      0.67         6
   FALSTAFF       0.50      0.33      0.40         9
       HOST       0.50      0.80      0.62        10
    QUICKLY       1.00      1.00      1.00         8

avg / total       0.71      0.67      0.66        33

=========================================================================================================

=========================================================================================================
Speaker: QUICKLY
Number of Total Listeners: 168

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
288 features selected out of 576 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00         6
      CAIUS       0.50      0.08      0.13        13
      EVANS       0.00      0.00      0.00         7
   FALSTAFF       0.40      0.96      0.56        26
     FENTON       0.50      0.62      0.55        13
   MRS PAGE       0.29      0.77      0.42        13
       PAGE       0.00      0.00      0.00         5
     PISTOL       0.33      0.07      0.11        15
      ROBIN       0.00      0.00      0.00        15
      RUGBY       0.44      0.25      0.32        16
    SHALLOW       0.00      0.00      0.00         6
     SIMPLE       0.38      0.79      0.51        19
    SLENDER       0.00      0.00      0.00         6
    WILLIAM       0.00      0.00      0.00         8

avg / total       0.28      0.38      0.27       168

=========================================================================================================

=========================================================================================================
Speaker: FALSTAFF
Number of Total Listeners: 382

Best model LogisticRegression(C=0.90000000000000002, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
564 features selected out of 1129 total
F1 mean: 0.05 (+/- 0.04)

             precision    recall  f1-score   support

   BARDOLPH       0.44      0.38      0.41        29
      EVANS       0.11      0.05      0.07        21
FAIRY QUEEN       0.00      0.00      0.00        10
       FORD       0.57      0.86      0.68        35
       HOST       0.48      0.61      0.54        18
   MRS FORD       0.21      0.23      0.22        31
   MRS PAGE       0.35      0.50      0.41        30
        NYM       0.33      0.08      0.12        26
       PAGE       0.00      0.00      0.00        18
     PISTOL       0.24      0.74      0.36        46
       PUCK       0.00      0.00      0.00        10
    QUICKLY       0.80      0.30      0.43        27
      ROBIN       0.31      0.27      0.29        41
    SHALLOW       0.00      0.00      0.00        11
     SIMPLE       0.50      0.22      0.31         9
    SLENDER       0.00      0.00      0.00        13
   THE SONG       0.00      0.00      0.00         7

avg / total       0.31      0.35      0.29       382

=========================================================================================================

=========================================================================================================
Speaker: NYM
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
46 features selected out of 93 total
F1 mean: 0.17 (+/- 0.11)

             precision    recall  f1-score   support

   FALSTAFF       0.00      0.00      0.00        12
     PISTOL       0.36      0.75      0.49        12
      ROBIN       0.33      0.30      0.32        10

avg / total       0.23      0.35      0.26        34

=========================================================================================================

=========================================================================================================
Speaker: CAIUS
Number of Total Listeners: 212

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
148 features selected out of 296 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

      EVANS       0.14      0.07      0.09        15
   FALSTAFF       0.00      0.00      0.00         9
       FORD       0.00      0.00      0.00         8
       HOST       0.33      0.14      0.19        22
   MRS FORD       0.00      0.00      0.00         8
   MRS PAGE       0.00      0.00      0.00        10
       PAGE       0.15      0.30      0.20        27
    QUICKLY       0.33      0.15      0.21        13
      RUGBY       0.24      0.87      0.38        38
    SERVANT       0.00      0.00      0.00         5
    SHALLOW       0.00      0.00      0.00        19
     SIMPLE       0.00      0.00      0.00        17
    SLENDER       0.00      0.00      0.00        21

avg / total       0.13      0.22      0.13       212

=========================================================================================================

=========================================================================================================
Speaker: EVANS
Number of Total Listeners: 397

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
319 features selected out of 639 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00         7
   BARDOLPH       0.00      0.00      0.00        16
      CAIUS       0.00      0.00      0.00        11
FAIRY QUEEN       0.00      0.00      0.00         7
   FALSTAFF       0.00      0.00      0.00        30
       FORD       0.00      0.00      0.00        17
       HOST       0.33      0.14      0.20         7
   MRS FORD       0.14      0.04      0.06        27
   MRS PAGE       0.24      0.62      0.34        45
        NYM       0.00      0.00      0.00        14
       PAGE       0.17      0.60      0.26        45
     PISTOL       0.00      0.00      0.00        14
       PUCK       0.00      0.00      0.00         7
    QUICKLY       0.00      0.00      0.00        20
      RUGBY       0.00      0.00      0.00         5
    SERVANT       0.00      0.00      0.00         6
    SHALLOW       0.20      0.33      0.25        39
     SIMPLE       0.24      0.33      0.28        24
    SLENDER       0.50      0.08      0.14        36
    WILLIAM       0.00      0.00      0.00        20

avg / total       0.14      0.20      0.13       397

=========================================================================================================

=========================================================================================================
Speaker: SHALLOW
Number of Total Listeners: 298

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
187 features selected out of 375 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00        16
   BARDOLPH       0.00      0.00      0.00        12
      CAIUS       0.00      0.00      0.00        10
      EVANS       0.38      0.07      0.12        41
   FALSTAFF       0.00      0.00      0.00        12
     FENTON       0.00      0.00      0.00         7
       FORD       0.00      0.00      0.00        10
       HOST       0.00      0.00      0.00        15
   MRS FORD       0.00      0.00      0.00        10
   MRS PAGE       0.00      0.00      0.00        12
        NYM       0.00      0.00      0.00        17
       PAGE       0.20      0.23      0.21        40
     PISTOL       0.00      0.00      0.00        12
    QUICKLY       0.00      0.00      0.00         7
      RUGBY       0.00      0.00      0.00        10
     SIMPLE       0.00      0.00      0.00        15
    SLENDER       0.19      0.88      0.31        52

avg / total       0.11      0.19      0.10       298

=========================================================================================================

=========================================================================================================
Speaker: MRS FORD
Number of Total Listeners: 214

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
254 features selected out of 509 total
F1 mean: 0.05 (+/- 0.01)

             precision    recall  f1-score   support

      EVANS       0.00      0.00      0.00        15
   FALSTAFF       0.00      0.00      0.00        35
FIRST SERVANT       0.00      0.00      0.00         9
       FORD       0.00      0.00      0.00        18
   MRS PAGE       0.36      1.00      0.53        77
       PAGE       0.00      0.00      0.00        18
      ROBIN       0.00      0.00      0.00        18
SECOND SERVANT       0.00      0.00      0.00         9
    SERVANT       0.00      0.00      0.00         7
    SHALLOW       0.00      0.00      0.00         8

avg / total       0.13      0.36      0.19       214

=========================================================================================================

=========================================================================================================
Speaker: FENTON
Number of Total Listeners: 44

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
115 features selected out of 230 total
F1 mean: 0.12 (+/- 0.11)

             precision    recall  f1-score   support

       ANNE       0.38      0.56      0.45         9
   MRS PAGE       0.00      0.00      0.00         6
       PAGE       0.00      0.00      0.00         6
    QUICKLY       0.35      0.92      0.51        12
    SHALLOW       0.00      0.00      0.00         5
    SLENDER       0.00      0.00      0.00         6

avg / total       0.18      0.36      0.23        44

=========================================================================================================

=========================================================================================================
Speaker: ANNE
Number of Total Listeners: 141

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
60 features selected out of 121 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

   BARDOLPH       0.00      0.00      0.00         9
      EVANS       0.00      0.00      0.00        10
   FALSTAFF       0.00      0.00      0.00        10
     FENTON       0.57      0.36      0.44        11
   MRS FORD       0.00      0.00      0.00        10
   MRS PAGE       0.00      0.00      0.00        12
        NYM       0.00      0.00      0.00         9
       PAGE       0.00      0.00      0.00        12
     PISTOL       0.00      0.00      0.00         9
    QUICKLY       0.00      0.00      0.00         7
    SHALLOW       0.09      0.06      0.07        16
     SIMPLE       0.00      0.00      0.00         9
    SLENDER       0.12      0.88      0.21        17

avg / total       0.07      0.14      0.07       141

=========================================================================================================

=========================================================================================================
Speaker: PISTOL
Number of Total Listeners: 64

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
117 features selected out of 235 total
F1 mean: 0.16 (+/- 0.09)

             precision    recall  f1-score   support

   FALSTAFF       0.40      0.91      0.56        22
        NYM       0.42      0.24      0.30        21
       PAGE       0.50      0.14      0.22         7
      ROBIN       0.00      0.00      0.00        14

avg / total       0.33      0.41      0.31        64

=========================================================================================================

=========================================================================================================
Speaker: SLENDER
Number of Total Listeners: 404

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
216 features selected out of 432 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       ANNE       0.09      0.03      0.05        29
   BARDOLPH       0.00      0.00      0.00        29
      EVANS       0.14      0.20      0.16        46
FAIRY QUEEN       0.00      0.00      0.00         5
   FALSTAFF       0.14      0.03      0.05        34
     FENTON       0.00      0.00      0.00         8
       FORD       0.00      0.00      0.00         7
   MRS FORD       0.00      0.00      0.00        26
   MRS PAGE       0.09      0.04      0.05        28
        NYM       0.00      0.00      0.00        29
       PAGE       0.12      0.07      0.09        43
     PISTOL       0.00      0.00      0.00        29
       PUCK       0.00      0.00      0.00         5
    QUICKLY       0.00      0.00      0.00         8
    SHALLOW       0.14      0.80      0.24        51
     SIMPLE       0.00      0.00      0.00        22
   THE SONG       0.00      0.00      0.00         5

avg / total       0.07      0.14      0.07       404

=========================================================================================================

=========================================================================================================
Speaker: FORD
Number of Total Listeners: 363

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
360 features selected out of 721 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

      CAIUS       0.00      0.00      0.00        14
      EVANS       0.14      0.05      0.07        42
FAIRY QUEEN       0.00      0.00      0.00        11
   FALSTAFF       0.35      0.71      0.46        55
FIRST SERVANT       0.50      0.08      0.13        13
   MRS FORD       0.14      0.05      0.08        39
   MRS PAGE       0.31      0.10      0.15        40
        NYM       0.00      0.00      0.00        16
       PAGE       0.20      0.72      0.32        58
       PUCK       0.00      0.00      0.00        11
      ROBIN       0.00      0.00      0.00         9
SECOND SERVANT       0.00      0.00      0.00        13
    SERVANT       0.00      0.00      0.00        10
    SHALLOW       0.00      0.00      0.00        16
    SLENDER       0.00      0.00      0.00         5
   THE SONG       0.00      0.00      0.00        11

avg / total       0.17      0.25      0.16       363

=========================================================================================================

=========================================================================================================
Speaker: HOST
Number of Total Listeners: 160

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
187 features selected out of 375 total
F1 mean: 0.01 (+/- 0.00)

             precision    recall  f1-score   support

   BARDOLPH       0.50      0.45      0.48        11
      CAIUS       0.17      0.21      0.19        19
      EVANS       0.00      0.00      0.00         6
   FALSTAFF       0.38      0.42      0.40        12
       FORD       0.00      0.00      0.00         8
        NYM       0.25      0.20      0.22        10
       PAGE       0.20      0.79      0.32        24
      ROBIN       0.00      0.00      0.00         6
      RUGBY       0.00      0.00      0.00        17
    SHALLOW       0.00      0.00      0.00        22
     SIMPLE       0.40      0.50      0.44         8
    SLENDER       0.00      0.00      0.00        17

avg / total       0.15      0.24      0.17       160

=========================================================================================================

=========================================================================================================
Speaker: MRS PAGE
Number of Total Listeners: 290

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
398 features selected out of 797 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00         5
      CAIUS       0.00      0.00      0.00         5
      EVANS       0.33      0.04      0.07        24
FAIRY QUEEN       0.00      0.00      0.00         8
   FALSTAFF       0.50      0.03      0.06        34
     FENTON       0.00      0.00      0.00         5
       FORD       0.50      0.04      0.07        27
   MRS FORD       0.29      0.98      0.45        81
       PAGE       0.00      0.00      0.00        25
       PUCK       0.00      0.00      0.00         8
    QUICKLY       0.50      0.07      0.12        14
      ROBIN       0.57      0.22      0.32        18
    SERVANT       0.00      0.00      0.00         7
    SHALLOW       0.00      0.00      0.00         5
    SLENDER       0.17      0.14      0.15         7
   THE SONG       0.00      0.00      0.00         8
    WILLIAM       0.00      0.00      0.00         9

avg / total       0.28      0.30      0.18       290

=========================================================================================================

=========================================================================================================
Speaker: WILLIAM
Number of Total Listeners: 33

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
17 features selected out of 34 total
F1 mean: 0.17 (+/- 0.00)

             precision    recall  f1-score   support

      EVANS       0.33      1.00      0.50        11
   MRS PAGE       0.00      0.00      0.00        11
    QUICKLY       0.00      0.00      0.00        11

avg / total       0.11      0.33      0.17        33

=========================================================================================================

=========================================================================================================
Speaker: PAGE
Number of Total Listeners: 395

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
233 features selected out of 466 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

       ANNE       0.00      0.00      0.00        11
   BARDOLPH       0.00      0.00      0.00         7
      CAIUS       0.00      0.00      0.00        11
      EVANS       0.17      0.65      0.27        52
FAIRY QUEEN       0.00      0.00      0.00        11
   FALSTAFF       0.00      0.00      0.00        23
     FENTON       0.00      0.00      0.00         5
FIRST SERVANT       0.00      0.00      0.00         5
       FORD       0.29      0.35      0.32        40
       HOST       0.00      0.00      0.00        10
   MRS FORD       0.00      0.00      0.00        32
   MRS PAGE       0.17      0.15      0.16        34
        NYM       0.00      0.00      0.00        19
     PISTOL       0.00      0.00      0.00         7
       PUCK       0.00      0.00      0.00        11
      RUGBY       0.00      0.00      0.00         7
SECOND SERVANT       0.00      0.00      0.00         5
    SHALLOW       0.21      0.24      0.23        41
     SIMPLE       0.00      0.00      0.00        11
    SLENDER       0.15      0.24      0.18        42
   THE SONG       0.00      0.00      0.00        11

avg / total       0.10      0.18      0.12       395

=========================================================================================================

Play: 21

=========================================================================================================
Speaker: PUCK
Number of Total Listeners: 58

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
302 features selected out of 605 total
F1 mean: 0.09 (+/- 0.09)

             precision    recall  f1-score   support

  DEMETRIUS       0.50      0.69      0.58        16
      FAIRY       1.00      0.29      0.44         7
   LYSANDER       0.50      0.20      0.29        10
     OBERON       0.46      0.73      0.56        15
    TITANIA       0.67      0.40      0.50        10

avg / total       0.58      0.52      0.49        58

=========================================================================================================

=========================================================================================================
Speaker: HELENA
Number of Total Listeners: 169

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
352 features selected out of 704 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

  DEMETRIUS       0.20      0.70      0.31        33
      EGEUS       0.00      0.00      0.00         8
      FAIRY       0.00      0.00      0.00         7
     HERMIA       0.33      0.04      0.07        24
  HIPPOLYTA       0.00      0.00      0.00         8
   LYSANDER       0.24      0.34      0.29        29
     OBERON       0.27      0.13      0.18        23
       PUCK       0.00      0.00      0.00        17
    THESEUS       0.00      0.00      0.00         8
    TITANIA       0.00      0.00      0.00        12

avg / total       0.17      0.22      0.14       169

=========================================================================================================

=========================================================================================================
Speaker: BOTTOM
Number of Total Listeners: 282

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
269 features selected out of 539 total
F1 mean: 0.02 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
     COBWEB       0.10      0.08      0.09        12
      FLUTE       0.14      0.09      0.11        34
       MOTH       0.00      0.00      0.00        12
MUSTARDSEED       0.00      0.00      0.00        12
     OBERON       0.00      0.00      0.00         8
PEASEBLOSSOM       0.00      0.00      0.00        12
     QUINCE       0.18      0.19      0.18        32
      SNOUT       0.17      0.55      0.26        40
       SNUG       0.00      0.00      0.00        40
 STARVELING       0.20      0.20      0.20        40
    TITANIA       0.17      0.26      0.20        31

avg / total       0.11      0.17      0.13       282

=========================================================================================================

=========================================================================================================
Speaker: HERMIA
Number of Total Listeners: 220

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
292 features selected out of 584 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

  DEMETRIUS       0.21      0.42      0.28        43
      EGEUS       0.00      0.00      0.00        19
     HELENA       0.20      0.04      0.06        26
  HIPPOLYTA       0.00      0.00      0.00        19
   LYSANDER       0.22      0.64      0.32        42
     OBERON       0.00      0.00      0.00        23
       PUCK       0.20      0.04      0.07        24
    THESEUS       0.00      0.00      0.00        19
    TITANIA       1.00      0.20      0.33         5

avg / total       0.15      0.22      0.14       220

=========================================================================================================

=========================================================================================================
Speaker: FLUTE
Number of Total Listeners: 37

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
61 features selected out of 123 total
F1 mean: 0.10 (+/- 0.02)

             precision    recall  f1-score   support

     QUINCE       0.00      0.00      0.00        10
      SNOUT       0.27      1.00      0.43        10
       SNUG       0.00      0.00      0.00         7
 STARVELING       0.00      0.00      0.00        10

avg / total       0.07      0.27      0.12        37

=========================================================================================================

=========================================================================================================
Speaker: MUSTARDSEED
Number of Total Listeners: 25

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
4 features selected out of 9 total
F1 mean: 0.07 (+/- 0.00)

             precision    recall  f1-score   support

     BOTTOM       0.20      1.00      0.33         5
     COBWEB       0.00      0.00      0.00         5
       MOTH       0.00      0.00      0.00         5
PEASEBLOSSOM       0.00      0.00      0.00         5
    TITANIA       0.00      0.00      0.00         5

avg / total       0.04      0.20      0.07        25

=========================================================================================================

=========================================================================================================
Speaker: QUINCE
Number of Total Listeners: 187

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
153 features selected out of 306 total
F1 mean: 0.05 (+/- 0.08)

             precision    recall  f1-score   support

     BOTTOM       0.25      0.03      0.06        32
      FLUTE       0.19      0.13      0.15        31
      SNOUT       0.19      0.11      0.14        38
       SNUG       0.19      0.17      0.18        35
 STARVELING       0.21      0.61      0.31        38
    TITANIA       0.00      0.00      0.00        13

avg / total       0.19      0.20      0.16       187

=========================================================================================================

=========================================================================================================
Speaker: THESEUS
Number of Total Listeners: 333

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
380 features selected out of 761 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

  DEMETRIUS       0.12      0.05      0.07        40
      EGEUS       0.20      0.08      0.11        13
     HELENA       0.00      0.00      0.00        32
     HERMIA       0.14      0.08      0.10        39
  HIPPOLYTA       0.14      0.77      0.24        48
       LION       0.00      0.00      0.00        13
   LYSANDER       0.18      0.10      0.13        41
       MOON       0.00      0.00      0.00         7
  MOONSHINE       0.00      0.00      0.00         9
PHILOSTRATE       0.11      0.03      0.05        35
   PROLOGUE       0.00      0.00      0.00        22
    PYRAMUS       0.00      0.00      0.00        18
     THISBY       0.00      0.00      0.00        16

avg / total       0.09      0.14      0.08       333

=========================================================================================================

=========================================================================================================
Speaker: THISBY
Number of Total Listeners: 78

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
67 features selected out of 134 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

  DEMETRIUS       0.00      0.00      0.00         8
     HELENA       0.00      0.00      0.00         8
     HERMIA       0.00      0.00      0.00         8
  HIPPOLYTA       0.00      0.00      0.00         8
   LYSANDER       0.00      0.00      0.00         8
PHILOSTRATE       0.00      0.00      0.00         8
   PROLOGUE       0.00      0.00      0.00         8
    PYRAMUS       0.10      1.00      0.19         8
    THESEUS       0.00      0.00      0.00         8
       WALL       0.00      0.00      0.00         6

avg / total       0.01      0.10      0.02        78

=========================================================================================================

=========================================================================================================
Speaker: TITANIA
Number of Total Listeners: 115

Best model LogisticRegression(C=2.8000000000000003, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
258 features selected out of 517 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

     BOTTOM       0.17      0.57      0.26        14
     COBWEB       0.00      0.00      0.00        11
      FAIRY       0.00      0.00      0.00         6
      FLUTE       0.00      0.00      0.00         6
       MOTH       0.11      0.09      0.10        11
MUSTARDSEED       0.00      0.00      0.00        11
     OBERON       0.21      0.69      0.32        16
PEASEBLOSSOM       0.00      0.00      0.00        11
       PUCK       0.33      0.18      0.24        11
      SNOUT       0.00      0.00      0.00         6
       SNUG       0.00      0.00      0.00         6
 STARVELING       0.00      0.00      0.00         6

avg / total       0.09      0.19      0.11       115

=========================================================================================================

=========================================================================================================
Speaker: SNOUT
Number of Total Listeners: 41

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
25 features selected out of 51 total
F1 mean: 0.04 (+/- 0.02)

             precision    recall  f1-score   support

     BOTTOM       0.17      1.00      0.29         7
      FLUTE       0.00      0.00      0.00         7
     QUINCE       0.00      0.00      0.00         7
       SNUG       0.00      0.00      0.00         7
 STARVELING       0.00      0.00      0.00         7
    TITANIA       0.00      0.00      0.00         6

avg / total       0.03      0.17      0.05        41

=========================================================================================================

=========================================================================================================
Speaker: LYSANDER
Number of Total Listeners: 247

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
286 features selected out of 573 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

  DEMETRIUS       0.18      0.66      0.28        41
      EGEUS       0.33      0.07      0.11        15
     HELENA       0.22      0.06      0.10        32
     HERMIA       0.23      0.45      0.30        40
  HIPPOLYTA       0.00      0.00      0.00        22
       LION       0.00      0.00      0.00         5
     OBERON       0.00      0.00      0.00        19
PHILOSTRATE       0.00      0.00      0.00         7
   PROLOGUE       0.00      0.00      0.00         6
       PUCK       0.20      0.05      0.08        21
    PYRAMUS       0.00      0.00      0.00         5
    THESEUS       0.00      0.00      0.00        22
     THISBY       0.00      0.00      0.00         5
    TITANIA       0.00      0.00      0.00         7

avg / total       0.13      0.20      0.12       247

=========================================================================================================

=========================================================================================================
Speaker: PYRAMUS
Number of Total Listeners: 86

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
109 features selected out of 219 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

  DEMETRIUS       0.00      0.00      0.00         9
     HELENA       0.00      0.00      0.00         9
     HERMIA       0.11      0.67      0.18         9
  HIPPOLYTA       0.00      0.00      0.00         9
   LYSANDER       0.00      0.00      0.00         9
PHILOSTRATE       0.00      0.00      0.00         9
   PROLOGUE       0.00      0.00      0.00         9
    THESEUS       0.00      0.00      0.00         9
     THISBY       0.00      0.00      0.00         7
       WALL       0.10      0.43      0.16         7

avg / total       0.02      0.10      0.03        86

=========================================================================================================

=========================================================================================================
Speaker: DEMETRIUS
Number of Total Listeners: 279

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
242 features selected out of 485 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

      EGEUS       0.00      0.00      0.00         5
      FAIRY       0.00      0.00      0.00         6
     HELENA       0.20      0.29      0.23        35
     HERMIA       0.12      0.44      0.19        32
  HIPPOLYTA       0.00      0.00      0.00        19
       LION       0.00      0.00      0.00        11
   LYSANDER       0.16      0.38      0.23        34
       MOON       0.00      0.00      0.00         7
  MOONSHINE       0.00      0.00      0.00         7
     OBERON       0.26      0.22      0.24        23
PHILOSTRATE       0.00      0.00      0.00        14
   PROLOGUE       0.00      0.00      0.00        14
       PUCK       0.36      0.24      0.29        21
    PYRAMUS       0.00      0.00      0.00        12
    THESEUS       0.00      0.00      0.00        19
     THISBY       0.00      0.00      0.00        12
    TITANIA       0.00      0.00      0.00         8

avg / total       0.11      0.17      0.12       279

=========================================================================================================

=========================================================================================================
Speaker: HIPPOLYTA
Number of Total Listeners: 94

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
89 features selected out of 179 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

  DEMETRIUS       0.00      0.00      0.00        10
     HELENA       0.00      0.00      0.00        10
     HERMIA       0.00      0.00      0.00        10
       LION       0.00      0.00      0.00         5
   LYSANDER       0.00      0.00      0.00        10
PHILOSTRATE       0.15      0.31      0.20        13
   PROLOGUE       0.00      0.00      0.00         8
    PYRAMUS       0.00      0.00      0.00         7
    THESEUS       0.15      0.71      0.25        14
     THISBY       0.00      0.00      0.00         7

avg / total       0.04      0.15      0.06        94

=========================================================================================================

=========================================================================================================
Speaker: PHILOSTRATE
Number of Total Listeners: 36

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
63 features selected out of 126 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

  DEMETRIUS       0.17      1.00      0.29         6
     HELENA       0.00      0.00      0.00         6
     HERMIA       0.00      0.00      0.00         6
  HIPPOLYTA       0.00      0.00      0.00         6
   LYSANDER       0.00      0.00      0.00         6
    THESEUS       0.00      0.00      0.00         6

avg / total       0.03      0.17      0.05        36

=========================================================================================================

=========================================================================================================
Speaker: OBERON
Number of Total Listeners: 87

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
361 features selected out of 722 total
F1 mean: 0.03 (+/- 0.03)

             precision    recall  f1-score   support

     BOTTOM       0.00      0.00      0.00         5
     COBWEB       0.00      0.00      0.00         5
  DEMETRIUS       1.00      0.12      0.22         8
      FAIRY       0.00      0.00      0.00        11
       MOTH       0.00      0.00      0.00         5
MUSTARDSEED       0.00      0.00      0.00         5
PEASEBLOSSOM       0.00      0.00      0.00         5
       PUCK       0.31      0.92      0.46        24
    TITANIA       0.33      0.26      0.29        19

avg / total       0.25      0.32      0.21        87

=========================================================================================================

Play: 22

=========================================================================================================
Speaker: BEATRICE
Number of Total Listeners: 590

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
415 features selected out of 830 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        27
  BALTHASAR       0.00      0.00      0.00        18
   BENEDICK       0.20      0.26      0.23        61
   BORACHIO       0.00      0.00      0.00        11
    CLAUDIO       0.17      0.02      0.03        56
      FRIAR       0.00      0.00      0.00        35
       HERO       0.18      0.74      0.29        94
       JOHN       0.00      0.00      0.00        44
    LEONATO       0.17      0.17      0.17        86
   MARGARET       0.50      0.02      0.04        48
  MESSENGER       0.00      0.00      0.00        17
      PEDRO       0.16      0.05      0.07        64
     URSULA       0.00      0.00      0.00        29

avg / total       0.15      0.18      0.11       590

=========================================================================================================

=========================================================================================================
Speaker: VERGES
Number of Total Listeners: 49

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
63 features selected out of 126 total
F1 mean: 0.10 (+/- 0.02)

             precision    recall  f1-score   support

   BORACHIO       0.00      0.00      0.00         5
   DOGBERRY       0.37      1.00      0.54        18
FIRST WATCH       0.00      0.00      0.00        10
    LEONATO       0.00      0.00      0.00         6
SECOND WATCH       0.00      0.00      0.00        10

avg / total       0.13      0.37      0.20        49

=========================================================================================================

=========================================================================================================
Speaker: ANTONIO
Number of Total Listeners: 77

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
110 features selected out of 221 total
F1 mean: 0.05 (+/- 0.03)

             precision    recall  f1-score   support

   BEATRICE       0.00      0.00      0.00         9
    CLAUDIO       0.00      0.00      0.00         8
       HERO       0.00      0.00      0.00         9
    LEONATO       0.29      1.00      0.44        22
   MARGARET       0.00      0.00      0.00         9
      PEDRO       0.00      0.00      0.00        11
     URSULA       0.00      0.00      0.00         9

avg / total       0.08      0.29      0.13        77

=========================================================================================================

=========================================================================================================
Speaker: MARGARET
Number of Total Listeners: 60

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
147 features selected out of 295 total
F1 mean: 0.06 (+/- 0.02)

             precision    recall  f1-score   support

  BALTHASAR       0.00      0.00      0.00         5
   BEATRICE       0.00      0.00      0.00        14
   BENEDICK       0.00      0.00      0.00         5
       HERO       0.35      1.00      0.52        21
    LEONATO       0.00      0.00      0.00         5
      PEDRO       0.00      0.00      0.00         5
     URSULA       0.00      0.00      0.00         5

avg / total       0.12      0.35      0.18        60

=========================================================================================================

=========================================================================================================
Speaker: LEONATO
Number of Total Listeners: 604

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
464 features selected out of 929 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.28      0.26      0.27        50
  BALTHASAR       0.00      0.00      0.00        20
   BEATRICE       0.21      0.12      0.16        57
   BENEDICK       0.14      0.17      0.16        63
   BORACHIO       0.00      0.00      0.00        17
    CLAUDIO       0.17      0.69      0.27        77
    CONRADE       0.00      0.00      0.00        10
   DOGBERRY       0.00      0.00      0.00        21
      FRIAR       0.00      0.00      0.00        30
       HERO       0.19      0.29      0.23        62
       JOHN       0.14      0.03      0.05        31
   MARGARET       0.00      0.00      0.00        21
  MESSENGER       0.00      0.00      0.00        16
      PEDRO       0.19      0.06      0.10        77
     SEXTON       0.00      0.00      0.00        10
     URSULA       0.00      0.00      0.00        21
     VERGES       0.50      0.14      0.22        21

avg / total       0.15      0.18      0.13       604

=========================================================================================================

=========================================================================================================
Speaker: MESSENGER
Number of Total Listeners: 49

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
71 features selected out of 142 total
F1 mean: 0.18 (+/- 0.11)

             precision    recall  f1-score   support

   BEATRICE       0.33      0.12      0.18        16
       HERO       0.00      0.00      0.00        16
    LEONATO       0.35      0.88      0.50        17

avg / total       0.23      0.35      0.23        49

=========================================================================================================

=========================================================================================================
Speaker: DOGBERRY
Number of Total Listeners: 208

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
276 features selected out of 553 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

   BENEDICK       0.00      0.00      0.00         7
   BORACHIO       0.00      0.00      0.00        23
       BOTH       0.00      0.00      0.00        11
    CLAUDIO       0.00      0.00      0.00         7
    CONRADE       0.00      0.00      0.00        19
FIRST WATCH       0.00      0.00      0.00        24
    LEONATO       0.00      0.00      0.00        19
      PEDRO       0.00      0.00      0.00         7
SECOND WATCH       0.33      0.05      0.08        22
     SEXTON       0.00      0.00      0.00        17
     VERGES       0.25      0.98      0.40        52

avg / total       0.10      0.25      0.11       208

=========================================================================================================

=========================================================================================================
Speaker: CLAUDIO
Number of Total Listeners: 631

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
385 features selected out of 770 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        16
  BALTHASAR       0.00      0.00      0.00        36
   BEATRICE       0.00      0.00      0.00        45
   BENEDICK       0.24      0.14      0.17       102
   BORACHIO       0.00      0.00      0.00        22
    CONRADE       0.00      0.00      0.00         8
   DOGBERRY       0.00      0.00      0.00         8
      FRIAR       0.14      0.05      0.07        22
       HERO       0.00      0.00      0.00        47
       JOHN       0.50      0.02      0.04        53
    LEONATO       0.17      0.17      0.17       112
   MARGARET       0.00      0.00      0.00         8
  MESSENGER       0.00      0.00      0.00        19
      PEDRO       0.19      0.74      0.31       117
     URSULA       0.00      0.00      0.00         8
     VERGES       0.00      0.00      0.00         8

avg / total       0.15      0.19      0.12       631

=========================================================================================================

=========================================================================================================
Speaker: SECOND WATCH
Number of Total Listeners: 47

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
53 features selected out of 107 total
F1 mean: 0.06 (+/- 0.04)

             precision    recall  f1-score   support

   BORACHIO       0.00      0.00      0.00         7
    CONRADE       0.00      0.00      0.00         7
   DOGBERRY       0.00      0.00      0.00         9
FIRST WATCH       0.32      1.00      0.48        15
     VERGES       0.00      0.00      0.00         9

avg / total       0.10      0.32      0.15        47

=========================================================================================================

=========================================================================================================
Speaker: SEXTON
Number of Total Listeners: 31

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
35 features selected out of 71 total
F1 mean: 0.07 (+/- 0.01)

             precision    recall  f1-score   support

   BORACHIO       0.00      0.00      0.00         7
       BOTH       0.00      0.00      0.00         5
    CONRADE       0.00      0.00      0.00         5
   DOGBERRY       0.23      1.00      0.37         7
     VERGES       0.00      0.00      0.00         7

avg / total       0.05      0.23      0.08        31

=========================================================================================================

=========================================================================================================
Speaker: JOHN
Number of Total Listeners: 97

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
199 features selected out of 399 total
F1 mean: 0.10 (+/- 0.06)

             precision    recall  f1-score   support

   BENEDICK       0.00      0.00      0.00        16
   BORACHIO       0.68      0.89      0.77        19
    CLAUDIO       0.26      0.79      0.39        19
    CONRADE       0.83      0.45      0.59        11
    LEONATO       0.00      0.00      0.00        16
      PEDRO       0.25      0.12      0.17        16

avg / total       0.32      0.40      0.32        97

=========================================================================================================

=========================================================================================================
Speaker: BALTHASAR
Number of Total Listeners: 55

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
39 features selected out of 78 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00         5
   BEATRICE       0.00      0.00      0.00         5
   BENEDICK       0.00      0.00      0.00         5
    CLAUDIO       0.00      0.00      0.00         5
       HERO       0.00      0.00      0.00         5
    LEONATO       0.20      0.60      0.30        10
   MARGARET       0.00      0.00      0.00         5
      PEDRO       0.16      0.40      0.23        10
     URSULA       0.00      0.00      0.00         5

avg / total       0.07      0.18      0.10        55

=========================================================================================================

=========================================================================================================
Speaker: PEDRO
Number of Total Listeners: 663

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
408 features selected out of 816 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        16
  BALTHASAR       0.00      0.00      0.00        44
   BEATRICE       0.00      0.00      0.00        43
   BENEDICK       0.31      0.13      0.18       100
   BORACHIO       0.14      0.03      0.05        33
    CLAUDIO       0.20      0.33      0.25       123
    CONRADE       0.00      0.00      0.00        10
   DOGBERRY       0.00      0.00      0.00        10
      FRIAR       0.00      0.00      0.00         6
       HERO       0.00      0.00      0.00        50
       JOHN       0.17      0.04      0.06        55
    LEONATO       0.19      0.60      0.29       126
   MARGARET       0.00      0.00      0.00         8
  MESSENGER       0.00      0.00      0.00        21
     URSULA       0.00      0.00      0.00         8
     VERGES       0.00      0.00      0.00        10

avg / total       0.14      0.20      0.14       663

=========================================================================================================

=========================================================================================================
Speaker: HERO
Number of Total Listeners: 222

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
228 features selected out of 457 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00         8
  BALTHASAR       0.17      0.15      0.16        13
   BEATRICE       0.18      0.74      0.29        34
   BENEDICK       0.00      0.00      0.00        12
    CLAUDIO       0.15      0.08      0.10        26
      FRIAR       0.00      0.00      0.00        12
       JOHN       0.00      0.00      0.00        10
    LEONATO       0.17      0.16      0.16        32
   MARGARET       0.75      0.29      0.41        21
      PEDRO       0.11      0.03      0.05        30
     URSULA       0.17      0.08      0.11        24

avg / total       0.18      0.19      0.15       222

=========================================================================================================

=========================================================================================================
Speaker: BORACHIO
Number of Total Listeners: 115

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
219 features selected out of 439 total
F1 mean: 0.05 (+/- 0.04)

             precision    recall  f1-score   support

   BENEDICK       0.00      0.00      0.00         5
    CLAUDIO       0.00      0.00      0.00         6
    CONRADE       0.25      0.96      0.40        27
   DOGBERRY       0.00      0.00      0.00         8
FIRST WATCH       0.00      0.00      0.00        15
       JOHN       0.83      0.62      0.71        16
    LEONATO       0.00      0.00      0.00         5
      PEDRO       0.00      0.00      0.00         5
SECOND WATCH       0.00      0.00      0.00        14
     SEXTON       0.00      0.00      0.00         6
     VERGES       0.00      0.00      0.00         8

avg / total       0.18      0.31      0.19       115

=========================================================================================================

=========================================================================================================
Speaker: FRIAR
Number of Total Listeners: 102

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
168 features selected out of 337 total
F1 mean: 0.04 (+/- 0.04)

             precision    recall  f1-score   support

   BEATRICE       0.14      0.06      0.09        16
   BENEDICK       0.18      0.19      0.18        16
    CLAUDIO       0.00      0.00      0.00        13
       HERO       0.20      0.19      0.19        16
       JOHN       0.00      0.00      0.00        12
    LEONATO       0.14      0.50      0.22        16
      PEDRO       0.14      0.08      0.10        13

avg / total       0.12      0.16      0.12       102

=========================================================================================================

=========================================================================================================
Speaker: URSULA
Number of Total Listeners: 99

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
107 features selected out of 215 total
F1 mean: 0.02 (+/- 0.07)

             precision    recall  f1-score   support

  BALTHASAR       0.00      0.00      0.00        15
   BEATRICE       0.21      0.35      0.26        17
    CLAUDIO       0.00      0.00      0.00        11
       HERO       0.19      0.72      0.30        18
    LEONATO       0.00      0.00      0.00        15
   MARGARET       0.00      0.00      0.00         8
      PEDRO       0.00      0.00      0.00        15

avg / total       0.07      0.19      0.10        99

=========================================================================================================

=========================================================================================================
Speaker: CONRADE
Number of Total Listeners: 51

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
76 features selected out of 152 total
F1 mean: 0.17 (+/- 0.20)

             precision    recall  f1-score   support

   BORACHIO       0.36      1.00      0.53        17
FIRST WATCH       0.00      0.00      0.00        14
       JOHN       1.00      0.67      0.80         6
SECOND WATCH       0.00      0.00      0.00        14

avg / total       0.24      0.41      0.27        51

=========================================================================================================

=========================================================================================================
Speaker: BENEDICK
Number of Total Listeners: 754

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
517 features selected out of 1034 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    ANTONIO       0.00      0.00      0.00        23
  BALTHASAR       0.00      0.00      0.00        41
   BEATRICE       0.16      0.32      0.21        93
   BORACHIO       0.00      0.00      0.00        13
    CLAUDIO       0.15      0.17      0.16        95
      FRIAR       0.00      0.00      0.00        46
       HERO       0.00      0.00      0.00        81
       JOHN       0.17      0.07      0.10        69
    LEONATO       0.16      0.34      0.22       102
   MARGARET       0.33      0.23      0.27        39
  MESSENGER       0.00      0.00      0.00        26
      PEDRO       0.17      0.30      0.22       102
     URSULA       0.00      0.00      0.00        24

avg / total       0.12      0.17      0.13       754

=========================================================================================================

Play: 23

=========================================================================================================
Speaker: RODERIGO
Number of Total Listeners: 276

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
200 features selected out of 400 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        13
  BRABANTIO       1.00      0.05      0.09        22
     CASSIO       0.00      0.00      0.00        15
  DESDEMONA       0.33      0.03      0.06        32
       DUKE       0.00      0.00      0.00        11
     EMILIA       0.00      0.00      0.00        19
FIRST GENTLEMAN       0.00      0.00      0.00         6
FIRST OFFICER       0.00      0.00      0.00        12
FIRST SENATOR       0.00      0.00      0.00        11
FOURTH GENTLEMAN       0.00      0.00      0.00         6
       IAGO       0.20      0.98      0.34        56
  MESSENGER       0.00      0.00      0.00        11
    MONTANO       0.00      0.00      0.00         7
    OTHELLO       0.00      0.00      0.00        21
     SAILOR       0.00      0.00      0.00        11
SECOND GENTLEMAN       0.00      0.00      0.00         6
SECOND SENATOR       0.00      0.00      0.00        11
THIRD GENTLEMAN       0.00      0.00      0.00         6

avg / total       0.16      0.21      0.08       276

=========================================================================================================

=========================================================================================================
Speaker: DUKE
Number of Total Listeners: 195

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
152 features selected out of 304 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        14
  BRABANTIO       0.00      0.00      0.00        16
  DESDEMONA       0.00      0.00      0.00         9
FIRST OFFICER       0.00      0.00      0.00        21
FIRST SENATOR       0.13      0.88      0.22        24
       IAGO       0.00      0.00      0.00        16
  MESSENGER       0.09      0.06      0.07        18
    OTHELLO       0.10      0.12      0.11        16
   RODERIGO       0.00      0.00      0.00        16
     SAILOR       0.00      0.00      0.00        21
SECOND SENATOR       0.00      0.00      0.00        24

avg / total       0.03      0.12      0.04       195

=========================================================================================================

=========================================================================================================
Speaker: CASSIO
Number of Total Listeners: 433

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
397 features selected out of 794 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        26
     BIANCA       0.00      0.00      0.00        10
  DESDEMONA       0.28      0.24      0.26        63
     EMILIA       0.00      0.00      0.00        21
FIRST GENTLEMAN       0.00      0.00      0.00        13
FOURTH GENTLEMAN       0.00      0.00      0.00        11
   GRATIANO       0.00      0.00      0.00        14
       IAGO       0.24      0.89      0.38        88
   LODOVICO       0.00      0.00      0.00        14
    MONTANO       0.23      0.15      0.18        33
    OTHELLO       0.23      0.08      0.12        72
   RODERIGO       0.25      0.05      0.08        43
SECOND GENTLEMAN       0.00      0.00      0.00        12
THIRD GENTLEMAN       0.00      0.00      0.00        13

avg / total       0.17      0.24      0.16       433

=========================================================================================================

=========================================================================================================
Speaker: BRABANTIO
Number of Total Listeners: 155

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
251 features selected out of 503 total
F1 mean: 0.04 (+/- 0.03)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         9
  DESDEMONA       0.00      0.00      0.00         5
       DUKE       0.00      0.00      0.00        11
FIRST OFFICER       0.00      0.00      0.00        15
FIRST SENATOR       0.00      0.00      0.00        11
       IAGO       0.20      0.35      0.25        26
  MESSENGER       0.00      0.00      0.00        11
    OTHELLO       0.00      0.00      0.00        15
   RODERIGO       0.19      0.70      0.30        30
     SAILOR       0.00      0.00      0.00        11
SECOND SENATOR       0.00      0.00      0.00        11

avg / total       0.07      0.19      0.10       155

=========================================================================================================

=========================================================================================================
Speaker: GRATIANO
Number of Total Listeners: 87

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
60 features selected out of 121 total
F1 mean: 0.04 (+/- 0.05)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
     BIANCA       0.00      0.00      0.00         5
     CASSIO       0.00      0.00      0.00        11
  DESDEMONA       0.00      0.00      0.00         6
     EMILIA       0.00      0.00      0.00         6
       IAGO       0.19      0.94      0.31        16
   LODOVICO       0.00      0.00      0.00        11
    MONTANO       0.00      0.00      0.00         8
    OTHELLO       0.29      0.20      0.24        10
   RODERIGO       0.00      0.00      0.00         9

avg / total       0.07      0.20      0.08        87

=========================================================================================================

=========================================================================================================
Speaker: FIRST MUSICIAN
Number of Total Listeners: 30

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
10 features selected out of 20 total
F1 mean: 0.05 (+/- 0.00)

             precision    recall  f1-score   support

        ALL       0.17      1.00      0.29         5
     CASSIO       0.00      0.00      0.00         5
      CLOWN       0.00      0.00      0.00         5
  DESDEMONA       0.00      0.00      0.00         5
    OTHELLO       0.00      0.00      0.00         5
   RODERIGO       0.00      0.00      0.00         5

avg / total       0.03      0.17      0.05        30

=========================================================================================================

=========================================================================================================
Speaker: DESDEMONA
Number of Total Listeners: 460

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
422 features selected out of 844 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         5
     CASSIO       0.00      0.00      0.00        29
      CLOWN       0.00      0.00      0.00         6
     EMILIA       0.26      0.54      0.35       112
FIRST GENTLEMAN       0.00      0.00      0.00        16
FOURTH GENTLEMAN       0.00      0.00      0.00        16
       IAGO       0.25      0.04      0.06        57
   LODOVICO       0.00      0.00      0.00        32
    MONTANO       0.00      0.00      0.00        17
    OTHELLO       0.45      0.84      0.58       117
   RODERIGO       0.00      0.00      0.00        21
SECOND GENTLEMAN       0.00      0.00      0.00        16
THIRD GENTLEMAN       0.00      0.00      0.00        16

avg / total       0.21      0.35      0.24       460

=========================================================================================================

=========================================================================================================
Speaker: FIRST SENATOR
Number of Total Listeners: 31

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 132 total
F1 mean: 0.07 (+/- 0.00)

             precision    recall  f1-score   support

       DUKE       0.00      0.00      0.00         7
FIRST OFFICER       0.00      0.00      0.00         6
  MESSENGER       0.00      0.00      0.00         5
     SAILOR       0.25      0.17      0.20         6
SECOND SENATOR       0.22      0.86      0.35         7

avg / total       0.10      0.23      0.12        31

=========================================================================================================

=========================================================================================================
Speaker: BIANCA
Number of Total Listeners: 55

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
79 features selected out of 159 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

     CASSIO       0.27      1.00      0.43        15
  DESDEMONA       0.00      0.00      0.00         8
     EMILIA       0.00      0.00      0.00        10
   GRATIANO       0.00      0.00      0.00         5
       IAGO       0.00      0.00      0.00         7
   LODOVICO       0.00      0.00      0.00         5
   RODERIGO       0.00      0.00      0.00         5

avg / total       0.07      0.27      0.12        55

=========================================================================================================

=========================================================================================================
Speaker: CLOWN
Number of Total Listeners: 58

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
66 features selected out of 132 total
F1 mean: 0.03 (+/- 0.05)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00         8
     CASSIO       0.00      0.00      0.00         8
  DESDEMONA       0.25      0.93      0.39        14
     EMILIA       0.00      0.00      0.00         6
FIRST MUSICIAN       0.00      0.00      0.00         6
    OTHELLO       0.00      0.00      0.00         8
   RODERIGO       0.17      0.12      0.14         8

avg / total       0.08      0.24      0.11        58

=========================================================================================================

=========================================================================================================
Speaker: IAGO
Number of Total Listeners: 1007

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
1069 features selected out of 2138 total
F1 mean: 0.02 (+/- 0.01)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        39
     BIANCA       0.00      0.00      0.00        13
  BRABANTIO       0.00      0.00      0.00        17
     CASSIO       0.23      0.11      0.15       102
  DESDEMONA       0.21      0.43      0.28       175
       DUKE       0.00      0.00      0.00        11
     EMILIA       0.17      0.04      0.06       101
FIRST GENTLEMAN       0.00      0.00      0.00        22
FIRST OFFICER       0.00      0.00      0.00        12
FIRST SENATOR       0.00      0.00      0.00        11
FOURTH GENTLEMAN       0.00      0.00      0.00        22
   GRATIANO       0.00      0.00      0.00        35
   LODOVICO       0.00      0.00      0.00        33
  MESSENGER       0.00      0.00      0.00        11
    MONTANO       0.00      0.00      0.00        47
    OTHELLO       0.30      0.74      0.43       184
   RODERIGO       0.26      0.26      0.26       106
     SAILOR       0.00      0.00      0.00        11
SECOND GENTLEMAN       0.11      0.05      0.06        22
SECOND SENATOR       0.00      0.00      0.00        11
THIRD GENTLEMAN       0.00      0.00      0.00        22

avg / total       0.16      0.25      0.18      1007

=========================================================================================================

=========================================================================================================
Speaker: LODOVICO
Number of Total Listeners: 118

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
153 features selected out of 307 total
F1 mean: 0.03 (+/- 0.01)

             precision    recall  f1-score   support

     CASSIO       0.25      0.06      0.09        18
  DESDEMONA       0.00      0.00      0.00        15
   GRATIANO       0.25      0.06      0.09        18
       IAGO       0.27      0.93      0.42        28
    MONTANO       0.00      0.00      0.00        11
    OTHELLO       0.29      0.19      0.23        21
   RODERIGO       0.00      0.00      0.00         7

avg / total       0.19      0.27      0.17       118

=========================================================================================================

=========================================================================================================
Speaker: OTHELLO
Number of Total Listeners: 725

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
901 features selected out of 1802 total
F1 mean: 0.03 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        23
  BRABANTIO       0.00      0.00      0.00        14
     CASSIO       0.20      0.02      0.04        47
  DESDEMONA       0.37      0.87      0.52       191
       DUKE       0.00      0.00      0.00        10
     EMILIA       0.50      0.07      0.12       112
FIRST OFFICER       0.00      0.00      0.00        14
FIRST SENATOR       0.10      0.10      0.10        10
   GRATIANO       1.00      0.05      0.10        19
       IAGO       0.34      0.46      0.39       169
   LODOVICO       0.33      0.04      0.06        28
  MESSENGER       0.00      0.00      0.00        10
    MONTANO       0.20      0.03      0.06        29
   RODERIGO       0.10      0.03      0.05        29
     SAILOR       0.00      0.00      0.00        10
SECOND SENATOR       0.00      0.00      0.00        10

avg / total       0.32      0.35      0.26       725

=========================================================================================================

=========================================================================================================
Speaker: EMILIA
Number of Total Listeners: 304

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
337 features selected out of 674 total
F1 mean: 0.05 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        13
     CASSIO       0.00      0.00      0.00        15
  DESDEMONA       0.32      0.83      0.46        92
   GRATIANO       0.00      0.00      0.00        20
       IAGO       0.50      0.03      0.05        40
   LODOVICO       0.00      0.00      0.00        21
    MONTANO       0.00      0.00      0.00        19
    OTHELLO       0.30      0.25      0.27        75
   RODERIGO       0.00      0.00      0.00         9

avg / total       0.24      0.32      0.21       304

=========================================================================================================

=========================================================================================================
Speaker: MONTANO
Number of Total Listeners: 94

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
127 features selected out of 254 total
F1 mean: 0.01 (+/- 0.02)

             precision    recall  f1-score   support

        ALL       0.00      0.00      0.00        12
     CASSIO       0.24      0.36      0.29        11
  DESDEMONA       0.00      0.00      0.00        15
FIRST GENTLEMAN       0.45      0.56      0.50         9
       IAGO       0.15      0.29      0.20        14
    OTHELLO       0.23      0.60      0.33        15
   RODERIGO       0.00      0.00      0.00         6
SECOND GENTLEMAN       0.00      0.00      0.00         6
THIRD GENTLEMAN       0.00      0.00      0.00         6

avg / total       0.13      0.23      0.16        94

=========================================================================================================

Play: 24

=========================================================================================================
Speaker: BOLINGBROKE
Number of Total Listeners: 458

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
581 features selected out of 1163 total
F1 mean: 0.01 (+/- 0.01)

             precision    recall  f1-score   support

ANOTHER LORD       0.00      0.00      0.00        18
    AUMERLE       0.16      0.69      0.25        55
      BAGOT       0.00      0.00      0.00        20
   BERKELEY       0.00      0.00      0.00         5
   CARLISLE       0.00      0.00      0.00        25
DUCHESS OF YORK       0.00      0.00      0.00         8
FIRST HERALD       0.00      0.00      0.00        11
  FITZWATER       0.00      0.00      0.00        22
      GAUNT       0.33      0.06      0.10        18
KING RICHARD       0.22      0.16      0.18        38
    MARSHAL       0.00      0.00      0.00        16
    MOWBRAY       0.25      0.15      0.19        13
NORTHUMBERLAND       0.35      0.20      0.25        41
      PERCY       0.19      0.37      0.25        57
       ROSS       0.18      0.20      0.19        10
  SALISBURY       0.00      0.00      0.00         5
     SCROOP       0.00      0.00      0.00         5
SECOND HERALD       0.00      0.00      0.00        16
     SURREY       0.00      0.00      0.00        18
 WILLOUGHBY       0.00      0.00      0.00        10
       YORK       0.25      0.17      0.20        47

avg / total       0.14      0.19      0.13       458

=========================================================================================================

=========================================================================================================
Speaker: AUMERLE
Number of Total Listeners: 109

Best model LogisticRegression(C=0.20000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
178 features selected out of 356 total
F1 mean: 0.04 (+/- 0.05)

             precision    recall  f1-score   support

      BAGOT       0.50      0.27      0.35        11
BOLINGBROKE       0.32      0.67      0.43        18
   CARLISLE       0.25      0.09      0.13        11
DUCHESS OF YORK       0.00      0.00      0.00         8
  FITZWATER       0.00      0.00      0.00         6
KING RICHARD       0.30      0.67      0.42        15
      PERCY       0.25      0.08      0.12        13
  SALISBURY       0.00      0.00      0.00         8
     SCROOP       0.00      0.00      0.00         6
       YORK       0.38      0.69      0.49        13

avg / total       0.24      0.33      0.25       109

=========================================================================================================

=========================================================================================================
Speaker: DUCHESS OF YORK
Number of Total Listeners: 84

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
188 features selected out of 376 total
F1 mean: 0.06 (+/- 0.07)

             precision    recall  f1-score   support

    AUMERLE       0.30      0.25      0.27        24
BOLINGBROKE       0.00      0.00      0.00        12
      PERCY       0.00      0.00      0.00        12
    SERVANT       0.00      0.00      0.00         9
       YORK       0.34      0.81      0.48        27

avg / total       0.20      0.33      0.23        84

=========================================================================================================

=========================================================================================================
Speaker: MARSHAL
Number of Total Listeners: 38

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
67 features selected out of 134 total
F1 mean: 0.02 (+/- 0.05)

             precision    recall  f1-score   support

    AUMERLE       0.25      0.90      0.39        10
BOLINGBROKE       0.00      0.00      0.00         7
KING RICHARD       0.50      0.12      0.20         8
    MOWBRAY       0.00      0.00      0.00         6
SECOND HERALD       0.00      0.00      0.00         7

avg / total       0.17      0.26      0.15        38

=========================================================================================================

=========================================================================================================
Speaker: MOWBRAY
Number of Total Listeners: 54

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
269 features selected out of 539 total
F1 mean: 0.07 (+/- 0.05)

             precision    recall  f1-score   support

    AUMERLE       0.00      0.00      0.00         6
BOLINGBROKE       0.22      0.17      0.19        12
      GAUNT       0.22      0.17      0.19        12
KING RICHARD       0.25      0.69      0.37        13
    MARSHAL       0.00      0.00      0.00         6
SECOND HERALD       0.00      0.00      0.00         5

avg / total       0.16      0.24      0.17        54

=========================================================================================================

=========================================================================================================
Speaker: NORTHUMBERLAND
Number of Total Listeners: 173

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
278 features selected out of 556 total
F1 mean: 0.03 (+/- 0.04)

             precision    recall  f1-score   support

ANOTHER LORD       0.00      0.00      0.00         6
    AUMERLE       0.00      0.00      0.00         9
      BAGOT       0.00      0.00      0.00         6
BOLINGBROKE       0.21      0.79      0.33        24
   CARLISLE       0.00      0.00      0.00         9
  FITZWATER       0.00      0.00      0.00         6
      GAUNT       0.00      0.00      0.00        11
KING RICHARD       0.22      0.59      0.32        22
      PERCY       0.24      0.20      0.22        20
      QUEEN       0.20      0.07      0.11        14
       ROSS       0.00      0.00      0.00        12
     SURREY       0.00      0.00      0.00         6
 WILLOUGHBY       0.00      0.00      0.00        12
       YORK       0.00      0.00      0.00        16

avg / total       0.10      0.21      0.12       173

=========================================================================================================

=========================================================================================================
Speaker: SCROOP
Number of Total Listeners: 24

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
99 features selected out of 198 total
F1 mean: 0.10 (+/- 0.00)

             precision    recall  f1-score   support

    AUMERLE       0.25      1.00      0.40         6
   CARLISLE       0.00      0.00      0.00         6
KING RICHARD       0.00      0.00      0.00         6
  SALISBURY       0.00      0.00      0.00         6

avg / total       0.06      0.25      0.10        24

=========================================================================================================

=========================================================================================================
Speaker: PERCY
Number of Total Listeners: 21

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
106 features selected out of 213 total
F1 mean: 0.28 (+/- 0.17)

             precision    recall  f1-score   support

BOLINGBROKE       0.57      1.00      0.73        12
NORTHUMBERLAND       0.00      0.00      0.00         9

avg / total       0.33      0.57      0.42        21

=========================================================================================================

=========================================================================================================
Speaker: GAUNT
Number of Total Listeners: 92

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='ovr', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
347 features selected out of 695 total
F1 mean: 0.05 (+/- 0.09)

             precision    recall  f1-score   support

    AUMERLE       0.00      0.00      0.00        11
BOLINGBROKE       0.00      0.00      0.00        13
FIRST HERALD       0.00      0.00      0.00        10
KING RICHARD       0.23      0.95      0.37        21
    MARSHAL       0.00      0.00      0.00        11
      QUEEN       0.00      0.00      0.00         6
SECOND HERALD       0.00      0.00      0.00        11
       YORK       0.60      0.33      0.43         9

avg / total       0.11      0.25      0.13        92

=========================================================================================================

=========================================================================================================
Speaker: WILLOUGHBY
Number of Total Listeners: 34

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
42 features selected out of 85 total
F1 mean: 0.05 (+/- 0.05)

             precision    recall  f1-score   support

      GAUNT       0.00      0.00      0.00         6
KING RICHARD       0.20      0.17      0.18         6
NORTHUMBERLAND       0.00      0.00      0.00         8
      QUEEN       0.00      0.00      0.00         6
       ROSS       0.24      0.88      0.38         8

avg / total       0.09      0.24      0.12        34

=========================================================================================================

=========================================================================================================
Speaker: YORK
Number of Total Listeners: 179

Best model LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=200,
          multi_class='multinomial', penalty='l1', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=1)
460 features selected out of 921 total
F1 mean: 0.02 (+/- 0.02)

             precision    recall  f1-score   support

    AUMERLE  